{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0109256-9d96-4c6e-9805-ce39c9a69641",
   "metadata": {},
   "source": [
    "# Text preprocessing techniques\n",
    "* Converting words into lowercase\n",
    "* Removing leading and trailing whitespaces\n",
    "* Removing punctuation\n",
    "* Removing stopwords\n",
    "* Expanding contractions\n",
    "* Removing special characters (numbers, emojis, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87620d0e-8a57-4209-8b99-d38a21082fbb",
   "metadata": {},
   "source": [
    "## Tokenization using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c1dcc2-da98-4d42-835d-8c8d32a8ffe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:22:36.938287Z",
     "iopub.status.busy": "2023-01-05T01:22:36.938144Z",
     "iopub.status.idle": "2023-01-05T01:22:37.194025Z",
     "shell.execute_reply": "2023-01-05T01:22:37.193597Z",
     "shell.execute_reply.started": "2023-01-05T01:22:36.938276Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'I', 'do', \"n't\", 'know', 'what', 'I', \"'m\", 'doing', 'here', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Initiliaze string\n",
    "string = \"Hello! I don't know what I'm doing here.\"\n",
    "# Create a Doc object\n",
    "doc = nlp(string)\n",
    "# Generate list of tokens\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01eb4c-fdcb-4b9b-b1e3-3f26905baf03",
   "metadata": {},
   "source": [
    "## Lemmatization using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1c0526-0145-47f6-bcc5-5bd98d9b61af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:21:47.589172Z",
     "iopub.status.busy": "2023-01-05T01:21:47.589031Z",
     "iopub.status.idle": "2023-01-05T01:21:47.843833Z",
     "shell.execute_reply": "2023-01-05T01:21:47.843539Z",
     "shell.execute_reply.started": "2023-01-05T01:21:47.589161Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', '!', 'I', 'do', 'not', 'know', 'what', 'I', 'be', 'do', 'here', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Initiliaze string\n",
    "string = \"Hello! I don't know what I'm doing here.\"\n",
    "# Create a Doc object\n",
    "doc = nlp(string)\n",
    "# Generate list of lemmas\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c00f9-b175-41d4-b27d-954a70a0ba73",
   "metadata": {},
   "source": [
    "## Tokenizing the Gettysburg Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc36cea0-3a2c-42b3-8d0e-32d602ef8194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:32:32.493842Z",
     "iopub.status.busy": "2023-01-05T01:32:32.493704Z",
     "iopub.status.idle": "2023-01-05T01:32:32.495906Z",
     "shell.execute_reply": "2023-01-05T01:32:32.495649Z",
     "shell.execute_reply.started": "2023-01-05T01:32:32.493831Z"
    }
   },
   "outputs": [],
   "source": [
    "gettysburg = \"Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal. Now we're engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We're met on a great battlefield of that war. We've come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It's altogether fitting and proper that we should do this. But, in a larger sense, we can't dedicate - we can not consecrate - we can not hallow - this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It's rather for us to be here dedicated to the great task remaining before us - that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion - that we here highly resolve that these dead shall not have died in vain - that this nation, under God, shall have a new birth of freedom - and that government of the people, by the people, for the people, shall not perish from the earth.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14b781ab-1a26-4a6f-8c26-f87a970d7d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:35:57.538674Z",
     "iopub.status.busy": "2023-01-05T01:35:57.538537Z",
     "iopub.status.idle": "2023-01-05T01:35:57.564874Z",
     "shell.execute_reply": "2023-01-05T01:35:57.564494Z",
     "shell.execute_reply.started": "2023-01-05T01:35:57.538663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Four', 'score', 'and', 'seven', 'years', 'ago', 'our', 'fathers', 'brought', 'forth', 'on', 'this', 'continent', ',', 'a', 'new', 'nation', ',', 'conceived', 'in', 'Liberty', ',', 'and', 'dedicated', 'to', 'the', 'proposition', 'that', 'all', 'men', 'are', 'created', 'equal', '.', 'Now', 'we', \"'re\", 'engaged', 'in', 'a', 'great', 'civil', 'war', ',', 'testing', 'whether', 'that', 'nation', ',', 'or', 'any', 'nation', 'so', 'conceived', 'and', 'so', 'dedicated', ',', 'can', 'long', 'endure', '.', 'We', \"'re\", 'met', 'on', 'a', 'great', 'battlefield', 'of', 'that', 'war', '.', 'We', \"'ve\", 'come', 'to', 'dedicate', 'a', 'portion', 'of', 'that', 'field', ',', 'as', 'a', 'final', 'resting', 'place', 'for', 'those', 'who', 'here', 'gave', 'their', 'lives', 'that', 'that', 'nation', 'might', 'live', '.', 'It', \"'s\", 'altogether', 'fitting', 'and', 'proper', 'that', 'we', 'should', 'do', 'this', '.', 'But', ',', 'in', 'a', 'larger', 'sense', ',', 'we', 'ca', \"n't\", 'dedicate', '-', 'we', 'can', 'not', 'consecrate', '-', 'we', 'can', 'not', 'hallow', '-', 'this', 'ground', '.', 'The', 'brave', 'men', ',', 'living', 'and', 'dead', ',', 'who', 'struggled', 'here', ',', 'have', 'consecrated', 'it', ',', 'far', 'above', 'our', 'poor', 'power', 'to', 'add', 'or', 'detract', '.', 'The', 'world', 'will', 'little', 'note', ',', 'nor', 'long', 'remember', 'what', 'we', 'say', 'here', ',', 'but', 'it', 'can', 'never', 'forget', 'what', 'they', 'did', 'here', '.', 'It', 'is', 'for', 'us', 'the', 'living', ',', 'rather', ',', 'to', 'be', 'dedicated', 'here', 'to', 'the', 'unfinished', 'work', 'which', 'they', 'who', 'fought', 'here', 'have', 'thus', 'far', 'so', 'nobly', 'advanced', '.', 'It', \"'s\", 'rather', 'for', 'us', 'to', 'be', 'here', 'dedicated', 'to', 'the', 'great', 'task', 'remaining', 'before', 'us', '-', 'that', 'from', 'these', 'honored', 'dead', 'we', 'take', 'increased', 'devotion', 'to', 'that', 'cause', 'for', 'which', 'they', 'gave', 'the', 'last', 'full', 'measure', 'of', 'devotion', '-', 'that', 'we', 'here', 'highly', 'resolve', 'that', 'these', 'dead', 'shall', 'not', 'have', 'died', 'in', 'vain', '-', 'that', 'this', 'nation', ',', 'under', 'God', ',', 'shall', 'have', 'a', 'new', 'birth', 'of', 'freedom', '-', 'and', 'that', 'government', 'of', 'the', 'people', ',', 'by', 'the', 'people', ',', 'for', 'the', 'people', ',', 'shall', 'not', 'perish', 'from', 'the', 'earth', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "doc = nlp(gettysburg)\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0056b6c1-5e19-4907-8b30-2839703f4074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:36:01.826206Z",
     "iopub.status.busy": "2023-01-05T01:36:01.825777Z",
     "iopub.status.idle": "2023-01-05T01:36:01.828334Z",
     "shell.execute_reply": "2023-01-05T01:36:01.828025Z",
     "shell.execute_reply.started": "2023-01-05T01:36:01.826192Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['four', 'score', 'and', 'seven', 'year', 'ago', 'our', 'father', 'bring', 'forth', 'on', 'this', 'continent', ',', 'a', 'new', 'nation', ',', 'conceive', 'in', 'Liberty', ',', 'and', 'dedicate', 'to', 'the', 'proposition', 'that', 'all', 'man', 'be', 'create', 'equal', '.', 'now', 'we', 'be', 'engage', 'in', 'a', 'great', 'civil', 'war', ',', 'test', 'whether', 'that', 'nation', ',', 'or', 'any', 'nation', 'so', 'conceive', 'and', 'so', 'dedicated', ',', 'can', 'long', 'endure', '.', 'we', 'be', 'meet', 'on', 'a', 'great', 'battlefield', 'of', 'that', 'war', '.', 'we', \"'ve\", 'come', 'to', 'dedicate', 'a', 'portion', 'of', 'that', 'field', ',', 'as', 'a', 'final', 'resting', 'place', 'for', 'those', 'who', 'here', 'give', 'their', 'life', 'that', 'that', 'nation', 'might', 'live', '.', 'it', 'be', 'altogether', 'fitting', 'and', 'proper', 'that', 'we', 'should', 'do', 'this', '.', 'but', ',', 'in', 'a', 'large', 'sense', ',', 'we', 'can', 'not', 'dedicate', '-', 'we', 'can', 'not', 'consecrate', '-', 'we', 'can', 'not', 'hallow', '-', 'this', 'ground', '.', 'the', 'brave', 'man', ',', 'living', 'and', 'dead', ',', 'who', 'struggle', 'here', ',', 'have', 'consecrate', 'it', ',', 'far', 'above', 'our', 'poor', 'power', 'to', 'add', 'or', 'detract', '.', 'the', 'world', 'will', 'little', 'note', ',', 'nor', 'long', 'remember', 'what', 'we', 'say', 'here', ',', 'but', 'it', 'can', 'never', 'forget', 'what', 'they', 'do', 'here', '.', 'it', 'be', 'for', 'we', 'the', 'living', ',', 'rather', ',', 'to', 'be', 'dedicate', 'here', 'to', 'the', 'unfinished', 'work', 'which', 'they', 'who', 'fight', 'here', 'have', 'thus', 'far', 'so', 'nobly', 'advanced', '.', 'it', 'be', 'rather', 'for', 'we', 'to', 'be', 'here', 'dedicate', 'to', 'the', 'great', 'task', 'remain', 'before', 'we', '-', 'that', 'from', 'these', 'honored', 'dead', 'we', 'take', 'increased', 'devotion', 'to', 'that', 'cause', 'for', 'which', 'they', 'give', 'the', 'last', 'full', 'measure', 'of', 'devotion', '-', 'that', 'we', 'here', 'highly', 'resolve', 'that', 'these', 'dead', 'shall', 'not', 'have', 'die', 'in', 'vain', '-', 'that', 'this', 'nation', ',', 'under', 'God', ',', 'shall', 'have', 'a', 'new', 'birth', 'of', 'freedom', '-', 'and', 'that', 'government', 'of', 'the', 'people', ',', 'by', 'the', 'people', ',', 'for', 'the', 'people', ',', 'shall', 'not', 'perish', 'from', 'the', 'earth', '.']\n"
     ]
    }
   ],
   "source": [
    "# Generate lemmas\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24bae8b-c15c-43ba-95dd-ec0f7c1ad0c6",
   "metadata": {},
   "source": [
    "# Text cleaning techniques\n",
    "* Unnecessary whitespaces and escape sequences\n",
    "* Punctuations\n",
    "* Special characters (numbers, emojis, etc.)\n",
    "* Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896c5280-81e2-4834-946e-37e8a1a4c8f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:25:49.445325Z",
     "iopub.status.busy": "2023-01-05T01:25:49.445187Z",
     "iopub.status.idle": "2023-01-05T01:25:49.447733Z",
     "shell.execute_reply": "2023-01-05T01:25:49.447375Z",
     "shell.execute_reply.started": "2023-01-05T01:25:49.445314Z"
    }
   },
   "source": [
    "## A word of caution\n",
    "* Abbreviations: U.S.A , U.K , etc.\n",
    "* Proper Nouns: word2vec and xto10x .\n",
    "* Write your own custom function (using regex) for the more nuanced cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec6a5f-733d-4311-816b-0c679438b245",
   "metadata": {},
   "source": [
    "## Removing non-alphabetic characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e79959af-7f72-4b1a-9089-a1995aba4426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:38:53.072960Z",
     "iopub.status.busy": "2023-01-05T01:38:53.072824Z",
     "iopub.status.idle": "2023-01-05T01:38:53.378313Z",
     "shell.execute_reply": "2023-01-05T01:38:53.377971Z",
     "shell.execute_reply.started": "2023-01-05T01:38:53.072949Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'OMG', '!', '!', '!', '!', 'this', 'be', 'like', 'the', 'good', 'thing', 'ever', '\\t\\n', '.', '\\n', 'wow', ',', 'such', 'an', 'amazing', 'song', '!', 'I', 'be', 'hook', '.', 'top', '5', 'definitely', '.', '?', '\\n']\n"
     ]
    }
   ],
   "source": [
    "string = \"\"\"\n",
    "OMG!!!! This is like the best thing ever \\t\\n.\n",
    "Wow, such an amazing song! I'm hooked. Top 5 definitely. ?\n",
    "\"\"\"\n",
    "import spacy\n",
    "# Generate list of tokens\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(string)\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4f75fdf-3b8b-40cb-a689-53d2752c5cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:38:53.473069Z",
     "iopub.status.busy": "2023-01-05T01:38:53.472931Z",
     "iopub.status.idle": "2023-01-05T01:38:53.475467Z",
     "shell.execute_reply": "2023-01-05T01:38:53.475077Z",
     "shell.execute_reply.started": "2023-01-05T01:38:53.473058Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMG this be like the good thing ever wow such an amazing song I be hook top definitely\n"
     ]
    }
   ],
   "source": [
    "# Remove tokens that are not alphabetic\n",
    "a_lemmas = [lemma for lemma in lemmas if lemma.isalpha()]\n",
    "# Print string after text cleaning\n",
    "print(' '.join(a_lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d2dd8-9c6f-4684-b2c9-9520610da542",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "* Words that occur extremely commonly\n",
    "* Eg. articles, be verbs, pronouns, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50ea036e-87b4-493b-ac5c-912c1dd1b387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:45:40.821930Z",
     "iopub.status.busy": "2023-01-05T01:45:40.821792Z",
     "iopub.status.idle": "2023-01-05T01:45:40.824280Z",
     "shell.execute_reply": "2023-01-05T01:45:40.823917Z",
     "shell.execute_reply.started": "2023-01-05T01:45:40.821919Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seemed', 'then', 'therein', 'almost', 'now', 'been', 'they', 'while', 'most', 'moreover', 'whose', 'ca', 'here', 'used', 'also', 'even', 'top', 'everyone', 'the', 'becoming', 'its', \"'re\", 'toward', 'their', 'hereby', 'however', 'same', 'behind', 'often', 'must', 'perhaps', 'regarding', 'how', '’d', 'whether', 'various', 'fifteen', 'i', 'thru', 'due', 'an', 'afterwards', 'were', 'again', 'forty', 'third', 'everywhere', 'within', 'otherwise', 'yourself', 'sixty', 'sometimes', 'seeming', 'latter', '‘m', 'name', 'make', 'should', 'himself', 'why', 'empty', 'noone', 'although', 'always', 'in', 'you', 'thence', 'for', 'whoever', 'below', 'into', 'ten', 'all', 'hundred', 'because', 'he', 'together', 'itself', 'than', 'thereupon', 'nowhere', 'twenty', 'hereafter', 'either', 'whom', 'hence', 'former', 'something', 'more', 'elsewhere', 'ours', 'amongst', 'several', 'or', 'made', 'myself', 'these', 'seem', 'which', 'through', 'his', 'beside', 'take', 'another', 'we', 'own', 'am', 'hers', 'any', 'it', 'her', 'other', 'each', 'herself', 'yet', 'such', 'off', 'my', 'those', 'since', 'towards', 'serious', 'during', 'around', 'too', 'ever', 'still', 'was', 'get', 'onto', 'could', 'nothing', 'somehow', 'can', 'call', 'give', 'anything', 'between', 'nine', 'nevertheless', 'by', 'latterly', \"'m\", 'really', 'sometime', 'every', 'so', 'part', 'at', 'bottom', 'anyway', 'via', 'upon', 'yours', 'see', 'whatever', 'mostly', 'put', 'full', 'would', 'from', 'after', 'enough', \"'d\", 'further', 'that', 'formerly', 'above', 'else', 're', '‘re', 'twelve', 'please', 'until', 'are', 'had', \"n't\", 'of', 'beforehand', 'first', 'whence', 'be', 'does', 'meanwhile', 'much', 'some', 'indeed', 'say', 'least', 'very', 'do', \"'ll\", 'neither', 'thereafter', 'four', \"'ve\", 'under', 'unless', 'she', 'them', 'whereupon', 'well', 'ourselves', 'when', 'keep', 'has', 'and', 'rather', 'wherein', 'once', 'therefore', 'before', 'whereby', 'about', 'many', 'besides', 'per', 'eleven', 'as', 'done', 'hereupon', 'front', 'on', 'being', 'less', 'without', 'only', 'have', 'seems', 'become', 'no', 'thereby', 'yourselves', 'is', 'beyond', 'our', 'across', 'though', 'out', 'move', 'somewhere', 'not', 'next', 'but', 'may', 'to', 'might', 'will', 'whereafter', 'everything', 'just', 'became', 'n’t', 'themselves', 'us', 'one', 'if', 'nobody', 'eight', 'mine', 'alone', 'two', 'both', '’m', 'quite', '‘ve', 'who', 'n‘t', 'throughout', 'doing', 'amount', 'down', 'whither', \"'s\", 'where', '‘ll', '‘s', 'wherever', 'five', 'against', 'with', 'among', 'show', 'there', 'side', 'along', 'three', 'what', 'six', 'whereas', 'go', 'never', '’re', 'others', 'anywhere', '’ve', '‘d', 'becomes', 'this', 'back', 'your', 'few', 'me', 'a', 'thus', 'someone', 'over', 'nor', 'except', 'fifty', '’s', 'anyhow', 'him', 'anyone', 'up', 'herein', 'none', 'namely', 'whenever', 'using', 'already', 'last', 'did', 'whole', '’ll', 'cannot'}\n"
     ]
    }
   ],
   "source": [
    "# Removing stopwords using spaCy\n",
    "# Get list of stopwords\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cd52e20-fe93-4475-9102-f8005bb0b46a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:29:55.629653Z",
     "iopub.status.busy": "2023-01-05T01:29:55.629516Z",
     "iopub.status.idle": "2023-01-05T01:29:55.632293Z",
     "shell.execute_reply": "2023-01-05T01:29:55.631928Z",
     "shell.execute_reply.started": "2023-01-05T01:29:55.629642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMG like good thing wow amazing song I hook definitely\n"
     ]
    }
   ],
   "source": [
    "string = \"\"\"\n",
    "OMG!!!! This is like the best thing ever \\t\\n.\n",
    "Wow, such an amazing song! I'm hooked. Top 5 definitely. ?\n",
    "\"\"\"\n",
    "# Remove stopwords and non-alphabetic tokens\n",
    "a_lemmas = [lemma for lemma in lemmas\n",
    "if lemma.isalpha() and lemma not in stopwords]\n",
    "# Print string after text cleaning\n",
    "print(' '.join(a_lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185eb35-300b-4e00-82f3-240e172123e3",
   "metadata": {},
   "source": [
    "## TODO: Other text preprocessing techniques\n",
    "* Removing HTML/XML tags\n",
    "* Replacing accented characters (such as é)\n",
    "* Correcting spelling errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d20205-eaf2-4932-8c1d-e1bc721a149e",
   "metadata": {},
   "source": [
    "## Cleaning a blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59ba5371-ca6a-4fd6-8da6-209ee40f645e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:46:47.821271Z",
     "iopub.status.busy": "2023-01-05T01:46:47.821137Z",
     "iopub.status.idle": "2023-01-05T01:46:47.838717Z",
     "shell.execute_reply": "2023-01-05T01:46:47.838385Z",
     "shell.execute_reply.started": "2023-01-05T01:46:47.821260Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "century politic witness alarming rise populism Europe warning sign come UK Brexit Referendum vote swinge way Leave follow stupendous victory billionaire Donald Trump President United States November Europe steady rise populist far right party capitalize Europe Immigration Crisis raise nationalist anti europe sentiment instance include alternative Germany AfD win seat enter Bundestag upset Germany political order time Second World War success Five Star Movement Italy surge popularity neo nazism neo fascism country Hungary Czech Republic Poland Austria\n"
     ]
    }
   ],
   "source": [
    "blog = '\\nTwenty-first-century politics has witnessed an alarming rise of populism in the U.S. and Europe. The first warning signs came with the UK Brexit Referendum vote in 2016 swinging in the way of Leave. This was followed by a stupendous victory by billionaire Donald Trump to become the 45th President of the United States in November 2016. Since then, Europe has seen a steady rise in populist and far-right parties that have capitalized on Europe’s Immigration Crisis to raise nationalist and anti-Europe sentiments. Some instances include Alternative for Germany (AfD) winning 12.6% of all seats and entering the Bundestag, thus upsetting Germany’s political order for the first time since the Second World War, the success of the Five Star Movement in Italy and the surge in popularity of neo-nazism and neo-fascism in countries such as Hungary, Czech Republic, Poland and Austria.\\n'\n",
    "# create doc Object\n",
    "doc = nlp(blog)\n",
    "# Generate lemmatized tokens\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "# Remove stopwords and non-alphabetic tokens\n",
    "a_lemmas = [lemma for lemma in lemmas \n",
    "            if lemma.isalpha() and lemma not in stopwords]\n",
    "# Print string after text cleaning\n",
    "print(' '.join(a_lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b2d43-aefb-4e8f-9411-fda3ead53765",
   "metadata": {},
   "source": [
    "## Cleaning TED talks in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "014b062f-3196-45cc-be89-c6900e755d6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:50:51.367078Z",
     "iopub.status.busy": "2023-01-05T01:50:51.366940Z",
     "iopub.status.idle": "2023-01-05T01:50:51.396203Z",
     "shell.execute_reply": "2023-01-05T01:50:51.395831Z",
     "shell.execute_reply.started": "2023-01-05T01:50:51.367068Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      We're going to talk — my — a new lecture, just...\n",
       "1      This is a representation of your brain, and yo...\n",
       "2      It's a great honor today to share with you The...\n",
       "3      My passions are music, technology and making t...\n",
       "4      It used to be that if you wanted to get a comp...\n",
       "                             ...                        \n",
       "495    Today I'm going to unpack for you three exampl...\n",
       "496    Both myself and my brother belong to the under...\n",
       "497    John Hockenberry: It's great to be here with y...\n",
       "498    What you're doing, right now, at this very mom...\n",
       "499    We've got a real problem with math education r...\n",
       "Name: transcript, Length: 500, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ted = pd.read_csv('ted.csv')\n",
    "ted['transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "add8b1af-af3c-4d4f-b655-a14f16dc9458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:50:51.937305Z",
     "iopub.status.busy": "2023-01-05T01:50:51.937168Z",
     "iopub.status.idle": "2023-01-05T01:51:20.999401Z",
     "shell.execute_reply": "2023-01-05T01:51:20.998962Z",
     "shell.execute_reply.started": "2023-01-05T01:50:51.937294Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talk new lecture TED I illusion create TED I t...\n",
       "1      representation brain brain break left half log...\n",
       "2      great honor today share Digital Universe creat...\n",
       "3      passion music technology thing combination thi...\n",
       "4      use want computer new program programming requ...\n",
       "                             ...                        \n",
       "495    today I unpack example iconic design perfect s...\n",
       "496    brother belong demographic Pat percent accord ...\n",
       "497    John Hockenberry great Tom I want start questi...\n",
       "498    right moment kill More car internet little mob...\n",
       "499    real problem math education right basically ha...\n",
       "Name: transcript, Length: 500, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess(text):\n",
    "  \t# Create Doc object\n",
    "    doc = nlp(text, disable=['ner', 'parser'])\n",
    "    # Generate lemmas\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    # Remove stopwords and non-alphabetic characters\n",
    "    a_lemmas = [lemma for lemma in lemmas \n",
    "            if lemma.isalpha() and lemma not in stopwords]\n",
    "    \n",
    "    return ' '.join(a_lemmas)\n",
    "  \n",
    "# Apply preprocess to ted['transcript']\n",
    "ted['transcript'] = ted['transcript'].apply(preprocess)\n",
    "ted['transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c3f8bc-c8a8-4da1-b184-d96fd1b460a2",
   "metadata": {},
   "source": [
    "# Part-of-speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d9e5fa-54ac-49c8-9611-281b03664696",
   "metadata": {},
   "source": [
    "## Applications\n",
    "* Word-sense disambiguation\n",
    "    * \"The bear is a majestic animal\"\n",
    "    * \"Please bear with me\"\n",
    "* Sentiment analysis\n",
    "* Question answering\n",
    "* Fake news and opinion spam detection\n",
    "\n",
    "> For example, one paper discovered that fake news headlines, on average, tend to use lesser common nouns and more proper nouns than mainstream headlines. Generating the POS tags for these words proved extremely useful in detecting false or hyperpartisan news. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a66fd0-c856-4971-9801-0c38391df3a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:53:01.164984Z",
     "iopub.status.busy": "2023-01-05T01:53:01.164846Z",
     "iopub.status.idle": "2023-01-05T01:53:01.167798Z",
     "shell.execute_reply": "2023-01-05T01:53:01.167306Z",
     "shell.execute_reply.started": "2023-01-05T01:53:01.164972Z"
    }
   },
   "source": [
    "## POS tagging\n",
    "* Assigning every word, its corresponding part of speech.  \n",
    "    \"Jane is an amazing guitarist.\"\n",
    "* POS Tagging:\n",
    "    * Jane → proper noun\n",
    "    * is → verb\n",
    "    * an → determiner\n",
    "    * amazing → adjective\n",
    "    * guitarist → noun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e18ae7-d1ee-4e88-9c14-f60bceef540e",
   "metadata": {},
   "source": [
    "## POS tagging using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b0d0da3-b1ce-44fc-999f-2504d128b31d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T01:56:24.631746Z",
     "iopub.status.busy": "2023-01-05T01:56:24.631611Z",
     "iopub.status.idle": "2023-01-05T01:56:24.639427Z",
     "shell.execute_reply": "2023-01-05T01:56:24.639145Z",
     "shell.execute_reply.started": "2023-01-05T01:56:24.631735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jane', 'PROPN'), ('is', 'AUX'), ('an', 'DET'), ('amazing', 'ADJ'), ('guitarist', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "string = \"Jane is an amazing guitarist\"\n",
    "# Create a Doc object\n",
    "doc = nlp(string)\n",
    "# Generate list of tokens and pos tags\n",
    "pos = [(token.text, token.pos_) for token in doc]\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c6bfc9-1a50-4619-a626-f2d43a6111ab",
   "metadata": {},
   "source": [
    "## POS annotations in spaCy\n",
    "* PROPN → proper noun\n",
    "* DET → determinant\n",
    "* spaCy annotations at hhttps://spacy.io/api/annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68af2e3-f442-451f-94bd-99390ed598a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:00:50.495563Z",
     "iopub.status.busy": "2023-01-05T02:00:50.495097Z",
     "iopub.status.idle": "2023-01-05T02:00:50.497583Z",
     "shell.execute_reply": "2023-01-05T02:00:50.497056Z",
     "shell.execute_reply.started": "2023-01-05T02:00:50.495550Z"
    }
   },
   "source": [
    "## POS tagging in Lord of the Flies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0250eb70-747d-4a34-a48e-19f1464050e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:02:47.484779Z",
     "iopub.status.busy": "2023-01-05T02:02:47.484643Z",
     "iopub.status.idle": "2023-01-05T02:02:47.740477Z",
     "shell.execute_reply": "2023-01-05T02:02:47.740133Z",
     "shell.execute_reply.started": "2023-01-05T02:02:47.484768Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('He', 'PRON'), ('found', 'VERB'), ('himself', 'PRON'), ('understanding', 'VERB'), ('the', 'DET'), ('wearisomeness', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('life', 'NOUN'), (',', 'PUNCT'), ('where', 'SCONJ'), ('every', 'DET'), ('path', 'NOUN'), ('was', 'AUX'), ('an', 'DET'), ('improvisation', 'NOUN'), ('and', 'CCONJ'), ('a', 'DET'), ('considerable', 'ADJ'), ('part', 'NOUN'), ('of', 'ADP'), ('one', 'NUM'), ('’s', 'NUM'), ('waking', 'VERB'), ('life', 'NOUN'), ('was', 'AUX'), ('spent', 'VERB'), ('watching', 'VERB'), ('one', 'NUM'), ('’s', 'NUM'), ('feet', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "lotf = 'He found himself understanding the wearisomeness of this life, where every path was an improvisation and a considerable part of one’s waking life was spent watching one’s feet.'\n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Create a Doc object\n",
    "doc = nlp(lotf)\n",
    "# Generate tokens and pos tags\n",
    "pos = [(token.text, token.pos_) for token in doc]\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb24883-16bf-4a28-bec0-3aeff3db0290",
   "metadata": {},
   "source": [
    "## Counting nouns in a piece of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cae01c3b-10c5-46b5-80e4-97f5d588bd75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:04:58.592032Z",
     "iopub.status.busy": "2023-01-05T02:04:58.591891Z",
     "iopub.status.idle": "2023-01-05T02:04:58.598595Z",
     "shell.execute_reply": "2023-01-05T02:04:58.598222Z",
     "shell.execute_reply.started": "2023-01-05T02:04:58.592020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Returns number of proper nouns\n",
    "def proper_nouns(text, model=nlp):\n",
    "  \t# Create doc object\n",
    "    doc = model(text)\n",
    "    # Generate list of POS tags\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    \n",
    "    # Return number of proper nouns\n",
    "    return pos.count('PROPN')\n",
    "\n",
    "print(proper_nouns(\"Abdul, Bill and Cathy went to the market to buy apples.\", nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38fc68a7-1b87-4a70-a5ca-0dd0b2207a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:05:49.138879Z",
     "iopub.status.busy": "2023-01-05T02:05:49.138665Z",
     "iopub.status.idle": "2023-01-05T02:05:49.147262Z",
     "shell.execute_reply": "2023-01-05T02:05:49.146907Z",
     "shell.execute_reply.started": "2023-01-05T02:05:49.138860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Returns number of other nouns\n",
    "def nouns(text, model=nlp):\n",
    "  \t# Create doc object\n",
    "    doc = model(text)\n",
    "    # Generate list of POS tags\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    \n",
    "    # Return number of other nouns\n",
    "    return pos.count('NOUN')\n",
    "\n",
    "print(nouns(\"Abdul, Bill and Cathy went to the market to buy apples.\", nlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410d3c5-95bd-44d2-8b2c-803d2570cc83",
   "metadata": {},
   "source": [
    "## Noun usage in fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f16ff70-8875-4fe1-b323-6e916635bb8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:07:31.908685Z",
     "iopub.status.busy": "2023-01-05T02:07:31.908547Z",
     "iopub.status.idle": "2023-01-05T02:07:31.914558Z",
     "shell.execute_reply": "2023-01-05T02:07:31.914294Z",
     "shell.execute_reply.started": "2023-01-05T02:07:31.908674Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>The Mandela Effect was made by one overlooked ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>CNN: One voter can make a difference by voting...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>Give Social Security recipients a CEO-style raise</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>Fireworks erupt between Trump and Bush, Rubio ...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>Obama, sounding like his critics, admits no 'c...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                              title label\n",
       "0            0                       You Can Smell Hillary’s Fear  FAKE\n",
       "1            1  Watch The Exact Moment Paul Ryan Committed Pol...  FAKE\n",
       "2            2        Kerry to go to Paris in gesture of sympathy  REAL\n",
       "3            3  Bernie supporters on Twitter erupt in anger ag...  FAKE\n",
       "4            4   The Battle of New York: Why This Primary Matters  REAL\n",
       "..         ...                                                ...   ...\n",
       "95          95  The Mandela Effect was made by one overlooked ...  FAKE\n",
       "96          96  CNN: One voter can make a difference by voting...  FAKE\n",
       "97          97  Give Social Security recipients a CEO-style raise  REAL\n",
       "98          98  Fireworks erupt between Trump and Bush, Rubio ...  REAL\n",
       "99          99  Obama, sounding like his critics, admits no 'c...  REAL\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines = pd.read_csv('fakenews.csv')\n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "293683c7-cba4-410a-b2a2-2a8740faadac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:09:19.528692Z",
     "iopub.status.busy": "2023-01-05T02:09:19.528556Z",
     "iopub.status.idle": "2023-01-05T02:09:19.868085Z",
     "shell.execute_reply": "2023-01-05T02:09:19.867731Z",
     "shell.execute_reply.started": "2023-01-05T02:09:19.528681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean no. of proper nouns in real and fake headlines are 2.37 and 4.81 respectively\n"
     ]
    }
   ],
   "source": [
    "headlines['num_propn'] = headlines['title'].apply(proper_nouns)\n",
    "\n",
    "# Compute mean of proper nouns\n",
    "real_propn = headlines[headlines['label'] == 'REAL']['num_propn'].mean()\n",
    "fake_propn = headlines[headlines['label'] == 'FAKE']['num_propn'].mean()\n",
    "\n",
    "# Print results\n",
    "print(\"Mean no. of proper nouns in real and fake headlines are %.2f and %.2f respectively\"%(real_propn, fake_propn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7c9c359-a038-46f1-bb88-b56dfde9eafb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:10:04.674170Z",
     "iopub.status.busy": "2023-01-05T02:10:04.674032Z",
     "iopub.status.idle": "2023-01-05T02:10:04.968984Z",
     "shell.execute_reply": "2023-01-05T02:10:04.968594Z",
     "shell.execute_reply.started": "2023-01-05T02:10:04.674159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean no. of other nouns in real and fake headlines are 2.39 and 1.60 respectively\n"
     ]
    }
   ],
   "source": [
    "headlines['num_noun'] = headlines['title'].apply(nouns)\n",
    "\n",
    "# Compute mean of other nouns\n",
    "real_noun = headlines[headlines['label'] == 'REAL']['num_noun'].mean()\n",
    "fake_noun = headlines[headlines['label'] == 'FAKE']['num_noun'].mean()\n",
    "\n",
    "# Print results\n",
    "print(\"Mean no. of other nouns in real and fake headlines are %.2f and %.2f respectively\"%(real_noun, fake_noun))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773cd830-5e0f-4e3e-991f-7066aada6483",
   "metadata": {},
   "source": [
    "# Named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1fea72-3837-4a14-9749-75afb6fa46b5",
   "metadata": {},
   "source": [
    "## Applications\n",
    "* Efficient search algorithms\n",
    "* Questions answering\n",
    "* News article classification\n",
    "* Custom services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cfcb06-4675-4d04-90c4-e8f724539643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:21:21.875693Z",
     "iopub.status.busy": "2023-01-05T02:21:21.875553Z",
     "iopub.status.idle": "2023-01-05T02:21:21.878381Z",
     "shell.execute_reply": "2023-01-05T02:21:21.877917Z",
     "shell.execute_reply.started": "2023-01-05T02:21:21.875682Z"
    }
   },
   "source": [
    "## Named entity recognition\n",
    "* Identifying and classifying named entities into predefined categories\n",
    "* Categories include person, organization, country, etc.  \n",
    "    \"John Doe is a software engineer working at Google. He lives in France.\"\n",
    "* Named Entities\n",
    "    * John Doe → person\n",
    "    * Google → organization\n",
    "    * France → country (geopolitical entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815f7ad-c89e-43cc-b8c3-f8c4f5e055bc",
   "metadata": {},
   "source": [
    "## NER using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce054148-ec97-43a4-b71f-b61298b27077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:22:52.435661Z",
     "iopub.status.busy": "2023-01-05T02:22:52.435526Z",
     "iopub.status.idle": "2023-01-05T02:22:52.442519Z",
     "shell.execute_reply": "2023-01-05T02:22:52.442103Z",
     "shell.execute_reply.started": "2023-01-05T02:22:52.435650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John Doe', 'PERSON'), ('Google', 'ORG'), ('France', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "string = \"John Doe is a software engineer working at Google. He lives in France.\"\n",
    "doc = nlp(string)\n",
    "ne = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "print(ne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffbd37-aeb6-4610-9130-5e9093434d32",
   "metadata": {},
   "source": [
    "## NER annotations in spaCy\n",
    "* More than 15 categories of named entities\n",
    "* NER annotations at https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29b3cb-ba04-4a8a-b99a-f4d9a02c42dd",
   "metadata": {},
   "source": [
    "## Named entities in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b26b0eb2-7594-4bfc-b432-38d1e77a926c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:31:51.978570Z",
     "iopub.status.busy": "2023-01-05T02:31:51.978428Z",
     "iopub.status.idle": "2023-01-05T02:31:51.984948Z",
     "shell.execute_reply": "2023-01-05T02:31:51.984671Z",
     "shell.execute_reply.started": "2023-01-05T02:31:51.978559Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sundar Pichai PERSON\n",
      "Google ORG\n",
      "Mountain View GPE\n"
     ]
    }
   ],
   "source": [
    "text = 'Sundar Pichai is the CEO of Google. Its headquarters is in Mountain View.'\n",
    "doc = nlp(text)\n",
    "# Print all named entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa2b978-69bc-4123-8f27-51fa5a8c1a22",
   "metadata": {},
   "source": [
    "## Identifying people mentioned in a news article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e929023e-f610-4f64-8ecb-c7604f0d654d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T02:35:19.988719Z",
     "iopub.status.busy": "2023-01-05T02:35:19.988578Z",
     "iopub.status.idle": "2023-01-05T02:35:20.001582Z",
     "shell.execute_reply": "2023-01-05T02:35:20.001252Z",
     "shell.execute_reply.started": "2023-01-05T02:35:19.988708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Facebook', 'Sheryl Sandberg', 'Mark Zuckerberg', 'Facebook']\n"
     ]
    }
   ],
   "source": [
    "tc =\"\\nIt’s' been a busy day for Facebook  exec op-eds. Earlier this morning, Sheryl Sandberg broke the site’s silence around the Christchurch massacre, and now Mark Zuckerberg is calling on governments and other bodies to increase regulation around the sorts of data Facebook traffics in. He’s hoping to get out in front of heavy-handed regulation and get a seat at the table shaping it.\\n\"\n",
    "def find_persons(text):\n",
    "    doc = nlp(text)\n",
    "    persons = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']\n",
    "    return persons\n",
    "\n",
    "print(find_persons(tc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a96a323-f9bb-4ebe-b3b7-8e0272b7db56",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A word of caution\n",
    "* Not perfect\n",
    "* Performance dependent on training and test data\n",
    "* Train models with specialized data for nuanced cases\n",
    "* Language specific"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
