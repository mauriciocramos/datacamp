{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5bebc76-d420-48cc-9dc2-1d1b6228014c",
   "metadata": {},
   "source": [
    "# Parallelized collection (parallelizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b714c76-f1ef-4cff-a68f-ba0123b95fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:42.272901Z",
     "iopub.status.busy": "2023-05-02T20:59:42.272798Z",
     "iopub.status.idle": "2023-05-02T20:59:42.337121Z",
     "shell.execute_reply": "2023-05-02T20:59:42.336713Z",
     "shell.execute_reply.started": "2023-05-02T20:59:42.272890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93538890-d5a2-481a-98b1-738ba7a4e173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:42.338050Z",
     "iopub.status.busy": "2023-05-02T20:59:42.337757Z",
     "iopub.status.idle": "2023-05-02T20:59:43.964828Z",
     "shell.execute_reply": "2023-05-02T20:59:43.964490Z",
     "shell.execute_reply.started": "2023-05-02T20:59:42.338034Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 17:59:43 WARN Utils: Your hostname, rig resolves to a loopback address: 127.0.1.1; using 192.168.0.102 instead (on interface enp6s0)\n",
      "23/05/02 17:59:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/02 17:59:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d5bc01b-0d4c-42fd-a601-29705ef1f757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:43.965345Z",
     "iopub.status.busy": "2023-05-02T20:59:43.965243Z",
     "iopub.status.idle": "2023-05-02T20:59:44.104915Z",
     "shell.execute_reply": "2023-05-02T20:59:44.104476Z",
     "shell.execute_reply.started": "2023-05-02T20:59:43.965334Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numRDD = sc.parallelize([1, 2, 3, 4])\n",
    "type(numRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d2fbbf-a725-46b3-8f29-8268c6291e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.106438Z",
     "iopub.status.busy": "2023-05-02T20:59:44.106260Z",
     "iopub.status.idle": "2023-05-02T20:59:44.112018Z",
     "shell.execute_reply": "2023-05-02T20:59:44.111686Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.106421Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helloRDD = sc.parallelize('Hello world')\n",
    "type(helloRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d80cd56-f603-49c3-8e66-af8d932af0b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:08:53.919506Z",
     "iopub.status.busy": "2023-03-29T18:08:53.919293Z",
     "iopub.status.idle": "2023-03-29T18:08:53.922439Z",
     "shell.execute_reply": "2023-03-29T18:08:53.921769Z",
     "shell.execute_reply.started": "2023-03-29T18:08:53.919488Z"
    }
   },
   "source": [
    "# From external datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9baf93e7-57d0-4fe9-8a5d-7430e12696dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.112694Z",
     "iopub.status.busy": "2023-05-02T20:59:44.112456Z",
     "iopub.status.idle": "2023-05-02T20:59:44.257531Z",
     "shell.execute_reply": "2023-05-02T20:59:44.257262Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.112681Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileRDD = sc.textFile('Complete_Shakespeare.txt')\n",
    "type(fileRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74cdab-9127-4e2b-987b-acbb81561b8a",
   "metadata": {},
   "source": [
    "# Understanding Partitioning in PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc203e-b983-4357-90c6-d85ebf492e48",
   "metadata": {},
   "source": [
    "* A partition is a logical division of a large distributed data set\n",
    "* parallelize() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08daaec-47e4-40bc-a946-301fde26a484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.258174Z",
     "iopub.status.busy": "2023-05-02T20:59:44.257901Z",
     "iopub.status.idle": "2023-05-02T20:59:44.262832Z",
     "shell.execute_reply": "2023-05-02T20:59:44.262592Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.258164Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numRDD = sc.parallelize(range(10), numSlices=6)\n",
    "type(numRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f0ad67-163a-494e-852f-a2a2fe04f4cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.263357Z",
     "iopub.status.busy": "2023-05-02T20:59:44.263175Z",
     "iopub.status.idle": "2023-05-02T20:59:44.268683Z",
     "shell.execute_reply": "2023-05-02T20:59:44.268305Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.263347Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd11b390-c6cd-4c4a-b01d-f5bf484e6d2c",
   "metadata": {},
   "source": [
    "* textFile() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5966b33-4fbd-4d2b-ac09-c61085fbfade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.269455Z",
     "iopub.status.busy": "2023-05-02T20:59:44.269186Z",
     "iopub.status.idle": "2023-05-02T20:59:44.287278Z",
     "shell.execute_reply": "2023-05-02T20:59:44.286935Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.269439Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileRDD = sc.textFile(\"Complete_Shakespeare.txt\", minPartitions=6)\n",
    "type(fileRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d992b921-238f-4a79-b2c1-728c592e782c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.287934Z",
     "iopub.status.busy": "2023-05-02T20:59:44.287780Z",
     "iopub.status.idle": "2023-05-02T20:59:44.315402Z",
     "shell.execute_reply": "2023-05-02T20:59:44.315081Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.287920Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c221710-bfc7-41a5-a3aa-4dca3baa301c",
   "metadata": {},
   "source": [
    "The number of partitions in an RDD can be found by using getNumPartitions() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b116183-8921-4cfc-9620-470f88c85d34",
   "metadata": {},
   "source": [
    "# RDDs from Parallelized collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda093bd-5230-4f94-a1e0-e0de434a28e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.315852Z",
     "iopub.status.busy": "2023-05-02T20:59:44.315755Z",
     "iopub.status.idle": "2023-05-02T20:59:44.320550Z",
     "shell.execute_reply": "2023-05-02T20:59:44.320279Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.315843Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of RDD is <class 'pyspark.rdd.RDD'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an RDD from a list of words\n",
    "RDD = sc.parallelize([\"Spark\", \"is\", \"a\", \"framework\", \"for\", \"Big Data processing\"])\n",
    "# Print out the type of the created object\n",
    "print(\"The type of RDD is\", type(RDD))\n",
    "RDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ae24a-b188-4171-af82-89da4685516a",
   "metadata": {},
   "source": [
    "# RDDs from External Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e868f1d-c173-4108-94af-d63762f1e7c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.321009Z",
     "iopub.status.busy": "2023-05-02T20:59:44.320908Z",
     "iopub.status.idle": "2023-05-02T20:59:44.343150Z",
     "shell.execute_reply": "2023-05-02T20:59:44.342901Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.320999Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file type of fileRDD is <class 'pyspark.rdd.RDD'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fileRDD from file_path\n",
    "fileRDD = sc.textFile('Complete_Shakespeare.txt')\n",
    "# Check the type of fileRDD\n",
    "print(\"The file type of fileRDD is\", type(fileRDD))\n",
    "fileRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d5f1d1-07f4-4ec3-becd-f4b33ae380b1",
   "metadata": {},
   "source": [
    "# Partitions in your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91ec9e6d-eac6-45fb-a42f-a448428199b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.343750Z",
     "iopub.status.busy": "2023-05-02T20:59:44.343501Z",
     "iopub.status.idle": "2023-05-02T20:59:44.364170Z",
     "shell.execute_reply": "2023-05-02T20:59:44.363721Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.343740Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions in fileRDD is 2\n",
      "Number of partitions in fileRDD_part is 5\n"
     ]
    }
   ],
   "source": [
    "# Check the number of partitions in fileRDD\n",
    "print(\"Number of partitions in fileRDD is\", fileRDD.getNumPartitions())\n",
    "# Create a fileRDD_part from file_path with 5 partitions\n",
    "fileRDD_part = sc.textFile('Complete_Shakespeare.txt', minPartitions = 5)\n",
    "# Check the number of partitions in fileRDD_part\n",
    "print(\"Number of partitions in fileRDD_part is\", fileRDD_part.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f82cd-beec-4961-ade4-a4d623348265",
   "metadata": {},
   "source": [
    "# Map and Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa309d46-80fb-4fb3-8c3a-afc45ba76982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.365931Z",
     "iopub.status.busy": "2023-05-02T20:59:44.365769Z",
     "iopub.status.idle": "2023-05-02T20:59:44.983812Z",
     "shell.execute_reply": "2023-05-02T20:59:44.983534Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.365919Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8\n",
      "27\n",
      "64\n",
      "125\n",
      "216\n",
      "343\n",
      "512\n",
      "729\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "numbRDD = sc.parallelize(range(1,11))\n",
    "# Create map() transformation to cube numbers\n",
    "cubedRDD = numbRDD.map(lambda x: x**3)\n",
    "# Collect the results\n",
    "numbers_all = cubedRDD.collect()\n",
    "# Print the numbers from numbers_all\n",
    "for numb in numbers_all:\n",
    "\tprint(numb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865f8436-d2e5-400b-ba40-fc0a87e01086",
   "metadata": {},
   "source": [
    "# Filter and Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02cf60e6-e476-426a-81f1-aa92e933c618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:44.984309Z",
     "iopub.status.busy": "2023-05-02T20:59:44.984203Z",
     "iopub.status.idle": "2023-05-02T20:59:45.162916Z",
     "shell.execute_reply": "2023-05-02T20:59:45.162640Z",
     "shell.execute_reply.started": "2023-05-02T20:59:44.984299Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of lines with the keyword Spark is 7\n",
      "Examples for Learning Spark\n",
      "Examples for the Learning Spark book. These examples require a number of libraries and as such have long build files. We have also added a stand alone example with minimal dependencies and a small build file\n",
      "These examples have been updated to run against Spark 1.3 so they may\n",
      "be slightly different than the versions in your copy of \"Learning Spark\".\n"
     ]
    }
   ],
   "source": [
    "fileRDD = sc.textFile('test.md')\n",
    "# Filter the fileRDD to select lines with Spark keyword\n",
    "fileRDD_filter = fileRDD.filter(lambda line: 'Spark' in line)\n",
    "# How many lines are there in fileRDD?\n",
    "print(\"The total number of lines with the keyword Spark is\", fileRDD_filter.count())\n",
    "# Print the first four lines of fileRDD\n",
    "for line in fileRDD_filter.take(4):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc5f0c-2f13-4598-a850-0bc0bc979a24",
   "metadata": {},
   "source": [
    "# Creating pair RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "308a695c-eff2-414c-b5dc-0f291b212939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:45.163411Z",
     "iopub.status.busy": "2023-05-02T20:59:45.163300Z",
     "iopub.status.idle": "2023-05-02T20:59:45.208986Z",
     "shell.execute_reply": "2023-05-02T20:59:45.208637Z",
     "shell.execute_reply.started": "2023-05-02T20:59:45.163397Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sam', 23), ('Mary', 34), ('Peter', 25)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tuple = [('Sam', 23), ('Mary', 34), ('Peter', 25)]\n",
    "pairRDD_tuple = sc.parallelize(my_tuple)\n",
    "pairRDD_tuple.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5a84d3-66fd-4c9c-9a5f-510affdbcca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:45.209916Z",
     "iopub.status.busy": "2023-05-02T20:59:45.209592Z",
     "iopub.status.idle": "2023-05-02T20:59:45.387705Z",
     "shell.execute_reply": "2023-05-02T20:59:45.387156Z",
     "shell.execute_reply.started": "2023-05-02T20:59:45.209895Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sam', '23'), ('Mary', '34'), ('Peter', '25')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = ['Sam 23', 'Mary 34', 'Peter 25']\n",
    "regularRDD = sc.parallelize(my_list)\n",
    "pairRDD_RDD = regularRDD.map(lambda s: tuple(s.split(' ')))\n",
    "pairRDD_RDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72effc13-49af-4829-8644-2e0231bc0543",
   "metadata": {},
   "source": [
    "# Transformations on pair RDDs\n",
    "* All regular transformations work on pair RDD\n",
    "* Have to pass functions that operate on key value pairs rather than on individual elements\n",
    "* Examples of paired RDD Transformations\n",
    "    * reduceByKey(func): Combine values with the same key\n",
    "    * groupByKey(): Group values with the same key\n",
    "    * sortByKey(): Return an RDD sorted by the key\n",
    "    * join(): Join two pair RDDs based on their key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2863ad31-875f-4b5c-9d95-a7736e88acb4",
   "metadata": {},
   "source": [
    "## reduceByKey() transformation\n",
    "* reduceByKey() transformation combines values with the same key\n",
    "* It runs parallel operations for each key in the dataset\n",
    "* It is a transformation and not action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e8dcb54-8c3a-40a7-9a8c-af971a97dd41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:45.388517Z",
     "iopub.status.busy": "2023-05-02T20:59:45.388352Z",
     "iopub.status.idle": "2023-05-02T20:59:45.914721Z",
     "shell.execute_reply": "2023-05-02T20:59:45.914361Z",
     "shell.execute_reply.started": "2023-05-02T20:59:45.388502Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Neymar', 22), ('Ronaldo', 34), ('Messi', 47)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduceByKey summing\n",
    "regularRDD = sc.parallelize([(\"Messi\", 23), (\"Ronaldo\", 34), (\"Neymar\", 22), (\"Messi\", 24)])\n",
    "pairRDD_reducebykey = regularRDD.reduceByKey(lambda x,y : x + y)\n",
    "pairRDD_reducebykey.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b47e7-9a2c-4770-98e1-e2a78458eef6",
   "metadata": {},
   "source": [
    "## sortByKey() transformation\n",
    "* sortByKey() operation orders pair RDD by key\n",
    "* It returns an RDD sorted by key in ascending or descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "658771a7-10c0-4d76-bbb7-a332da749471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:45.915486Z",
     "iopub.status.busy": "2023-05-02T20:59:45.915202Z",
     "iopub.status.idle": "2023-05-02T20:59:46.758375Z",
     "shell.execute_reply": "2023-05-02T20:59:46.758062Z",
     "shell.execute_reply.started": "2023-05-02T20:59:45.915473Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(47, 'Messi'), (34, 'Ronaldo'), (22, 'Neymar')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# swap key value and sort descending\n",
    "# pairRDD_reducebykey_rev = pairRDD_reducebykey.map(lambda x: list(reversed(x)))\n",
    "pairRDD_reducebykey_rev = pairRDD_reducebykey.map(lambda x: (x[1], x[0]))\n",
    "pairRDD_reducebykey_rev.sortByKey(ascending=False).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d45a8-f00f-4a88-80cd-3fed486d6369",
   "metadata": {},
   "source": [
    "## groupByKey() transformation\n",
    "* groupByKey() groups all the values with the same key in the pair RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4248a20f-c740-4f03-bd2a-b0fc623a2ae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:46.758902Z",
     "iopub.status.busy": "2023-05-02T20:59:46.758780Z",
     "iopub.status.idle": "2023-05-02T20:59:47.095933Z",
     "shell.execute_reply": "2023-05-02T20:59:47.095570Z",
     "shell.execute_reply.started": "2023-05-02T20:59:46.758890Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR ['CDG']\n",
      "UK ['LHR']\n",
      "US ['JFK', 'SFO']\n"
     ]
    }
   ],
   "source": [
    "airports = [(\"US\", \"JFK\"),(\"UK\", \"LHR\"),(\"FR\", \"CDG\"),(\"US\", \"SFO\")]\n",
    "regularRDD = sc.parallelize(airports)\n",
    "pairRDD_group = regularRDD.groupByKey().collect()\n",
    "for cont, air in pairRDD_group:\n",
    "    print(cont, list(air))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66970ddf-a4ed-4dd6-b618-d2f85d2dbf3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## join() transformation\n",
    "join() transformation joins the two pair RDDs based on their key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "776cbaf0-14a4-4d6b-95a1-619bd69b8ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:47.096504Z",
     "iopub.status.busy": "2023-05-02T20:59:47.096359Z",
     "iopub.status.idle": "2023-05-02T20:59:47.881309Z",
     "shell.execute_reply": "2023-05-02T20:59:47.880946Z",
     "shell.execute_reply.started": "2023-05-02T20:59:47.096493Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Neymar', (24, 120)), ('Ronaldo', (32, 80)), ('Messi', (34, 100))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD1 = sc.parallelize([(\"Messi\", 34),(\"Ronaldo\", 32),(\"Neymar\", 24)])\n",
    "RDD2 = sc.parallelize([(\"Ronaldo\", 80),(\"Neymar\", 120),(\"Messi\", 100)])\n",
    "RDD1.join(RDD2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e668a-0f91-40e2-9b0b-95d33a00aac5",
   "metadata": {},
   "source": [
    "# ReduceBykey and Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69c47c42-89d1-454b-8198-d6715e811e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:47.881943Z",
     "iopub.status.busy": "2023-05-02T20:59:47.881795Z",
     "iopub.status.idle": "2023-05-02T20:59:48.139320Z",
     "shell.execute_reply": "2023-05-02T20:59:48.138842Z",
     "shell.execute_reply.started": "2023-05-02T20:59:47.881928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 1 has 2 Counts\n",
      "Key 3 has 10 Counts\n",
      "Key 4 has 5 Counts\n"
     ]
    }
   ],
   "source": [
    "# Create PairRDD Rdd with key value pairs\n",
    "Rdd = sc.parallelize([(1,2),(3,4),(3,6),(4,5)])\n",
    "# Apply reduceByKey() operation on Rdd\n",
    "Rdd_Reduced = Rdd.reduceByKey(lambda x, y: x + y)\n",
    "# Iterate over the result and print the output\n",
    "for num in Rdd_Reduced.collect():\n",
    "    print(\"Key {} has {} Counts\".format(num[0], num[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725dd208-6d64-44bc-8ae7-c41c7ad36edc",
   "metadata": {},
   "source": [
    "# SortByKey and Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d764c245-3056-468b-9fed-58aa26ec6d7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:48.139933Z",
     "iopub.status.busy": "2023-05-02T20:59:48.139795Z",
     "iopub.status.idle": "2023-05-02T20:59:48.646123Z",
     "shell.execute_reply": "2023-05-02T20:59:48.645715Z",
     "shell.execute_reply.started": "2023-05-02T20:59:48.139920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 4 has 5 Counts\n",
      "Key 3 has 10 Counts\n",
      "Key 1 has 2 Counts\n"
     ]
    }
   ],
   "source": [
    "# Sort the reduced RDD with the key by descending order\n",
    "Rdd_Reduced_Sort = Rdd_Reduced.sortByKey(ascending=False)\n",
    "# Iterate over the result and retrieve all the elements of the RDD\n",
    "for num in Rdd_Reduced_Sort.collect():\n",
    "    print(\"Key {} has {} Counts\".format(num[0], num[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211e383-7f7c-48f3-8760-75d70bec026b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T20:16:30.775775Z",
     "iopub.status.busy": "2023-03-29T20:16:30.775551Z",
     "iopub.status.idle": "2023-03-29T20:16:30.778120Z",
     "shell.execute_reply": "2023-03-29T20:16:30.777774Z",
     "shell.execute_reply.started": "2023-03-29T20:16:30.775762Z"
    }
   },
   "source": [
    "# reduce() action\n",
    "* reduce(func) action is used for aggregating the elements of a regular RDD\n",
    "* The function should be commutative (changing the order of the operands does not change\n",
    "the result) and associative\n",
    "* An example of reduce() action in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c84e6cb3-6b2e-4d34-9537-c9a3265d8e49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:48.646658Z",
     "iopub.status.busy": "2023-05-02T20:59:48.646547Z",
     "iopub.status.idle": "2023-05-02T20:59:48.768457Z",
     "shell.execute_reply": "2023-05-02T20:59:48.768123Z",
     "shell.execute_reply.started": "2023-05-02T20:59:48.646648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,3,4,6]\n",
    "RDD = sc.parallelize(x)\n",
    "RDD.reduce(lambda x, y : x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e16f383-368d-49c1-8922-cd4c65dd588c",
   "metadata": {},
   "source": [
    "# saveAsTextFile() action\n",
    "saveAsTextFile() action saves RDD into a text file  inside a directory with each partition as\n",
    "a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30fbc826-e175-46ab-8b14-997277f78c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:48.768898Z",
     "iopub.status.busy": "2023-05-02T20:59:48.768788Z",
     "iopub.status.idle": "2023-05-02T20:59:49.170095Z",
     "shell.execute_reply": "2023-05-02T20:59:49.169722Z",
     "shell.execute_reply.started": "2023-05-02T20:59:48.768887Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf tempFile/\n",
    "RDD.saveAsTextFile(\"tempFile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d38b12-90eb-486b-9745-ae07b8acf531",
   "metadata": {},
   "source": [
    "coalesce() method can be used to save RDD as a single text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a92daa5d-8036-40e2-b23d-3f9771704c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:49.170746Z",
     "iopub.status.busy": "2023-05-02T20:59:49.170624Z",
     "iopub.status.idle": "2023-05-02T20:59:49.365008Z",
     "shell.execute_reply": "2023-05-02T20:59:49.364628Z",
     "shell.execute_reply.started": "2023-05-02T20:59:49.170733Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf tempFile2/\n",
    "RDD.coalesce(1).saveAsTextFile(\"tempFile2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8384f-38af-4ce0-8b35-08b0b8929d4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Action Operations on pair RDDs\n",
    "* RDD actions available for PySpark pair RDDs\n",
    "* Pair RDD actions leverage the key-value data\n",
    "* Few examples of pair RDD actions include\n",
    "    * countByKey()\n",
    "    * collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8e9e4-0b3f-47fb-8c34-2cd4f34788ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## countByKey() action\n",
    "* countByKey() only available for type (K, V)\n",
    "* countByKey() action counts the number of elements for each key\n",
    "Example of countByKey() on a simple list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ea8ca66-b732-4cd5-8918-79cc4e09ccab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:49.365627Z",
     "iopub.status.busy": "2023-05-02T20:59:49.365510Z",
     "iopub.status.idle": "2023-05-02T20:59:49.518533Z",
     "shell.execute_reply": "2023-05-02T20:59:49.518190Z",
     "shell.execute_reply.started": "2023-05-02T20:59:49.365615Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 2\n",
      "b 1\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
    "for kee, val in rdd.countByKey().items():\n",
    "    print(kee, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841a20e-b0d0-48f3-8a73-f4757c44940a",
   "metadata": {},
   "source": [
    "> countByKey should only be used on a dataset whose size is small enough to fit in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a038fd-a7a3-44e9-920b-6b0dc7667924",
   "metadata": {},
   "source": [
    "## collectAsMap() action\n",
    "* collectAsMap() return the key-value pairs in the RDD as a dictionary\n",
    "* Example of collectAsMap() on a simple tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26c9745f-142e-41a3-b912-277d5878b191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:49.519085Z",
     "iopub.status.busy": "2023-05-02T20:59:49.518972Z",
     "iopub.status.idle": "2023-05-02T20:59:49.536841Z",
     "shell.execute_reply": "2023-05-02T20:59:49.536445Z",
     "shell.execute_reply.started": "2023-05-02T20:59:49.519074Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 3: 4}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([(1, 2), (3, 4)]).collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f5570-0d12-4608-ab2c-96e4181c23e6",
   "metadata": {},
   "source": [
    "> countByKey should only be used on a dataset whose size is small enough to fit in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db462d7b-57a7-4435-8316-d720e7109d8f",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a4896-6bac-4c8d-8b34-29fa278db7de",
   "metadata": {},
   "source": [
    "## CountingBykeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5085b228-7ebf-4aaa-b490-dcbc8227cf2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:49.537384Z",
     "iopub.status.busy": "2023-05-02T20:59:49.537274Z",
     "iopub.status.idle": "2023-05-02T20:59:49.676123Z",
     "shell.execute_reply": "2023-05-02T20:59:49.675630Z",
     "shell.execute_reply.started": "2023-05-02T20:59:49.537374Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of total is <class 'collections.defaultdict'>\n",
      "key 1 has 1 counts\n",
      "key 3 has 2 counts\n",
      "key 4 has 1 counts\n"
     ]
    }
   ],
   "source": [
    "# Count the unique keys\n",
    "total = Rdd.countByKey()\n",
    "# What is the type of total?\n",
    "print(\"The type of total is\", type(total))\n",
    "# Iterate over the total and print the output\n",
    "for k, v in total.items():\n",
    "    print(\"key\", k, \"has\", v, \"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86c5e1cb-df00-4336-baaf-4f1a05702b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:49.676904Z",
     "iopub.status.busy": "2023-05-02T20:59:49.676646Z",
     "iopub.status.idle": "2023-05-02T20:59:49.679725Z",
     "shell.execute_reply": "2023-05-02T20:59:49.679420Z",
     "shell.execute_reply.started": "2023-05-02T20:59:49.676892Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 3: 2, 4: 1})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37988c86-8406-4876-a4d8-7036b9d658bd",
   "metadata": {},
   "source": [
    "## Create a base RDD and transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30328b77-b443-44b7-ab52-5aa443b50d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:49.680318Z",
     "iopub.status.busy": "2023-05-02T20:59:49.680130Z",
     "iopub.status.idle": "2023-05-02T20:59:49.896657Z",
     "shell.execute_reply": "2023-05-02T20:59:49.896264Z",
     "shell.execute_reply.started": "2023-05-02T20:59:49.680307Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18013 Complete_Shakespeare.txt\n",
      "128576 Complete_Shakespeare.txt\n"
     ]
    }
   ],
   "source": [
    "# lines\n",
    "! wc -l Complete_Shakespeare.txt\n",
    "# words\n",
    "! wc -w Complete_Shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "994dde70-9f51-4e32-a95d-3a6026841d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:49.897266Z",
     "iopub.status.busy": "2023-05-02T20:59:49.897157Z",
     "iopub.status.idle": "2023-05-02T20:59:49.972769Z",
     "shell.execute_reply": "2023-05-02T20:59:49.972403Z",
     "shell.execute_reply.started": "2023-05-02T20:59:49.897254Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18014"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a baseRDD from the file path\n",
    "baseRDD = sc.textFile('Complete_Shakespeare.txt')\n",
    "baseRDD.count() # lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4461924d-16a0-41b8-a9a5-f9af02fb0daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:49.973338Z",
     "iopub.status.busy": "2023-05-02T20:59:49.973227Z",
     "iopub.status.idle": "2023-05-02T20:59:50.025748Z",
     "shell.execute_reply": "2023-05-02T20:59:50.025490Z",
     "shell.execute_reply.started": "2023-05-02T20:59:49.973327Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg EBook of The Complete Works of William Shakespeare, by']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take n lines\n",
    "baseRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14d945a6-8ecc-4433-ba15-70ea5faa03cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:50.026206Z",
     "iopub.status.busy": "2023-05-02T20:59:50.026110Z",
     "iopub.status.idle": "2023-05-02T20:59:50.088749Z",
     "shell.execute_reply": "2023-05-02T20:59:50.088375Z",
     "shell.execute_reply.started": "2023-05-02T20:59:50.026196Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in splitRDD: 128576\n"
     ]
    }
   ],
   "source": [
    "# Split the lines of baseRDD into words\n",
    "splitRDD = baseRDD.flatMap(lambda x: x.split())\n",
    "# Count the total number of words\n",
    "print(\"Total number of words in splitRDD:\", splitRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3c20d02-f449-4875-a919-f7e4f3934e56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:50.089350Z",
     "iopub.status.busy": "2023-05-02T20:59:50.089197Z",
     "iopub.status.idle": "2023-05-02T20:59:50.145139Z",
     "shell.execute_reply": "2023-05-02T20:59:50.144866Z",
     "shell.execute_reply.started": "2023-05-02T20:59:50.089334Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Complete', 'Works', 'of', 'William', 'Shakespeare,', 'by']\n"
     ]
    }
   ],
   "source": [
    "print(splitRDD.take(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9d008-aa73-4533-bee3-ff43dc105cc3",
   "metadata": {},
   "source": [
    "## Remove stop words and reduce the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2a82312-7b0c-49b3-8e3a-a5cba702fc4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:50.145697Z",
     "iopub.status.busy": "2023-05-02T20:59:50.145501Z",
     "iopub.status.idle": "2023-05-02T20:59:50.344285Z",
     "shell.execute_reply": "2023-05-02T20:59:50.344025Z",
     "shell.execute_reply.started": "2023-05-02T20:59:50.145686Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19279"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will', 'just', 'don', 'should', 'now']\n",
    "# Convert the words in lower case and remove stop words from the stop_words curated list\n",
    "splitRDD_no_stop = splitRDD.filter(lambda x: x.lower() not in stop_words)\n",
    "# Create a tuple of the word and 1 \n",
    "splitRDD_no_stop_words = splitRDD_no_stop.map(lambda w: (w, 1))\n",
    "# Count of the number of occurences of each word\n",
    "resultRDD = splitRDD_no_stop_words.reduceByKey(lambda x, y: x + y)\n",
    "resultRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4d5c70d-1942-46da-9172-a04f3483991f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:50.344733Z",
     "iopub.status.busy": "2023-05-02T20:59:50.344637Z",
     "iopub.status.idle": "2023-05-02T20:59:50.400053Z",
     "shell.execute_reply": "2023-05-02T20:59:50.399672Z",
     "shell.execute_reply.started": "2023-05-02T20:59:50.344724Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Project', 9), ('EBook', 1), ('Shakespeare', 12), ('use', 38), ('anyone', 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2514cb-9a0a-44a2-ae2e-86314ee97c0d",
   "metadata": {},
   "source": [
    "# Print word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3e03cb0-4683-468e-9938-0631f3e53122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:50.400563Z",
     "iopub.status.busy": "2023-05-02T20:59:50.400459Z",
     "iopub.status.idle": "2023-05-02T20:59:50.459201Z",
     "shell.execute_reply": "2023-05-02T20:59:50.458781Z",
     "shell.execute_reply.started": "2023-05-02T20:59:50.400553Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Project', 9)\n",
      "('EBook', 1)\n",
      "('Shakespeare', 12)\n",
      "('use', 38)\n",
      "('anyone', 1)\n",
      "('anywhere', 1)\n",
      "('restrictions', 1)\n",
      "('whatsoever.', 1)\n",
      "('may', 162)\n",
      "('it,', 74)\n"
     ]
    }
   ],
   "source": [
    "# Display the first 10 words and their frequencies from the input RDD\n",
    "for word in resultRDD.take(10):\n",
    "\tprint(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff735d24-e80d-48ca-b9bb-3057f352bcbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:50.459728Z",
     "iopub.status.busy": "2023-05-02T20:59:50.459615Z",
     "iopub.status.idle": "2023-05-02T20:59:50.567242Z",
     "shell.execute_reply": "2023-05-02T20:59:50.566761Z",
     "shell.execute_reply.started": "2023-05-02T20:59:50.459718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18013 Complete_Shakespeare.txt\n"
     ]
    }
   ],
   "source": [
    "! wc -l Complete_Shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af9b05c3-9651-4119-81cb-e652bbcb0ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T20:59:50.567839Z",
     "iopub.status.busy": "2023-05-02T20:59:50.567730Z",
     "iopub.status.idle": "2023-05-02T20:59:50.795429Z",
     "shell.execute_reply": "2023-05-02T20:59:50.795080Z",
     "shell.execute_reply.started": "2023-05-02T20:59:50.567829Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('thou', 650)\n",
      "('thy', 574)\n",
      "('shall', 393)\n",
      "('would', 311)\n",
      "('good', 295)\n",
      "('thee', 286)\n",
      "('love', 273)\n",
      "('Enter', 269)\n",
      "(\"th'\", 254)\n",
      "('make', 225)\n"
     ]
    }
   ],
   "source": [
    "# Swap the keys and values from the input RDD\n",
    "resultRDD_swap = resultRDD.map(lambda x: x[::-1])\n",
    "# Sort the keys in descending order\n",
    "resultRDD_swap_sort = resultRDD_swap.sortByKey(ascending=False)\n",
    "# Show the top 10 most frequent words and their frequencies from the sorted RDD\n",
    "for item in resultRDD_swap_sort.take(10):\n",
    "\tprint(item[::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
