{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa96aaf-1fca-4106-b028-90bb77317666",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b553eaf-9829-41f1-b0b9-b57078127e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T22:00:27.923992Z",
     "iopub.status.busy": "2023-07-05T22:00:27.923861Z",
     "iopub.status.idle": "2023-07-05T22:00:30.367040Z",
     "shell.execute_reply": "2023-07-05T22:00:30.365995Z",
     "shell.execute_reply.started": "2023-07-05T22:00:27.923979Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/05 19:00:29 WARN Utils: Your hostname, rig resolves to a loopback address: 127.0.1.1; using 192.168.0.106 instead (on interface enp6s0)\n",
      "23/07/05 19:00:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/05 19:00:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "plt.style.use('dark_background')\n",
    "import sys\n",
    "sys.path.insert(1, '/home/mauricio/code/mcr')\n",
    "from mcr.util import glimpse, plot_value_counts, plot_value_counts_timeseries, missing_report, plot_missing, plot_unique, plot_duplicates, size\n",
    "\n",
    "from pyspark import SparkContext\n",
    "# SparkContext.getOrCreate(conf: Optional[pyspark.conf.SparkConf] = None) -> 'SparkContext'\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# sc.setLogLevel('DEBUG')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').appName('spark_application').getOrCreate()\n",
    "print(spark.version)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385394f5-0e27-4f44-93d6-eae9e366e3ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04096551-2a46-4d1b-b11a-c8aa09944bda",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9ce8e-820c-428c-8c3e-a23b3af43414",
   "metadata": {},
   "source": [
    "### Loading flights data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0941351-f3de-4ca2-aa0d-ec9ea3434588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:11.819647Z",
     "iopub.status.busy": "2023-05-02T22:34:11.819401Z",
     "iopub.status.idle": "2023-05-02T22:34:14.715266Z",
     "shell.execute_reply": "2023-05-02T22:34:14.714756Z",
     "shell.execute_reply.started": "2023-05-02T22:34:11.819635Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contain 275000 records.\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|\n",
      "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| null|\n",
      "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|\n",
      "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "[('mon', 'int'), ('dom', 'int'), ('dow', 'int'), ('carrier', 'string'), ('flight', 'int'), ('org', 'string'), ('mile', 'int'), ('depart', 'double'), ('duration', 'int'), ('delay', 'int')]\n"
     ]
    }
   ],
   "source": [
    "# Read data from CSV file\n",
    "flights = spark.read.csv('flights-larger.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')\n",
    "\n",
    "# Get number of records\n",
    "print(\"The data contain %d records.\" % flights.count())\n",
    "\n",
    "# View the first five records\n",
    "flights.show(5)\n",
    "\n",
    "# Check column data types\n",
    "print(flights.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88c04b6-0b98-4db9-8cd8-87b0cc9329df",
   "metadata": {},
   "source": [
    "### Loading SMS spam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b5de1b-931e-40f7-805f-1e01c2982a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:14.716065Z",
     "iopub.status.busy": "2023-05-02T22:34:14.715854Z",
     "iopub.status.idle": "2023-05-02T22:34:14.737286Z",
     "shell.execute_reply": "2023-05-02T22:34:14.736813Z",
     "shell.execute_reply.started": "2023-05-02T22:34:14.716046Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# Specify column names and types\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"text\", StringType()),\n",
    "    StructField(\"label\", IntegerType())\n",
    "])\n",
    "\n",
    "# Load data from a delimited file\n",
    "sms = spark.read.csv('sms.csv', sep=';', header=False, schema=schema)\n",
    "\n",
    "# Print schema of DataFrame\n",
    "sms.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89718a03-a891-49cb-ac16-b7f907f8da67",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2762cd7-3e0a-47b9-bc49-ed0e600cc7ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4a20b-26a5-41f3-8bb0-ddd49823bb62",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56271104-578f-4310-abb0-71a6caaf8ef9",
   "metadata": {},
   "source": [
    "#### Removing columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974ca1b4-32ab-494c-9441-b10c337d2da8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:14.739028Z",
     "iopub.status.busy": "2023-05-02T22:34:14.738670Z",
     "iopub.status.idle": "2023-05-02T22:34:15.636151Z",
     "shell.execute_reply": "2023-05-02T22:34:15.635815Z",
     "shell.execute_reply.started": "2023-05-02T22:34:14.739013Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flights.count()=275000\n",
      "flights_drop_column.filter('delay IS NULL').count()=16711\n",
      "flights_valid_delay.count()=258289\n",
      "flights_none_missing.count()=258289\n"
     ]
    }
   ],
   "source": [
    "print(f'{flights.count()=}')\n",
    "# Remove the 'flight' column\n",
    "flights_drop_column = flights.drop('flight')\n",
    "\n",
    "# Number of records with missing 'delay' values\n",
    "print(f\"{flights_drop_column.filter('delay IS NULL').count()=}\")\n",
    "\n",
    "# Remove records with missing 'delay' values\n",
    "flights_valid_delay = flights_drop_column.filter('delay IS NOT NULL')\n",
    "print(f'{flights_valid_delay.count()=}')\n",
    "\n",
    "# Remove records with missing values in any column and get the number of remaining rows\n",
    "flights_none_missing = flights_valid_delay.dropna()\n",
    "print(f'{flights_none_missing.count()=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86346949-e9af-43c3-b8a6-26f4fdb79c2e",
   "metadata": {},
   "source": [
    "#### Column manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7d49c5-2949-404f-bdfc-9080e30af980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:15.636694Z",
     "iopub.status.busy": "2023-05-02T22:34:15.636583Z",
     "iopub.status.idle": "2023-05-02T22:34:15.756380Z",
     "shell.execute_reply": "2023-05-02T22:34:15.755842Z",
     "shell.execute_reply.started": "2023-05-02T22:34:15.636683Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+\n",
      "| 10| 10|  1|     OO|  5836|ORD|  8.18|      51|   27| 253.0|    1|\n",
      "|  1|  4|  1|     OO|  5866|ORD|  15.5|     102| null| 750.0| null|\n",
      "| 11| 22|  1|     OO|  6016|ORD|  7.17|     127|  -19|1188.0|    0|\n",
      "|  2| 14|  5|     B6|   199|JFK| 21.17|     365|   60|3618.0|    1|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 12.92|      85|   22| 621.0|    1|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the required function\n",
    "# Convert 'mile' to 'km' and drop 'mile' column (1 mile is equivalent to 1.60934 km)\n",
    "flights_km = flights.withColumn('km', F.round(F.col('mile') * 1.60934, 0)) \\\n",
    "                    .drop('mile')\n",
    "\n",
    "# Create 'label' column indicating whether flight delayed (1) or not (0)\n",
    "flights_km = flights_km.withColumn('label', (F.col('delay') >= 15).cast('integer'))\n",
    "\n",
    "# Check first five records\n",
    "flights_km.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f996ab-2784-47a3-b440-7df09108a5d6",
   "metadata": {},
   "source": [
    "#### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb2f58f-35b6-4efc-bdf4-303c7a5e96ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:15.757482Z",
     "iopub.status.busy": "2023-05-02T22:34:15.756995Z",
     "iopub.status.idle": "2023-05-02T22:34:16.533832Z",
     "shell.execute_reply": "2023-05-02T22:34:16.533395Z",
     "shell.execute_reply.started": "2023-05-02T22:34:15.757443Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+-----------+-------+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|carrier_idx|org_idx|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+-----------+-------+\n",
      "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|        2.0|    0.0|\n",
      "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| null|        2.0|    0.0|\n",
      "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|        2.0|    0.0|\n",
      "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|        4.0|    2.0|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|        3.0|    5.0|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Create an indexer\n",
    "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\n",
    "\n",
    "# Indexer identifies categories in the data\n",
    "indexer_model = indexer.fit(flights)\n",
    "\n",
    "# Indexer creates a new column with numeric index values\n",
    "flights_indexed = indexer_model.transform(flights)\n",
    "\n",
    "# Repeat the process for the other categorical feature\n",
    "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)\n",
    "flights_indexed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c8d36-91f1-411f-9714-9e23ad28da05",
   "metadata": {},
   "source": [
    "#### Assembling columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5abdeef5-a9a0-42cd-873f-bc34566bc906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:16.534684Z",
     "iopub.status.busy": "2023-05-02T22:34:16.534413Z",
     "iopub.status.idle": "2023-05-02T22:34:17.177134Z",
     "shell.execute_reply": "2023-05-02T22:34:17.176809Z",
     "shell.execute_reply.started": "2023-05-02T22:34:16.534666Z"
    }
   },
   "outputs": [],
   "source": [
    "# reproducing previous transformations\n",
    "flights = flights\\\n",
    "    .drop('flight')\\\n",
    "    .filter('delay IS NOT NULL')\\\n",
    "    .dropna()\\\n",
    "    .withColumn('km', F.round(F.col('mile') * 1.60934, 0))\\\n",
    "    .drop('mile')\\\n",
    "    .withColumn('label', (F.col('delay') >= 15).cast('integer'))\n",
    "\n",
    "flights = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\\\n",
    "    .fit(flights)\\\n",
    "    .transform(flights)\n",
    "\n",
    "flights = StringIndexer(inputCol='org', outputCol='org_idx')\\\n",
    "    .fit(flights)\\\n",
    "    .transform(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf68d55d-cbb8-4694-8176-ad8299daddc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:17.177661Z",
     "iopub.status.busy": "2023-05-02T22:34:17.177549Z",
     "iopub.status.idle": "2023-05-02T22:34:17.389925Z",
     "shell.execute_reply": "2023-05-02T22:34:17.389648Z",
     "shell.execute_reply.started": "2023-05-02T22:34:17.177650Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|features                                 |delay|\n",
      "+-----------------------------------------+-----+\n",
      "|[10.0,10.0,1.0,2.0,0.0,253.0,8.18,51.0]  |27   |\n",
      "|[11.0,22.0,1.0,2.0,0.0,1188.0,7.17,127.0]|-19  |\n",
      "|[2.0,14.0,5.0,4.0,2.0,3618.0,21.17,365.0]|60   |\n",
      "|[5.0,25.0,3.0,3.0,5.0,621.0,12.92,85.0]  |22   |\n",
      "|[3.0,28.0,1.0,4.0,3.0,1732.0,13.33,182.0]|70   |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary class\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    'mon',\n",
    "    'dom',\n",
    "    'dow',\n",
    "    'carrier_idx',\n",
    "    'org_idx',\n",
    "    'km',\n",
    "    'depart',\n",
    "    'duration'\n",
    "], outputCol='features')\n",
    "\n",
    "# Consolidate predictor columns\n",
    "flights = assembler.transform(flights)\n",
    "\n",
    "# Check the resulting column\n",
    "flights.select('features', 'delay').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444862d-d915-47c0-965a-c18699ce73f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36246b-826c-49d9-80c8-fabb266c6f55",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a214a-b1db-4473-9104-4ccba6f23430",
   "metadata": {},
   "source": [
    "#### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5cda99-be7f-4589-824f-7e6ea4626c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:17.390681Z",
     "iopub.status.busy": "2023-05-02T22:34:17.390311Z",
     "iopub.status.idle": "2023-05-02T22:34:18.264818Z",
     "shell.execute_reply": "2023-05-02T22:34:18.264557Z",
     "shell.execute_reply.started": "2023-05-02T22:34:17.390667Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8007387074168857"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into training and testing sets in a 80:20 ratio\n",
    "flights_train, flights_test = flights.randomSplit([.8,.2], seed=43)\n",
    "\n",
    "# Check that training set has around 80% of records\n",
    "flights_train.count() / flights.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21980969-7feb-44c0-a4e3-6ccc39420684",
   "metadata": {},
   "source": [
    "#### Build a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "460ef697-6ed4-4028-b1c6-294490a00a76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:18.265345Z",
     "iopub.status.busy": "2023-05-02T22:34:18.265239Z",
     "iopub.status.idle": "2023-05-02T22:34:21.592581Z",
     "shell.execute_reply": "2023-05-02T22:34:21.592229Z",
     "shell.execute_reply.started": "2023-05-02T22:34:18.265334Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------------------------------------+\n",
      "|label|prediction|probability                            |\n",
      "+-----+----------+---------------------------------------+\n",
      "|1    |0.0       |[0.6224005522478212,0.3775994477521788]|\n",
      "|0    |1.0       |[0.3236222942591237,0.6763777057408763]|\n",
      "|1    |0.0       |[0.6224005522478212,0.3775994477521788]|\n",
      "|0    |1.0       |[0.3236222942591237,0.6763777057408763]|\n",
      "|0    |1.0       |[0.3236222942591237,0.6763777057408763]|\n",
      "+-----+----------+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Decision Tree Classifier class\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create a classifier object and fit to the training data\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "prediction = tree_model.transform(flights_test)\n",
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537047b-62f7-4379-8872-de588c6f8fe9",
   "metadata": {},
   "source": [
    "#### Evaluate the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f4608de-0aa3-48ce-ba61-d22ddb7d22fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:21.593099Z",
     "iopub.status.busy": "2023-05-02T22:34:21.592981Z",
     "iopub.status.idle": "2023-05-02T22:34:24.340446Z",
     "shell.execute_reply": "2023-05-02T22:34:24.340125Z",
     "shell.execute_reply.started": "2023-05-02T22:34:21.593087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9934|\n",
      "|    0|       0.0|16558|\n",
      "|    1|       1.0|16210|\n",
      "|    0|       1.0| 8765|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6366798142499077\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "prediction.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94051d20-066e-4b8d-b089-c9835fe7faba",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48806229-86b4-4331-b5e3-a03f5114856a",
   "metadata": {},
   "source": [
    "### Precision and recall\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "$$Recall = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb0ff1-9a1e-4b15-b845-45753aa19e9e",
   "metadata": {},
   "source": [
    "### Weighted metrics\n",
    "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "    evaluator = MulticlassClassificationEvaluator()\n",
    "    evaluator.evaluate(prediction, {evaluator.metricName: 'weightedPrecision'})\n",
    "\n",
    "Other metrics:\n",
    "* weightedRecall\n",
    "* accuracy\n",
    "* f1 - the harmonic mean of precision and recall, which is generally more robust than the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716d094-658e-4fb4-9bfb-8a0d5a83a328",
   "metadata": {},
   "source": [
    "### ROC and AUC\n",
    "ROC = \"Receiver Operating Characteristic\"\n",
    "* TP versus FP\n",
    "* threshold = 0 (top right)\n",
    "* threshold = 1 (bottom left)\n",
    "\n",
    "AUC = \"Area under the curve\"\n",
    "* ideally AUC = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661b220-7a05-4ce3-b48a-6c277e819cb3",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c275bb-91fb-4ab6-bb8c-7b5589fda930",
   "metadata": {},
   "source": [
    "#### Build a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6305fb60-93ec-4136-b7e0-51e8090382e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:24.340937Z",
     "iopub.status.busy": "2023-05-02T22:34:24.340834Z",
     "iopub.status.idle": "2023-05-02T22:34:27.237280Z",
     "shell.execute_reply": "2023-05-02T22:34:27.236911Z",
     "shell.execute_reply.started": "2023-05-02T22:34:24.340926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9499|\n",
      "|    0|       0.0|14779|\n",
      "|    1|       1.0|16645|\n",
      "|    0|       1.0|10544|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the logistic regression class\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create a classifier object and train on training data\n",
    "logistic = LogisticRegression().fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data and show confusion matrix\n",
    "prediction = logistic.transform(flights_test)\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c1fa4-819a-473c-9946-46c4e6fbfb69",
   "metadata": {},
   "source": [
    "#### Evaluate the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "702878ea-f79d-4c9c-a294-2192b5fcde74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:27.238882Z",
     "iopub.status.busy": "2023-05-02T22:34:27.238760Z",
     "iopub.status.idle": "2023-05-02T22:34:28.870525Z",
     "shell.execute_reply": "2023-05-02T22:34:28.870104Z",
     "shell.execute_reply.started": "2023-05-02T22:34:27.238871Z"
    }
   },
   "outputs": [],
   "source": [
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91b2a13-571e-4430-ac80-003f68ef998f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:28.871046Z",
     "iopub.status.busy": "2023-05-02T22:34:28.870939Z",
     "iopub.status.idle": "2023-05-02T22:34:30.378591Z",
     "shell.execute_reply": "2023-05-02T22:34:30.378179Z",
     "shell.execute_reply.started": "2023-05-02T22:34:28.871035Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.61\n",
      "recall    = 0.64\n",
      "accuracy  = 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "accuracy = (TP+TN) / (TP+FP+TN+FN)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}\\naccuracy  = {:.2f}'.format(precision, recall, accuracy))\n",
    "\n",
    "# Find weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "# Find AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(prediction, {binary_evaluator.metricName: 'areaUnderROC'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d86630-f259-44ce-a75d-3fea8a702074",
   "metadata": {},
   "source": [
    "> The weighted precision indicates what proportion of predictions (positive and negative) are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ef724-4732-44b2-a8d4-2b9f6b47b17f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turn Text into Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea345f-2a17-4f53-91eb-c3d5b399c329",
   "metadata": {},
   "source": [
    "### Punctuation, numbers and tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7704ab14-8bd4-45bd-b67a-dbd04122dbc3",
   "metadata": {},
   "source": [
    "Removing punctuation\n",
    "\n",
    "        from pyspark.sql.functions import regexp_replace\n",
    "        # Regular expression (REGEX) to match commas and hyphens\n",
    "        REGEX = '[,\\\\-]'\n",
    "        books = books.withColumn('text', regexp_replace(books.text, REGEX, ' '))\n",
    "\n",
    "Text to tokens\n",
    "\n",
    "    from pyspark.ml.feature import Tokenizer\n",
    "    books = Tokenizer(inputCol=\"text\", outputCol=\"tokens\").transform(books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253748e6-2910-4ae5-a19e-1987be00f2d8",
   "metadata": {},
   "source": [
    "### Stop words, hashing and common words (IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bccd0d-d42b-420a-b3e1-b4b9c01c73e0",
   "metadata": {},
   "source": [
    "What are stop words?\n",
    "\n",
    "    from pyspark.ml.feature import StopWordsRemover\n",
    "    stopwords = StopWordsRemover()\n",
    "    # Take a look at the list of stop words\n",
    "    stopwords.getStopWords()\n",
    "\n",
    "Removing stop words\n",
    "\n",
    "    # Specify the input and output column names\n",
    "    stopwords = stopwords.setInputCol('tokens').setOutputCol('words')\n",
    "    books = stopwords.transform(books)\n",
    "    \n",
    "Feature hashing\n",
    "\n",
    "    from pyspark.ml.feature import HashingTF\n",
    "    hasher = HashingTF(inputCol=\"words\", outputCol=\"hash\", numFeatures=32)\n",
    "    books = hasher.transform(books)\n",
    "\n",
    "Dealing with common words\n",
    "\n",
    "    from pyspark.ml.feature import IDF\n",
    "    books = IDF(inputCol=\"hash\", outputCol=\"features\").fit(books).transform(books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793a4c1-c311-4a17-bf85-65d13484b5a0",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d93e49d-30dd-4126-91db-58aa5328cae1",
   "metadata": {},
   "source": [
    "#### Punctuation, numbers and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff6d07c0-8ac9-45e7-bd3a-75e27137c422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:30.379204Z",
     "iopub.status.busy": "2023-05-02T22:34:30.378999Z",
     "iopub.status.idle": "2023-05-02T22:34:30.496102Z",
     "shell.execute_reply": "2023-05-02T22:34:30.495613Z",
     "shell.execute_reply.started": "2023-05-02T22:34:30.379192Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------+-----+------------------------------------------+\n",
      "|id |text                              |label|words                                     |\n",
      "+---+----------------------------------+-----+------------------------------------------+\n",
      "|1  |Sorry I'll call later in meeting  |0    |[sorry, i'll, call, later, in, meeting]   |\n",
      "|2  |Dont worry I guess he's busy      |0    |[dont, worry, i, guess, he's, busy]       |\n",
      "|3  |Call FREEPHONE now                |1    |[call, freephone, now]                    |\n",
      "|4  |Win a cash prize or a prize worth |1    |[win, a, cash, prize, or, a, prize, worth]|\n",
      "+---+----------------------------------+-----+------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary functions\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "# Remove punctuation (REGEX provided) and numbers\n",
    "wrangled = sms.withColumn('text', regexp_replace(sms.text, '[_():;,.!?\\\\-]', ' '))\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, '\\\\d+', ' '))\n",
    "\n",
    "# Merge multiple spaces\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, ' +', ' '))\n",
    "\n",
    "# Split the text into words\n",
    "wrangled = Tokenizer(inputCol='text', outputCol='words').transform(wrangled)\n",
    "\n",
    "wrangled.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9eb062-4862-4af7-9315-ac244c4b1522",
   "metadata": {},
   "source": [
    "#### Stop words and hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb6294e7-de56-4a23-a8d3-b90007cad436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:30.496852Z",
     "iopub.status.busy": "2023-05-02T22:34:30.496565Z",
     "iopub.status.idle": "2023-05-02T22:34:30.834326Z",
     "shell.execute_reply": "2023-05-02T22:34:30.833909Z",
     "shell.execute_reply.started": "2023-05-02T22:34:30.496839Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|terms                           |features                                                                                            |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|[sorry, call, later, meeting]   |(1024,[138,384,577,996],[2.273418200008753,3.6288353225642043,3.5890949939146903,4.104259019279279])|\n",
      "|[dont, worry, guess, busy]      |(1024,[215,233,276,329],[3.9913186080986836,3.3790235241678332,4.734227298217693,4.58299632849377]) |\n",
      "|[call, freephone]               |(1024,[133,138],[5.367951058306837,2.273418200008753])                                              |\n",
      "|[win, cash, prize, prize, worth]|(1024,[31,47,62,389],[3.6632029660684124,4.754846585420428,4.072170704727778,7.064594791043114])    |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover, HashingTF, IDF\n",
    "\n",
    "# Remove stop words.\n",
    "wrangled = StopWordsRemover(inputCol='words', outputCol='terms')\\\n",
    "      .transform(wrangled)\n",
    "\n",
    "# Apply the hashing trick\n",
    "wrangled = HashingTF(inputCol='terms', outputCol='hash', numFeatures=1024)\\\n",
    "      .transform(wrangled)\n",
    "\n",
    "# Convert hashed symbols to TF-IDF\n",
    "tf_idf = IDF(inputCol='hash', outputCol='features')\\\n",
    "      .fit(wrangled).transform(wrangled)\n",
    "      \n",
    "tf_idf.select('terms', 'features').show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8bc1fa-1c9c-4d97-b70b-d2eff9849a67",
   "metadata": {},
   "source": [
    "#### Train a spam classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56dbac5a-d171-4009-a032-ebca6b8af92c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:30.834860Z",
     "iopub.status.busy": "2023-05-02T22:34:30.834743Z",
     "iopub.status.idle": "2023-05-02T22:34:31.742286Z",
     "shell.execute_reply": "2023-05-02T22:34:31.741715Z",
     "shell.execute_reply.started": "2023-05-02T22:34:30.834848Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|   39|\n",
      "|    0|       0.0|  932|\n",
      "|    1|       1.0|  121|\n",
      "|    0|       1.0|    4|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms = tf_idf.select('label', 'features')\n",
    "# Split the data into training and testing sets\n",
    "sms_train, sms_test = sms.randomSplit([.8, .2], seed=13)\n",
    "\n",
    "# Fit a Logistic Regression model to the training data\n",
    "logistic = LogisticRegression(regParam=0.2).fit(sms_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "prediction = logistic.transform(sms_test)\n",
    "\n",
    "# Create a confusion matrix, comparing predictions to known labels\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ac755cf-586b-42fd-9232-aaafad463cba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:31.743042Z",
     "iopub.status.busy": "2023-05-02T22:34:31.742869Z",
     "iopub.status.idle": "2023-05-02T22:34:32.454368Z",
     "shell.execute_reply": "2023-05-02T22:34:32.453828Z",
     "shell.execute_reply.started": "2023-05-02T22:34:31.743023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.97\n",
      "recall    = 0.76\n",
      "accuracy  = 0.96\n"
     ]
    }
   ],
   "source": [
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "accuracy = (TP+TN) / (TP+FP+TN+FN)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}\\naccuracy  = {:.2f}'.format(precision, recall, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba9bd2e-b097-4397-ba5e-f01692e1f18c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1bf077-7ce9-4f45-95a5-db10a88f194b",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d08f1-c9c2-4afc-94cc-0eaa558ed2d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dense versus sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb36a856-0f7e-467a-8de6-df99507291b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:32.454921Z",
     "iopub.status.busy": "2023-05-02T22:34:32.454813Z",
     "iopub.status.idle": "2023-05-02T22:34:32.456999Z",
     "shell.execute_reply": "2023-05-02T22:34:32.456648Z",
     "shell.execute_reply.started": "2023-05-02T22:34:32.454910Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseVector, SparseVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f92b5c-94f7-4a81-ac21-6e83d5486f0d",
   "metadata": {},
   "source": [
    "Store this vector as Dense: [1, 0, 0, 0, 0, 7, 0, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f20e815a-c3eb-4a83-9590-344489683f7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:32.457450Z",
     "iopub.status.busy": "2023-05-02T22:34:32.457351Z",
     "iopub.status.idle": "2023-05-02T22:34:32.459847Z",
     "shell.execute_reply": "2023-05-02T22:34:32.459604Z",
     "shell.execute_reply.started": "2023-05-02T22:34:32.457440Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DenseVector([1, 0, 0, 0, 0, 7, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6575cf-a70c-44c1-bb3d-8134fbe55df9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T16:47:54.816739Z",
     "iopub.status.busy": "2023-04-11T16:47:54.816589Z",
     "iopub.status.idle": "2023-04-11T16:47:54.819978Z",
     "shell.execute_reply": "2023-04-11T16:47:54.819640Z",
     "shell.execute_reply.started": "2023-04-11T16:47:54.816727Z"
    }
   },
   "source": [
    "Store same vector as Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0d17209-e14d-40fe-84de-73431e50c81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:32.460368Z",
     "iopub.status.busy": "2023-05-02T22:34:32.460188Z",
     "iopub.status.idle": "2023-05-02T22:34:32.462540Z",
     "shell.execute_reply": "2023-05-02T22:34:32.462270Z",
     "shell.execute_reply.started": "2023-05-02T22:34:32.460357Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(8, {0: 1.0, 5: 7.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparseVector(8, [0, 5], [1, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b1c01ce-9298-4d6f-ada4-c576eaa3ec63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:32.463120Z",
     "iopub.status.busy": "2023-05-02T22:34:32.462897Z",
     "iopub.status.idle": "2023-05-02T22:34:32.465490Z",
     "shell.execute_reply": "2023-05-02T22:34:32.465237Z",
     "shell.execute_reply.started": "2023-05-02T22:34:32.463110Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DenseVector([1, 0, 0, 0, 0, 7, 0, 0]) == SparseVector(8, [0, 5], [1, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745652c-a515-42fc-8507-9bebe3db7149",
   "metadata": {},
   "source": [
    "> **Sparse representation is essential for effective one-hot encoding on large data sets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b0a2a-f629-4723-895a-b2493fffb7cc",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ed159-6c34-4771-a9c1-43ca2f94f026",
   "metadata": {},
   "source": [
    "#### Encoding flight origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9bbf9dd-2b69-4997-befe-456480688500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:32.465953Z",
     "iopub.status.busy": "2023-05-02T22:34:32.465854Z",
     "iopub.status.idle": "2023-05-02T22:34:32.829957Z",
     "shell.execute_reply": "2023-05-02T22:34:32.829660Z",
     "shell.execute_reply.started": "2023-05-02T22:34:32.465943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------+-----+\n",
      "|org|org_idx|    org_dummy|count|\n",
      "+---+-------+-------------+-----+\n",
      "|ORD|    0.0|(7,[0],[1.0])|98251|\n",
      "|SFO|    1.0|(7,[1],[1.0])|50011|\n",
      "|JFK|    2.0|(7,[2],[1.0])|41068|\n",
      "|LGA|    3.0|(7,[3],[1.0])|25180|\n",
      "|SMF|    4.0|(7,[4],[1.0])|16381|\n",
      "|SJC|    5.0|(7,[5],[1.0])|16068|\n",
      "|TUS|    6.0|(7,[6],[1.0])| 6025|\n",
      "|OGG|    7.0|    (7,[],[])| 5305|\n",
      "+---+-------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the one hot encoder class\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "# Create an instance of the one hot encoder\n",
    "onehot = OneHotEncoder(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
    "\n",
    "# Apply the one hot encoder to the flights data\n",
    "onehot = onehot.fit(flights)\n",
    "flights_onehot = onehot.transform(flights)\n",
    "\n",
    "# Check the results\n",
    "flights_onehot.groupBy('org', 'org_idx', 'org_dummy').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b27cd-f304-4508-941c-1edc4aadad10",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ea0e2-1333-4241-8283-3a2a2d4f89b5",
   "metadata": {},
   "source": [
    "### Calculate RMSE\n",
    "        from pyspark.ml.evaluation import RegressionEvaluator\n",
    "        # Find RMSE (Root Mean Squared Error)\n",
    "        RegressionEvaluator(labelCol='consumption').evaluate(predictions)\n",
    "        0.708699086182001\n",
    "A RegressionEvaluator can also calculate the following metrics:\n",
    "* mae (Mean Absolute Error)\n",
    "* r2 (R )\n",
    "* mse (Mean Squared Error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087559a-3223-43de-b8fe-a2c062f0d7c5",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625e000-6981-4958-b49b-969e033013d4",
   "metadata": {},
   "source": [
    "#### Flight duration model: Just distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8738cc37-4e95-4020-8027-8a433f53d249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:32.830597Z",
     "iopub.status.busy": "2023-05-02T22:34:32.830438Z",
     "iopub.status.idle": "2023-05-02T22:34:32.854498Z",
     "shell.execute_reply": "2023-05-02T22:34:32.854067Z",
     "shell.execute_reply.started": "2023-05-02T22:34:32.830581Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=['km'], outputCol='features')\n",
    "# Consolidate predictor columns\n",
    "flights = assembler.transform(flights.drop('features'))\n",
    "flights_train, flights_test = flights.randomSplit([.8,.2], seed=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7553843f-9ac4-4880-91eb-db432fee105f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:32.855047Z",
     "iopub.status.busy": "2023-05-02T22:34:32.854940Z",
     "iopub.status.idle": "2023-05-02T22:34:34.841141Z",
     "shell.execute_reply": "2023-05-02T22:34:34.840859Z",
     "shell.execute_reply.started": "2023-05-02T22:34:32.855037Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 19:34:32 WARN Instrumentation: [807997f2] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|duration|prediction        |\n",
      "+--------+------------------+\n",
      "|230     |238.6544157338315 |\n",
      "|379     |345.6385472841618 |\n",
      "|240     |213.2901665693866 |\n",
      "|255     |213.2901665693866 |\n",
      "|170     |152.11311186827768|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.062726863631564"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a regression object and train on training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "predictions = regression.transform(flights_test)\n",
    "predictions.select('duration', 'prediction').show(5, False)\n",
    "\n",
    "# Calculate the RMSE\n",
    "RegressionEvaluator(labelCol='duration').evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0959993f-5756-45b7-bce9-e22a052b3544",
   "metadata": {},
   "source": [
    "#### Interpreting the coefficients\n",
    "\n",
    "The linear regression model for flight duration as a function of distance takes the form\n",
    "\n",
    "$duration = \\alpha + \\beta \\times distance$\n",
    "\n",
    "where\n",
    "\n",
    "* $\\alpha$ — intercept (component of duration which does not depend on distance) and\n",
    "* $\\beta$ — coefficient (rate at which duration increases as a function of distance; also called the slope).\n",
    "\n",
    "By looking at the coefficients of your model you will be able to infer\n",
    "\n",
    "* how much of the average flight duration is actually spent on the ground and\n",
    "* what the average speed is during a flight.\n",
    "\n",
    "Instructions\n",
    "\n",
    "* What's the intercept?\n",
    "* What are the coefficients? This is a vector.\n",
    "* Extract the element from the vector which corresponds to the slope for distance.\n",
    "* Find the average speed in km per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b983ebd0-1b98-47b4-9e98-159edb9e3066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:34.841732Z",
     "iopub.status.busy": "2023-05-02T22:34:34.841579Z",
     "iopub.status.idle": "2023-05-02T22:34:34.852906Z",
     "shell.execute_reply": "2023-05-02T22:34:34.852615Z",
     "shell.execute_reply.started": "2023-05-02T22:34:34.841716Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average flight duration (minutes) spent on the ground, i.e., when distance is 0 km:\n",
      "\tThe intercept=44.1 (minutes) is the component of duration (minutes) independent on distance (km)\n",
      "\n",
      "The distance coefficient is the rate at which duration (minutes) increases as function of distance:\n",
      "\tThe coefficient=0.0757 is the component of duration (minutes) for each distance unit (km)\n",
      "\tThe coefficient=0.0757 is the average minutes per kilometer\n",
      "\tThe average speed (km/minute) is 1/coefficient=13.2076\n",
      "\tThe average speed (km/hour) is 60/coefficient=792.4540\n"
     ]
    }
   ],
   "source": [
    "# Intercept (average minutes on ground)\n",
    "intercept = regression.intercept\n",
    "print('The average flight duration (minutes) spent on the ground, i.e., when distance is 0 km:')\n",
    "print(f'\\tThe {intercept=:.1f} (minutes) is the component of duration (minutes) independent on distance (km)')\n",
    "print()\n",
    "\n",
    "# Coefficients\n",
    "coefficient = regression.coefficients[0]\n",
    "print('The distance coefficient is the rate at which duration (minutes) increases as function of distance:')\n",
    "print(f'\\tThe {coefficient=:.4f} is the component of duration (minutes) for each distance unit (km)')\n",
    "print(f'\\tThe {coefficient=:.4f} is the average minutes per kilometer')\n",
    "print(f'\\tThe average speed (km/minute) is {1/coefficient=:.4f}')\n",
    "print(f'\\tThe average speed (km/hour) is {60/coefficient=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b3ab88-8579-41ca-8da1-c1e705279135",
   "metadata": {},
   "source": [
    "> **The average speed of a commercial jet is around 850 km/hour. But you got that already from the data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5090e703-c229-44f4-8bd8-0b4c317db587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:34.853506Z",
     "iopub.status.busy": "2023-05-02T22:34:34.853359Z",
     "iopub.status.idle": "2023-05-02T22:34:35.127398Z",
     "shell.execute_reply": "2023-05-02T22:34:35.126891Z",
     "shell.execute_reply.started": "2023-05-02T22:34:34.853490Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+\n",
      "|summary|(km / (duration / 60))|\n",
      "+-------+----------------------+\n",
      "|  count|                258289|\n",
      "|   mean|     501.3299838474135|\n",
      "| stddev|    143.79012533366503|\n",
      "|    min|                  18.0|\n",
      "|    max|     911.1864406779662|\n",
      "+-------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Really?\n",
    "flights.selectExpr('km / (duration/60)').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3652da8-7f0e-4e52-b6cf-cddc022dd678",
   "metadata": {},
   "source": [
    "#### Flight duration model: Adding origin airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31e73bb7-5453-4672-8e56-5d3c2f6e0efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:35.128390Z",
     "iopub.status.busy": "2023-05-02T22:34:35.128032Z",
     "iopub.status.idle": "2023-05-02T22:34:35.179883Z",
     "shell.execute_reply": "2023-05-02T22:34:35.179455Z",
     "shell.execute_reply.started": "2023-05-02T22:34:35.128369Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|km    |label|carrier_idx|org_idx|features|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------+\n",
      "|10 |10 |1  |OO     |ORD|8.18  |51      |27   |253.0 |1    |2.0        |0.0    |[253.0] |\n",
      "|11 |22 |1  |OO     |ORD|7.17  |127     |-19  |1188.0|0    |2.0        |0.0    |[1188.0]|\n",
      "|2  |14 |5  |B6     |JFK|21.17 |365     |60   |3618.0|1    |4.0        |2.0    |[3618.0]|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b2d42b8-342f-49f3-801c-299472f4a479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:35.180773Z",
     "iopub.status.busy": "2023-05-02T22:34:35.180462Z",
     "iopub.status.idle": "2023-05-02T22:34:35.231268Z",
     "shell.execute_reply": "2023-05-02T22:34:35.230739Z",
     "shell.execute_reply.started": "2023-05-02T22:34:35.180754Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of the one hot encoder\n",
    "onehot = OneHotEncoder(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
    "# Apply the one hot encoder to the flights data\n",
    "onehot = onehot.fit(flights)\n",
    "flights = onehot.transform(flights)\n",
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy'], outputCol='features')\n",
    "# Consolidate predictor columns\n",
    "flights = assembler.transform(flights.drop('features'))\n",
    "flights_train, flights_test = flights.randomSplit([.8,.2], seed=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62669086-8498-41ab-ac99-d25b9570db67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:35.232327Z",
     "iopub.status.busy": "2023-05-02T22:34:35.231871Z",
     "iopub.status.idle": "2023-05-02T22:34:36.885366Z",
     "shell.execute_reply": "2023-05-02T22:34:36.885033Z",
     "shell.execute_reply.started": "2023-05-02T22:34:35.232309Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 19:34:35 WARN Instrumentation: [e6e74c38] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.01952980081567"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a regression object and train on training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data\n",
    "predictions = regression.transform(flights_test)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "RegressionEvaluator(labelCol='duration').evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05ba2f-0ae2-4d70-8712-0c243ba76b7b",
   "metadata": {},
   "source": [
    "#### Interpreting coefficients\n",
    "\n",
    "Remember that origin airport, org, has eight possible values (ORD, SFO, JFK, LGA, SMF, SJC, TUS and OGG) which have been one-hot encoded to seven dummy variables in org_dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90686178-8dc5-4c0f-9679-84094e891e4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:36.885895Z",
     "iopub.status.busy": "2023-05-02T22:34:36.885775Z",
     "iopub.status.idle": "2023-05-02T22:34:37.127007Z",
     "shell.execute_reply": "2023-05-02T22:34:37.126733Z",
     "shell.execute_reply.started": "2023-05-02T22:34:36.885883Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------+-----+\n",
      "|org|org_idx|    org_dummy|count|\n",
      "+---+-------+-------------+-----+\n",
      "|ORD|    0.0|(7,[0],[1.0])|98251|\n",
      "|SFO|    1.0|(7,[1],[1.0])|50011|\n",
      "|JFK|    2.0|(7,[2],[1.0])|41068|\n",
      "|LGA|    3.0|(7,[3],[1.0])|25180|\n",
      "|SMF|    4.0|(7,[4],[1.0])|16381|\n",
      "|SJC|    5.0|(7,[5],[1.0])|16068|\n",
      "|TUS|    6.0|(7,[6],[1.0])| 6025|\n",
      "|OGG|    7.0|    (7,[],[])| 5305|\n",
      "+---+-------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.groupby('org', 'org_idx', 'org_dummy').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb95064-b7f9-43ff-8bc1-9e20977dae20",
   "metadata": {},
   "source": [
    "The values for km and org_dummy have been assembled into features, which has eight columns with sparse representation. Column indices in features are as follows:\n",
    "\n",
    "        0 — km\n",
    "        1 — ORD\n",
    "        2 — SFO\n",
    "        3 — JFK\n",
    "        4 — LGA\n",
    "        5 — SMF\n",
    "        6 — SJC and\n",
    "        7 — TUS.\n",
    "\n",
    "Note that OGG does not appear in this list because it is the reference level for the origin airport category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6235c61-19f7-402b-81a9-6c5033a5f4e4",
   "metadata": {},
   "source": [
    "In this exercise you'll be using the intercept and coefficients attributes to interpret the model.\n",
    "\n",
    "The coefficients attribute is a list, where the first element indicates how flight duration changes with flight distance.\n",
    "\n",
    "Instructions\n",
    "\n",
    "* Find the average speed in km per hour. This will be different to the value that you got earlier because your model is now more sophisticated.\n",
    "* What's the average time on the ground at OGG?\n",
    "* What's the average time on the ground at JFK?\n",
    "* What's the average time on the ground at LGA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63398422-6ae5-4f9b-9dcf-35ea8206f248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:37.127483Z",
     "iopub.status.busy": "2023-05-02T22:34:37.127380Z",
     "iopub.status.idle": "2023-05-02T22:34:37.134043Z",
     "shell.execute_reply": "2023-05-02T22:34:37.133781Z",
     "shell.execute_reply.started": "2023-05-02T22:34:37.127473Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average speed in km per hour:\n",
      "\t(60 / regression.coefficients[0])=807.7485822157474\n",
      "Average minutes on ground at OGG (reference level):\n",
      "\tregression.intercept=15.895921738780528\n",
      "Average minutes on ground at JFK:\n",
      "\t(intercept + regression.coefficients[3])=96.6527776065116\n",
      "Average minutes on ground at LGA:\n",
      "\t(intercept + regression.coefficients[4])=90.86860944814529\n"
     ]
    }
   ],
   "source": [
    "# Average speed in km per hour\n",
    "print(f'Average speed in km per hour:\\n\\t{(60 / regression.coefficients[0])=}')\n",
    "\n",
    "# Average minutes on ground at OGG\n",
    "print(f'Average minutes on ground at OGG (reference level):\\n\\t{regression.intercept=}')\n",
    "\n",
    "# Average minutes on ground at JFK\n",
    "avg_ground_jfk = intercept + regression.coefficients[3]\n",
    "print(f'Average minutes on ground at JFK:\\n\\t{(intercept + regression.coefficients[3])=}')\n",
    "\n",
    "# Average minutes on ground at LGA\n",
    "print(f'Average minutes on ground at LGA:\\n\\t{(intercept + regression.coefficients[4])=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2399ec17-e25a-474b-9f4e-df49edd72cfc",
   "metadata": {},
   "source": [
    "> **You're going to spend over an hour on the ground at JFK or LGA but only around 15 minutes at OGG.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a47f6-6cb6-4957-a74e-3e246030eab2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bucketing & Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5990e4e-adb9-4f99-92dc-8378d9859e06",
   "metadata": {},
   "source": [
    "### More feature engineering\n",
    "Operations on a single column:\n",
    "* log()\n",
    "* sqrt()\n",
    "* pow()\n",
    "\n",
    "Operations on two columns:\n",
    "* product\n",
    "* ratio.\n",
    "\n",
    "Examples:\n",
    "* Mass & Height to BIM: $bmi = mass \\div height^2$\n",
    "* Linear density: $linear\\_density = mass \\div length$\n",
    "* Area density: $area_density = mass \\div length^2$\n",
    "* Volume density: $volume_density = mass \\div length^3$\n",
    "\n",
    "> Since you only have the length of the vehicles but not their width or height, the length is being used as a proxy for these missing dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c014c36-bb68-4f71-b3a5-45a6fb82a5b3",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f52ecd-44aa-4a1f-9e02-e4839bb30cea",
   "metadata": {},
   "source": [
    "#### Bucket departure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a123baf1-67bd-4a4c-a282-238c2066553d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:37.134512Z",
     "iopub.status.busy": "2023-05-02T22:34:37.134405Z",
     "iopub.status.idle": "2023-05-02T22:34:37.478017Z",
     "shell.execute_reply": "2023-05-02T22:34:37.477542Z",
     "shell.execute_reply.started": "2023-05-02T22:34:37.134501Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|depart_bucket|count|\n",
      "+-------------+-----+\n",
      "|          0.0|  198|\n",
      "|          1.0|  694|\n",
      "|          2.0|45274|\n",
      "|          3.0|48280|\n",
      "|          4.0|48838|\n",
      "|          5.0|48689|\n",
      "|          6.0|48401|\n",
      "|          7.0|17915|\n",
      "+-------------+-----+\n",
      "\n",
      "+------+-------------+-------------+\n",
      "|depart|depart_bucket| depart_dummy|\n",
      "+------+-------------+-------------+\n",
      "|  8.18|          2.0|(7,[2],[1.0])|\n",
      "|  7.17|          2.0|(7,[2],[1.0])|\n",
      "| 21.17|          7.0|    (7,[],[])|\n",
      "| 12.92|          4.0|(7,[4],[1.0])|\n",
      "| 13.33|          4.0|(7,[4],[1.0])|\n",
      "+------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer, OneHotEncoder\n",
    "\n",
    "# Create buckets at 3 hour intervals through the day\n",
    "buckets = Bucketizer(splits=np.linspace(0,24,9), inputCol='depart', outputCol='depart_bucket')\n",
    "\n",
    "# Bucket the departure times\n",
    "flights = buckets.transform(flights)\n",
    "flights.groupby('depart_bucket').count().orderBy('depart_bucket').show()\n",
    "\n",
    "# Create a one-hot encoder\n",
    "onehot = OneHotEncoder(inputCol='depart_bucket', outputCol='depart_dummy')\n",
    "\n",
    "# One-hot encode the bucketed departure times\n",
    "flights = onehot.fit(flights).transform(flights)\n",
    "flights.select('depart', 'depart_bucket', 'depart_dummy').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560e565-5b58-4d93-a84f-da8448b601e1",
   "metadata": {},
   "source": [
    "#### Fligh duration model: Adding departure time\n",
    "\n",
    "In the previous exercise the departure time was bucketed and converted to dummy variables. Now you're going to include those dummy variables in a regression model for flight duration.\n",
    "\n",
    "The data are in flights. The km, org_dummy and depart_dummy columns have been assembled into features, where km is index 0, org_dummy runs from index 1 to 7 and depart_dummy from index 8 to 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "121e75db-87f0-4ae6-84bc-d7eb5417fd88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:37.478591Z",
     "iopub.status.busy": "2023-05-02T22:34:37.478482Z",
     "iopub.status.idle": "2023-05-02T22:34:37.543474Z",
     "shell.execute_reply": "2023-05-02T22:34:37.543157Z",
     "shell.execute_reply.started": "2023-05-02T22:34:37.478580Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-------------+------------------------------+\n",
      "|km    |org_dummy    |depart_dummy |features                      |\n",
      "+------+-------------+-------------+------------------------------+\n",
      "|253.0 |(7,[0],[1.0])|(7,[2],[1.0])|(15,[0,1,10],[253.0,1.0,1.0]) |\n",
      "|1188.0|(7,[0],[1.0])|(7,[2],[1.0])|(15,[0,1,10],[1188.0,1.0,1.0])|\n",
      "|3618.0|(7,[2],[1.0])|(7,[],[])    |(15,[0,3],[3618.0,1.0])       |\n",
      "|621.0 |(7,[5],[1.0])|(7,[4],[1.0])|(15,[0,6,12],[621.0,1.0,1.0]) |\n",
      "|1732.0|(7,[3],[1.0])|(7,[4],[1.0])|(15,[0,4,12],[1732.0,1.0,1.0])|\n",
      "+------+-------------+-------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'depart_dummy'], outputCol='features')\n",
    "# Consolidate predictor columns\n",
    "flights = assembler.transform(flights.drop('features'))\n",
    "flights[['km', 'org_dummy', 'depart_dummy', 'features']].show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1276962-cdc7-4006-a578-8c21d69b4d98",
   "metadata": {},
   "source": [
    "The data have been split into training and testing sets and a linear regression model, regression, has been built on the training data. Predictions have been made on the testing data and are available as predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e99a4e2-4aa3-497d-a066-d608c5600665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:37.543984Z",
     "iopub.status.busy": "2023-05-02T22:34:37.543877Z",
     "iopub.status.idle": "2023-05-02T22:34:38.804403Z",
     "shell.execute_reply": "2023-05-02T22:34:38.803994Z",
     "shell.execute_reply.started": "2023-05-02T22:34:37.543973Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 19:34:37 WARN Instrumentation: [e9f051ae] regParam is zero, which might cause numerical instability and overfitting.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flights_train, flights_test = flights.randomSplit([.8,.2], seed=43)\n",
    "# Create a regression object and train on training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "# Create predictions for the testing data\n",
    "predictions = regression.transform(flights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5627ff-78bd-44db-b08c-4c878902eedf",
   "metadata": {},
   "source": [
    "Instructions\n",
    "\n",
    "* Find the RMSE for predictions on the testing data.\n",
    "* Find the average time spent on the ground for flights departing from OGG (org reference level) between 21:00 and 24:00 (depart reference level).\n",
    "* Find the average time spent on the ground for flights departing from OGG (reference level) between 03:00 and 06:00.\n",
    "* Find the average time spent on the ground for flights departing from JFK (between 03:00 and 06:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75b8b0b6-9152-4ae1-a5f6-e3e0146db1cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:38.804881Z",
     "iopub.status.busy": "2023-05-02T22:34:38.804783Z",
     "iopub.status.idle": "2023-05-02T22:34:38.882872Z",
     "shell.execute_reply": "2023-05-02T22:34:38.882409Z",
     "shell.execute_reply.started": "2023-05-02T22:34:38.804871Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+------+------------+----------------+\n",
      "|km   |org|org_dummy|depart|depart_dummy|features        |\n",
      "+-----+---+---------+------+------------+----------------+\n",
      "|161.0|OGG|(7,[],[])|21.0  |(7,[],[])   |(15,[0],[161.0])|\n",
      "+-----+---+---------+------+------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# both OFF and 21-24h are references levels\n",
    "flights.select('km', 'org', 'org_dummy', 'depart', 'depart_dummy', 'features').where('org = \"OGG\" AND depart >=21 and depart<24').show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0559d2e7-c325-4e2f-ba4f-3ddd4d677879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:38.883559Z",
     "iopub.status.busy": "2023-05-02T22:34:38.883406Z",
     "iopub.status.idle": "2023-05-02T22:34:39.532245Z",
     "shell.execute_reply": "2023-05-02T22:34:39.531831Z",
     "shell.execute_reply.started": "2023-05-02T22:34:38.883543Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+------+------------+--------+\n",
      "|km |org|org_dummy|depart|depart_dummy|features|\n",
      "+---+---+---------+------+------------+--------+\n",
      "+---+---+---------+------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.select('km', 'org', 'org_dummy', 'depart', 'depart_dummy', 'features').where('org = \"OGG\" AND depart >=3 and depart <6').show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e18a58a-710a-4061-961d-807c2e5f8b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:39.532755Z",
     "iopub.status.busy": "2023-05-02T22:34:39.532650Z",
     "iopub.status.idle": "2023-05-02T22:34:39.610504Z",
     "shell.execute_reply": "2023-05-02T22:34:39.610025Z",
     "shell.execute_reply.started": "2023-05-02T22:34:39.532745Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-------------+------+-------------+-----------------------------+\n",
      "|km    |org|org_dummy    |depart|depart_dummy |features                     |\n",
      "+------+---+-------------+------+-------------+-----------------------------+\n",
      "|1754.0|JFK|(7,[2],[1.0])|5.75  |(7,[1],[1.0])|(15,[0,3,9],[1754.0,1.0,1.0])|\n",
      "+------+---+-------------+------+-------------+-----------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.select('km', 'org', 'org_dummy', 'depart', 'depart_dummy', 'features').where('org = \"JFK\" AND depart >=3 and depart<6').show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89d50bb7-7618-4af0-93f6-85780256b27e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:39.611134Z",
     "iopub.status.busy": "2023-05-02T22:34:39.610977Z",
     "iopub.status.idle": "2023-05-02T22:34:40.159202Z",
     "shell.execute_reply": "2023-05-02T22:34:40.158782Z",
     "shell.execute_reply.started": "2023-05-02T22:34:39.611118Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 10.688463762040891\n",
      "10.154076497469674\n",
      "10.65109471840926\n",
      "62.49567196984156\n"
     ]
    }
   ],
   "source": [
    "# Find the RMSE on testing data\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "rmse = RegressionEvaluator(labelCol='duration').evaluate(predictions)\n",
    "print(\"The test RMSE is\", rmse)\n",
    "\n",
    "# Average minutes on ground at OGG for flights departing between 21:00 and 24:00\n",
    "avg_eve_ogg = regression.intercept\n",
    "print(avg_eve_ogg)\n",
    "\n",
    "# Average minutes on ground at OGG for flights departing between 03:00 and 06:00\n",
    "avg_night_ogg = regression.intercept + regression.coefficients[9]\n",
    "print(avg_night_ogg)\n",
    "\n",
    "# Average minutes on ground at JFK for flights departing between 03:00 and 06:00\n",
    "avg_night_jfk = regression.intercept + regression.coefficients[3] + regression.coefficients[9]\n",
    "print(avg_night_jfk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e26e5-83ec-4ac9-9a64-286e85ddc64f",
   "metadata": {},
   "source": [
    ">**Adding departure time resulted in a smaller RMSE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dafb69-1973-4ef7-aac0-c0d8b3470f0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451aaa28-579b-416b-b75d-45d39546fba4",
   "metadata": {},
   "source": [
    "### Loss function (revisited)\n",
    "Linear regression aims to minimise the MSE.\n",
    "$$MSE = \\frac{1}{N} \\sum_{i=1}^{N} \\left(y_i - \\hat{y_i}\\right)^2$$\n",
    "\n",
    "In this lesson we'll be exploring one such approach to feature selection known as \"penalized regression\".\n",
    "\n",
    "The basic idea is that the model is penalized, or punished, for having too many coefficients.\n",
    "\n",
    "Recall that the conventional regression algorithm chooses coefficients to minimize the loss function, which is average of the squared residuals.\n",
    "\n",
    "A good model will result in low MSE because its predictions will be close to the observed values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e85b95-c929-4047-a5d7-4a3950cc3916",
   "metadata": {},
   "source": [
    "### Loss function with regularization\n",
    "\n",
    "Add a regularization term which depends on coefficients.\n",
    "$$MSE = \\frac{1}{N} \\sum_{i=1}^{N} \\left(y_i - \\hat{y_i}\\right)^2 + \\lambda f(\\beta)$$\n",
    "\n",
    "With penalized regression an additional \"regularization\" or \"shrinkage\" term is added to the loss function.\n",
    "\n",
    "**Rather than depending on the data, this term is a function of the model coefficients.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221dbb4e-9542-4ce7-87e6-39b96fc9c1f9",
   "metadata": {},
   "source": [
    "### Regularization term\n",
    "An extra *regularization* term is added to the loss function.\n",
    "\n",
    "The regularization term can be either\n",
    "\n",
    "* Lasso — proportion to absolute value of the coefficients\n",
    "* Ridge — square of the coefficients\n",
    "\n",
    ">There's a subtle distinction between Lasso and Ridge regression. Both will shrink the coefficients of unimportant predictors. However, whereas Ridge will result in those coefficients being close to zero, Lasso will actually force them to zero precisely.\n",
    "\n",
    "It's also possible to have a blend of Lasso and Ridge regression.\n",
    "\n",
    "Strength of regularization determined by parameter $\\lambda$:\n",
    "* $\\lambda$ = 0 — no regularization (standard regression)\n",
    "* $\\lambda$ = $\\infty$ — complete regularization (all coefficients zero)\n",
    "\n",
    "> **Ideally you want to choose a value for lambda between these two extremes!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b57dc-9319-4343-8059-51ea632a19d2",
   "metadata": {},
   "source": [
    "### Cars: Linear regression\n",
    "Fit a (standard) Linear Regression model to the training data.\n",
    "\n",
    "        # default elasticNetParam = 0 | default regParam = 0\n",
    "        regression = LinearRegression(labelCol='consumption').fit(cars_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5840f4-8033-4e76-9ec6-16934a1f663b",
   "metadata": {},
   "source": [
    "### Cars: Ridge regression\n",
    "\n",
    "        # alpha = 0 | lambda = 0.1 -> Ridge\n",
    "        ridge = LinearRegression(labelCol='consumption', elasticNetParam=0, regParam=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b6c533-d9bc-40ec-ba20-2463e8d8d743",
   "metadata": {},
   "source": [
    "### Cars: Lasso regression\n",
    "        # alpha = 1 | lambda = 0.1 -> Lasso\n",
    "        lasso = LinearRegression(labelCol='consumption', elasticNetParam=1, regParam=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20db237-f9d1-4d40-8736-98226a47069a",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc115f5c-c42b-4ff2-baa8-c16290f9d4b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Flight duration model: More features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2bf80ce-b919-4620-a953-e7c710c5b107",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:40.162193Z",
     "iopub.status.busy": "2023-05-02T22:34:40.161957Z",
     "iopub.status.idle": "2023-05-02T22:34:40.487235Z",
     "shell.execute_reply": "2023-05-02T22:34:40.486798Z",
     "shell.execute_reply.started": "2023-05-02T22:34:40.162181Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-------------+-------------+---------------+--------------------------------------------+\n",
      "|km    |org_dummy    |depart_dummy |dow_dummy    |mon_dummy      |features                                    |\n",
      "+------+-------------+-------------+-------------+---------------+--------------------------------------------+\n",
      "|253.0 |(7,[0],[1.0])|(7,[2],[1.0])|(6,[1],[1.0])|(11,[10],[1.0])|(32,[0,1,10,16,31],[253.0,1.0,1.0,1.0,1.0]) |\n",
      "|1188.0|(7,[0],[1.0])|(7,[2],[1.0])|(6,[1],[1.0])|(11,[],[])     |(32,[0,1,10,16],[1188.0,1.0,1.0,1.0])       |\n",
      "|3618.0|(7,[2],[1.0])|(7,[],[])    |(6,[5],[1.0])|(11,[2],[1.0]) |(32,[0,3,20,23],[3618.0,1.0,1.0,1.0])       |\n",
      "|621.0 |(7,[5],[1.0])|(7,[4],[1.0])|(6,[3],[1.0])|(11,[5],[1.0]) |(32,[0,6,12,18,26],[621.0,1.0,1.0,1.0,1.0]) |\n",
      "|1732.0|(7,[3],[1.0])|(7,[4],[1.0])|(6,[1],[1.0])|(11,[3],[1.0]) |(32,[0,4,12,16,24],[1732.0,1.0,1.0,1.0,1.0])|\n",
      "+------+-------------+-------------+-------------+---------------+--------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights = OneHotEncoder(inputCols=['dow', 'mon'], outputCols=['dow_dummy', 'mon_dummy']).fit(flights).transform(flights)\n",
    "\n",
    "features = ['km', 'org_dummy', 'depart_dummy', 'dow_dummy', 'mon_dummy']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "# Consolidate predictor columns\n",
    "\n",
    "flights = assembler.transform(flights.drop('features'))\n",
    "flights[features + ['features']].show(5, truncate=False)\n",
    "\n",
    "flights_train, flights_test = flights.randomSplit([.8,.2], seed=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6cd1832-c181-473f-a3a1-f5a01a762e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:40.487714Z",
     "iopub.status.busy": "2023-05-02T22:34:40.487610Z",
     "iopub.status.idle": "2023-05-02T22:34:42.557029Z",
     "shell.execute_reply": "2023-05-02T22:34:42.556732Z",
     "shell.execute_reply.started": "2023-05-02T22:34:40.487704Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 19:34:40 WARN Instrumentation: [c3c2fbb1] regParam is zero, which might cause numerical instability and overfitting.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 10.602802123410276\n",
      "regression.coefficients=DenseVector([0.0744, 27.4514, 20.2582, 52.0512, 46.1826, 15.3612, 17.5627, 17.6088, -14.8112, 0.2419, 4.1927, 7.1363, 4.823, 8.9569, 9.0253, -0.0644, -0.1053, -0.1307, -0.0945, -0.0609, -0.1116, -1.5643, -1.8322, -1.9545, -3.2953, -3.925, -3.796, -3.8926, -3.926, -3.7033, -2.4839, -0.3535])\n"
     ]
    }
   ],
   "source": [
    "# Fit linear regression model to training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Make predictions on testing data\n",
    "predictions = regression.transform(flights_test)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "rmse = RegressionEvaluator(labelCol='duration').evaluate(predictions)\n",
    "print(\"The test RMSE is\", rmse)\n",
    "\n",
    "# Look at the model coefficients\n",
    "print(f'{regression.coefficients=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a712f4-c050-471f-ab76-91706b73a222",
   "metadata": {},
   "source": [
    ">**With all those non-zero coefficients the model is a little hard to interpret!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d132b41-ed68-4df3-ba81-7ab4f42c65bd",
   "metadata": {},
   "source": [
    "#### Flight duration model: Regularization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91163b70-e6ad-4ffd-bf5e-234140511f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:42.557532Z",
     "iopub.status.busy": "2023-05-02T22:34:42.557423Z",
     "iopub.status.idle": "2023-05-02T22:34:44.339649Z",
     "shell.execute_reply": "2023-05-02T22:34:44.339290Z",
     "shell.execute_reply.started": "2023-05-02T22:34:42.557521Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 11.58447424577635\n",
      "regression.coefficients=DenseVector([0.0735, 5.6223, 0.0, 29.1973, 22.206, -2.0498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.048, 1.232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
      "Number of coefficients equal to 0: 25\n"
     ]
    }
   ],
   "source": [
    "# Fit Lasso model (λ = 1, α = 1) to training data\n",
    "regression = LinearRegression(labelCol='duration', regParam=1, elasticNetParam=1).fit(flights_train)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "rmse = RegressionEvaluator(labelCol='duration').evaluate(regression.transform(flights_test))\n",
    "print(\"The test RMSE is\", rmse)\n",
    "\n",
    "# Look at the model coefficients\n",
    "print(f'{regression.coefficients=}')\n",
    "\n",
    "# Number of zero coefficients\n",
    "zero_coeff = sum([beta==0 for beta in regression.coefficients])\n",
    "print(\"Number of coefficients equal to 0:\", zero_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97b1e7-6d13-4cf2-a211-755703812b2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ensemble & Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5eca48-057e-4f8b-8ab1-0c8014c3323a",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252435ad-35f3-45b4-ad25-2364ac894837",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f07c68-a525-4dea-8590-1f18fe909bd6",
   "metadata": {},
   "source": [
    "#### Flight duration model: Pipeline stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2828edb8-0f20-4cf3-b467-434b369da9c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:44.340345Z",
     "iopub.status.busy": "2023-05-02T22:34:44.340183Z",
     "iopub.status.idle": "2023-05-02T22:34:44.347897Z",
     "shell.execute_reply": "2023-05-02T22:34:44.347520Z",
     "shell.execute_reply.started": "2023-05-02T22:34:44.340328Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert categorical strings to index values\n",
    "indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
    "\n",
    "# One-hot encode index values\n",
    "onehot = OneHotEncoder(\n",
    "    inputCols=['org_idx', 'dow'],\n",
    "    outputCols=['org_dummy', 'dow_dummy']\n",
    ")\n",
    "\n",
    "# Assemble predictors into a single column\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'dow_dummy'], outputCol='features')\n",
    "\n",
    "# A linear regression object\n",
    "regression = LinearRegression(labelCol='duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b36669-8117-4faa-b677-1add65ac1fcb",
   "metadata": {},
   "source": [
    "#### Flight duration model: Pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4a6b94e-04c1-4f50-9bab-7229ae01dd66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:44.348608Z",
     "iopub.status.busy": "2023-05-02T22:34:44.348444Z",
     "iopub.status.idle": "2023-05-02T22:34:47.282917Z",
     "shell.execute_reply": "2023-05-02T22:34:47.282553Z",
     "shell.execute_reply.started": "2023-05-02T22:34:44.348591Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 19:34:45 WARN Instrumentation: [1a7dce9e] regParam is zero, which might cause numerical instability and overfitting.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import class for creating a pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Construct a pipeline\n",
    "pipeline = Pipeline(stages=[indexer, onehot, assembler, regression])\n",
    "\n",
    "#\n",
    "flights_train = flights_train.drop(*['org_idx', 'org_dummy', 'dow_dummy', 'features'])\n",
    "flights_test = flights_test.drop(*['org_idx', 'org_dummy', 'dow_dummy', 'features'])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "pipeline = pipeline.fit(flights_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = pipeline.transform(flights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06914d-7ca6-44e8-81da-96974dde69b4",
   "metadata": {},
   "source": [
    "#### SMS spam pipeline\n",
    "You haven't looked at the SMS data for quite a while. Last time we did the following:\n",
    "\n",
    "* split the text into tokens\n",
    "* removed stop words\n",
    "* applied the hashing trick\n",
    "* converted the data from counts to IDF and\n",
    "* trained a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6867494-cfa3-4987-878c-c8ea9f3c8c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:47.283619Z",
     "iopub.status.busy": "2023-05-02T22:34:47.283461Z",
     "iopub.status.idle": "2023-05-02T22:34:47.300427Z",
     "shell.execute_reply": "2023-05-02T22:34:47.300041Z",
     "shell.execute_reply.started": "2023-05-02T22:34:47.283603Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Break text into tokens at non-word characters\n",
    "tokenizer = Tokenizer(inputCol='text', outputCol='words')\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='terms')\n",
    "# Apply the hashing trick and transform to TF-IDF\n",
    "hasher = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"hash\", numFeatures=1024)\n",
    "idf = IDF(inputCol=hasher.getOutputCol(), outputCol=\"features\")\n",
    "# Create a logistic regression object and add everything to a pipeline\n",
    "logistic = LogisticRegression(regParam=0.2)\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hasher, idf, logistic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0aa87545-fc32-4253-b8cb-cd9425fdf00c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:47.301171Z",
     "iopub.status.busy": "2023-05-02T22:34:47.300924Z",
     "iopub.status.idle": "2023-05-02T22:34:47.321431Z",
     "shell.execute_reply": "2023-05-02T22:34:47.321043Z",
     "shell.execute_reply.started": "2023-05-02T22:34:47.301155Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sms = spark.read.csv('sms.csv', sep=';', header=False, schema=schema)\n",
    "# Remove punctuation (REGEX provided) and numbers\n",
    "sms = sms.withColumn('text', regexp_replace(sms.text, '[_():;,.!?\\\\-]', ' '))\n",
    "sms = sms.withColumn('text', regexp_replace(sms.text, '\\\\d+', ' '))\n",
    "# Merge multiple spaces\n",
    "sms = sms.withColumn('text', regexp_replace(sms.text, ' +', ' '))\n",
    "sms_train, sms_test = sms.randomSplit([.8, .2], seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2c9f67c-8cb6-4675-8898-84c3fec53d42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:47.322147Z",
     "iopub.status.busy": "2023-05-02T22:34:47.321991Z",
     "iopub.status.idle": "2023-05-02T22:34:48.013442Z",
     "shell.execute_reply": "2023-05-02T22:34:48.013169Z",
     "shell.execute_reply.started": "2023-05-02T22:34:47.322130Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = pipeline.fit(sms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6305373-6b52-42dd-9651-7fd8c491c7b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:48.014024Z",
     "iopub.status.busy": "2023-05-02T22:34:48.013874Z",
     "iopub.status.idle": "2023-05-02T22:34:48.211114Z",
     "shell.execute_reply": "2023-05-02T22:34:48.210723Z",
     "shell.execute_reply.started": "2023-05-02T22:34:48.014008Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|   41|\n",
      "|    0|       0.0|  948|\n",
      "|    1|       1.0|  105|\n",
      "|    0|       1.0|    2|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = pipeline.transform(sms_test)\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d8864c7-e845-4224-af09-f22cb4e5742e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:48.211637Z",
     "iopub.status.busy": "2023-05-02T22:34:48.211533Z",
     "iopub.status.idle": "2023-05-02T22:34:48.672786Z",
     "shell.execute_reply": "2023-05-02T22:34:48.672364Z",
     "shell.execute_reply.started": "2023-05-02T22:34:48.211627Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.98\n",
      "recall    = 0.72\n",
      "accuracy  = 0.96\n"
     ]
    }
   ],
   "source": [
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "accuracy = (TP+TN) / (TP+FP+TN+FN)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}\\naccuracy  = {:.2f}'.format(precision, recall, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff55315-1564-4fc8-bf3b-b49e330cf52a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a90058-f196-4ab4-9f1c-bfd940755e40",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745037ad-0c71-4b41-89f5-6cb11588075a",
   "metadata": {},
   "source": [
    "#### Cross validating simple flight duration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2dc60bda-aacd-44e4-bd24-46b18dad8816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:48.673535Z",
     "iopub.status.busy": "2023-05-02T22:34:48.673368Z",
     "iopub.status.idle": "2023-05-02T22:34:48.943976Z",
     "shell.execute_reply": "2023-05-02T22:34:48.943549Z",
     "shell.execute_reply.started": "2023-05-02T22:34:48.673517Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+------+--------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|km    |features|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+--------+\n",
      "|10 |10 |1  |OO     |5836  |ORD|8.18  |51      |27   |253.0 |[253.0] |\n",
      "|1  |4  |1  |OO     |5866  |ORD|15.5  |102     |null |750.0 |[750.0] |\n",
      "|11 |22 |1  |OO     |6016  |ORD|7.17  |127     |-19  |1188.0|[1188.0]|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data from CSV file\n",
    "flights = spark.read.csv('flights-larger.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')\n",
    "# Convert 'mile' to 'km' and drop 'mile' column (1 mile is equivalent to 1.60934 km)\n",
    "flights = flights.withColumn('km', F.round(F.col('mile') * 1.60934, 0)).drop('mile')\n",
    "# Assemble predictors into a single column\n",
    "flights = VectorAssembler(inputCols=['km'], outputCol='features').transform(flights)\n",
    "# random split\n",
    "flights_train, flights_test = flights.randomSplit([.8,.2], seed=43)\n",
    "flights.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "388f64fd-8669-404e-8b7c-33786f244bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:48.944577Z",
     "iopub.status.busy": "2023-05-02T22:34:48.944421Z",
     "iopub.status.idle": "2023-05-02T22:34:55.142721Z",
     "shell.execute_reply": "2023-05-02T22:34:55.142446Z",
     "shell.execute_reply.started": "2023-05-02T22:34:48.944560Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 19:34:49 WARN Instrumentation: [26b37c57] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 19:34:50 WARN Instrumentation: [aaafa31a] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 19:34:51 WARN Instrumentation: [d17075d0] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 19:34:52 WARN Instrumentation: [373ea077] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 19:34:53 WARN Instrumentation: [ad905417] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 19:34:54 WARN Instrumentation: [6ac4fe1a] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17.184539498559413]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create an empty parameter grid\n",
    "params = ParamGridBuilder().build()\n",
    "\n",
    "# Create objects for building and evaluating a regression model\n",
    "regression = LinearRegression(labelCol='duration')\n",
    "evaluator = RegressionEvaluator(labelCol='duration')\n",
    "\n",
    "# Create a cross validator\n",
    "cv = CrossValidator(estimator=regression, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Train and test model on multiple folds of the training data\n",
    "cv = cv.fit(flights_train)\n",
    "\n",
    "# NOTE: Since cross-validation builds multiple models, the fit() method can take a little while to complete.\n",
    "cv.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d24b485b-e465-4077-a90b-a7828911e248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:55.143267Z",
     "iopub.status.busy": "2023-05-02T22:34:55.143104Z",
     "iopub.status.idle": "2023-05-02T22:34:55.538296Z",
     "shell.execute_reply": "2023-05-02T22:34:55.537905Z",
     "shell.execute_reply.started": "2023-05-02T22:34:55.143256Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 17.21204153787274\n"
     ]
    }
   ],
   "source": [
    "predictions = cv.transform(flights_test)\n",
    "# Calculate the RMSE on testing data\n",
    "print(\"The test RMSE is\", evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0bf982e-fa54-4c4f-bb7d-5dc971378222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:55.538824Z",
     "iopub.status.busy": "2023-05-02T22:34:55.538720Z",
     "iopub.status.idle": "2023-05-02T22:34:55.543334Z",
     "shell.execute_reply": "2023-05-02T22:34:55.542982Z",
     "shell.execute_reply.started": "2023-05-02T22:34:55.538813Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07572046955862763]\n"
     ]
    }
   ],
   "source": [
    "# Look at the model coefficients\n",
    "print(f'{cv.bestModel.coefficients}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5151925-9e9a-4c80-961d-8b38a0a9564c",
   "metadata": {},
   "source": [
    "#### Cross validating flight duration model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f62d0b5-07a1-425d-9731-2a44d9e7dbec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:55.543845Z",
     "iopub.status.busy": "2023-05-02T22:34:55.543742Z",
     "iopub.status.idle": "2023-05-02T22:34:55.764947Z",
     "shell.execute_reply": "2023-05-02T22:34:55.764628Z",
     "shell.execute_reply.started": "2023-05-02T22:34:55.543835Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|km    |\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+\n",
      "|10 |10 |1  |OO     |5836  |ORD|8.18  |51      |27   |253.0 |\n",
      "|1  |4  |1  |OO     |5866  |ORD|15.5  |102     |null |750.0 |\n",
      "|11 |22 |1  |OO     |6016  |ORD|7.17  |127     |-19  |1188.0|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data from CSV file\n",
    "flights = spark.read.csv('flights-larger.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')\n",
    "# Convert 'mile' to 'km' and drop 'mile' column (1 mile is equivalent to 1.60934 km)\n",
    "flights = flights.withColumn('km', F.round(F.col('mile') * 1.60934, 0)).drop('mile')\n",
    "# random split\n",
    "flights_train, flights_test = flights.randomSplit([.8,.2], seed=43)\n",
    "flights.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2954772-6e9a-4a37-aae3-69e3634ee8b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:55.765453Z",
     "iopub.status.busy": "2023-05-02T22:34:55.765340Z",
     "iopub.status.idle": "2023-05-02T22:34:55.772756Z",
     "shell.execute_reply": "2023-05-02T22:34:55.772427Z",
     "shell.execute_reply.started": "2023-05-02T22:34:55.765439Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an indexer for the org field\n",
    "indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
    "\n",
    "# Create an one-hot encoder for the indexed org field\n",
    "onehot = OneHotEncoder(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
    "\n",
    "# Assemble the km and one-hot encoded fields\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy'], outputCol='features')\n",
    "\n",
    "# Create a pipeline and cross-validator.\n",
    "pipeline = Pipeline(stages=[indexer, onehot, assembler, regression])\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "          estimatorParamMaps=params,\n",
    "          evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69850da7-9697-4c65-abc8-79e0712a2c1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:34:55.773257Z",
     "iopub.status.busy": "2023-05-02T22:34:55.773154Z",
     "iopub.status.idle": "2023-05-02T22:35:00.512327Z",
     "shell.execute_reply": "2023-05-02T22:35:00.512068Z",
     "shell.execute_reply.started": "2023-05-02T22:34:55.773246Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 19:34:56 WARN Instrumentation: [ad40667d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 19:34:57 WARN Instrumentation: [4ccd9b68] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 19:34:58 WARN Instrumentation: [3c57d1ac] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 19:34:59 WARN Instrumentation: [d59c0ff6] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.194191176221066]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test model on multiple folds of the training data\n",
    "cv = cv.fit(flights_train)\n",
    "\n",
    "# NOTE: Since cross-validation builds multiple models, the fit() method can take a little while to complete.\n",
    "cv.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a268464-52a0-44dd-9952-8d9ddafd1067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:00.512790Z",
     "iopub.status.busy": "2023-05-02T22:35:00.512685Z",
     "iopub.status.idle": "2023-05-02T22:35:00.885931Z",
     "shell.execute_reply": "2023-05-02T22:35:00.885551Z",
     "shell.execute_reply.started": "2023-05-02T22:35:00.512779Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 11.26193940811068\n"
     ]
    }
   ],
   "source": [
    "predictions = cv.transform(flights_test)\n",
    "# Calculate the RMSE on testing data\n",
    "print(\"The test RMSE is\", evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7cc7ded-8f5f-4a39-b4f0-99d9e779dd10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:00.886455Z",
     "iopub.status.busy": "2023-05-02T22:35:00.886350Z",
     "iopub.status.idle": "2023-05-02T22:35:00.890010Z",
     "shell.execute_reply": "2023-05-02T22:35:00.889729Z",
     "shell.execute_reply.started": "2023-05-02T22:35:00.886445Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07430685724487272,28.181588242547328,20.199347017329146,52.7008360753772,46.804414004997824,15.642700086393011,17.944909276738414,17.81322776623134]\n"
     ]
    }
   ],
   "source": [
    "# Look at the model coefficients\n",
    "print(f'{cv.bestModel.stages[3].coefficients}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2577ba53-8371-46c7-b6de-a9250b82fa8a",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb108647-a2e6-4308-9b15-b499bec4d5aa",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97d8d9-a804-41b8-a3de-c19f80f58322",
   "metadata": {},
   "source": [
    "#### Optimizing flights linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b116f808-f38f-4546-8527-ff63424a2a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:00.890480Z",
     "iopub.status.busy": "2023-05-02T22:35:00.890377Z",
     "iopub.status.idle": "2023-05-02T22:35:00.893095Z",
     "shell.execute_reply": "2023-05-02T22:35:00.892809Z",
     "shell.execute_reply.started": "2023-05-02T22:35:00.890469Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models to be tested:  12\n"
     ]
    }
   ],
   "source": [
    "# Create parameter grid\n",
    "params = ParamGridBuilder()\n",
    "\n",
    "# Add grids for two parameters\n",
    "params = params.addGrid(regression.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
    "               .addGrid(regression.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "\n",
    "# Build the parameter grid\n",
    "params = params.build()\n",
    "print('Number of models to be tested: ', len(params))\n",
    "\n",
    "# Create cross-validator\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "608d93dc-18e1-47eb-849e-e3f77d0d8ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:00.893553Z",
     "iopub.status.busy": "2023-05-02T22:35:00.893453Z",
     "iopub.status.idle": "2023-05-02T22:35:27.969764Z",
     "shell.execute_reply": "2023-05-02T22:35:27.969437Z",
     "shell.execute_reply.started": "2023-05-02T22:35:00.893543Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.194422127061321, 11.194801268348169, 11.195581136149205, 11.196376011100767, 11.228310723887455, 11.30283992559167, 11.316858436515284, 11.633405913385612, 11.813595128811798, 14.627907755391655, 17.08384459871639, 19.306444641885214]\n"
     ]
    }
   ],
   "source": [
    "# Train and test model on multiple folds of the training data\n",
    "cv = cv.fit(flights_train)\n",
    "\n",
    "# NOTE: Since cross-validation builds multiple models, the fit() method can take a little while to complete.\n",
    "print(cv.avgMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4774d6c-2a2f-4ed4-8bc4-578c1d275a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:27.970429Z",
     "iopub.status.busy": "2023-05-02T22:35:27.970271Z",
     "iopub.status.idle": "2023-05-02T22:35:28.277063Z",
     "shell.execute_reply": "2023-05-02T22:35:28.276718Z",
     "shell.execute_reply.started": "2023-05-02T22:35:27.970412Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 11.261880914187932\n"
     ]
    }
   ],
   "source": [
    "predictions = cv.transform(flights_test)\n",
    "# Calculate the RMSE on testing data\n",
    "print(\"The test RMSE is\", evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "038b803f-bc23-4212-ae4a-c5fb9168e0e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:28.277709Z",
     "iopub.status.busy": "2023-05-02T22:35:28.277568Z",
     "iopub.status.idle": "2023-05-02T22:35:28.282020Z",
     "shell.execute_reply": "2023-05-02T22:35:28.281652Z",
     "shell.execute_reply.started": "2023-05-02T22:35:28.277693Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07429749423740031,28.04384600659602,20.063235485009532,52.56487077738323,46.66261179485449,15.50175124003904,17.804380246734887,17.672763805589963]\n"
     ]
    }
   ],
   "source": [
    "# Look at the model coefficients\n",
    "print(f'{cv.bestModel.stages[3].coefficients}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c0d44-5fbd-4ff3-8ded-418dd8227beb",
   "metadata": {},
   "source": [
    "#### Dissecting the best flight duration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c86a212-fc37-4e73-8541-f388d616042a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:28.282700Z",
     "iopub.status.busy": "2023-05-02T22:35:28.282551Z",
     "iopub.status.idle": "2023-05-02T22:35:28.574024Z",
     "shell.execute_reply": "2023-05-02T22:35:28.573608Z",
     "shell.execute_reply.started": "2023-05-02T22:35:28.282684Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StringIndexerModel: uid=StringIndexer_02eea1e4cb4d, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_7f2b5c13c50a, dropLast=true, handleInvalid=error, numInputCols=1, numOutputCols=1, VectorAssembler_a81c0fbd3ab3, LinearRegressionModel: uid=LinearRegression_28115e64c83c, numFeatures=8]\n",
      "RMSE = 11.261880914187932\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from cross validation\n",
    "best_model = cv.bestModel\n",
    "\n",
    "# Look at the stages in the best model\n",
    "print(best_model.stages)\n",
    "\n",
    "# Get the parameters for the LinearRegression object in the best model\n",
    "best_model.stages[3].extractParamMap()\n",
    "\n",
    "# Generate predictions on testing data using the best model then calculate RMSE\n",
    "predictions = best_model.transform(flights_test)\n",
    "print(\"RMSE =\", evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32a177-ee5b-4323-ac76-f272bca45714",
   "metadata": {},
   "source": [
    "#### SMS spam optimised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8186b0ef-4fb2-4926-b4d3-1ffa122ff7fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:28.574601Z",
     "iopub.status.busy": "2023-05-02T22:35:28.574454Z",
     "iopub.status.idle": "2023-05-02T22:35:28.589044Z",
     "shell.execute_reply": "2023-05-02T22:35:28.588569Z",
     "shell.execute_reply.started": "2023-05-02T22:35:28.574585Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Break text into tokens at non-word characters\n",
    "tokenizer = Tokenizer(inputCol='text', outputCol='words')\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='terms')\n",
    "# Apply the hashing trick and transform to TF-IDF\n",
    "hasher = HashingTF(inputCol='terms', outputCol=\"hash\")\n",
    "idf = IDF(inputCol=hasher.getOutputCol(), outputCol=\"features\")\n",
    "# Create a logistic regression object and add everything to a pipeline\n",
    "logistic = LogisticRegression()\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hasher, idf, logistic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dc24c79e-8a50-4847-aac8-a22b73e72569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:28.589714Z",
     "iopub.status.busy": "2023-05-02T22:35:28.589564Z",
     "iopub.status.idle": "2023-05-02T22:35:28.605546Z",
     "shell.execute_reply": "2023-05-02T22:35:28.605092Z",
     "shell.execute_reply.started": "2023-05-02T22:35:28.589697Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sms = spark.read.csv('sms.csv', sep=';', header=False, schema=schema)\n",
    "# Remove punctuation (REGEX provided) and numbers\n",
    "sms = sms.withColumn('text', regexp_replace(sms.text, '[_():;,.!?\\\\-]', ' '))\n",
    "sms = sms.withColumn('text', regexp_replace(sms.text, '\\\\d+', ' '))\n",
    "# Merge multiple spaces\n",
    "sms = sms.withColumn('text', regexp_replace(sms.text, ' +', ' '))\n",
    "sms_train, sms_test = sms.randomSplit([.8, .2], seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8dd63980-8245-4a20-9769-e65aa92ff5c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:28.606265Z",
     "iopub.status.busy": "2023-05-02T22:35:28.606121Z",
     "iopub.status.idle": "2023-05-02T22:35:28.628732Z",
     "shell.execute_reply": "2023-05-02T22:35:28.628334Z",
     "shell.execute_reply.started": "2023-05-02T22:35:28.606251Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "| id|                text|label|\n",
      "+---+--------------------+-----+\n",
      "|  1|Sorry I'll call l...|    0|\n",
      "|  2|Dont worry I gues...|    0|\n",
      "|  3| Call FREEPHONE now |    1|\n",
      "+---+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a12476d-a6f9-4102-aa0c-16ad4b6ba17b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:28.629225Z",
     "iopub.status.busy": "2023-05-02T22:35:28.629125Z",
     "iopub.status.idle": "2023-05-02T22:35:28.631765Z",
     "shell.execute_reply": "2023-05-02T22:35:28.631475Z",
     "shell.execute_reply.started": "2023-05-02T22:35:28.629215Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create parameter grid\n",
    "params = ParamGridBuilder()\n",
    "\n",
    "# Add grid for hashing trick parameters\n",
    "params = params.addGrid(hasher.numFeatures, [1024, 4096, 16384]) \\\n",
    "               .addGrid(hasher.binary, [True, False])\n",
    "\n",
    "# Add grid for logistic regression parameters\n",
    "params = params.addGrid(logistic.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
    "               .addGrid(logistic.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "\n",
    "# Build parameter grid\n",
    "params = params.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "367df168-379d-459d-a58f-c506b6ef6ebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:28.632160Z",
     "iopub.status.busy": "2023-05-02T22:35:28.632071Z",
     "iopub.status.idle": "2023-05-02T22:35:28.635578Z",
     "shell.execute_reply": "2023-05-02T22:35:28.635209Z",
     "shell.execute_reply.started": "2023-05-02T22:35:28.632151Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "27706183-0e69-4359-85a3-481545a02566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:28.636342Z",
     "iopub.status.busy": "2023-05-02T22:35:28.636098Z",
     "iopub.status.idle": "2023-05-02T22:35:28.638628Z",
     "shell.execute_reply": "2023-05-02T22:35:28.638226Z",
     "shell.execute_reply.started": "2023-05-02T22:35:28.636325Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create cross-validator\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7cb9fb1-2e72-4722-b3d1-4ea3fb824dce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:35:28.639439Z",
     "iopub.status.busy": "2023-05-02T22:35:28.639147Z",
     "iopub.status.idle": "2023-05-02T22:38:58.666141Z",
     "shell.execute_reply": "2023-05-02T22:38:58.665701Z",
     "shell.execute_reply.started": "2023-05-02T22:35:28.639421Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 19:38:42 WARN BlockManager: Asked to remove block broadcast_19355, which does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9865324890539766, 0.981648802385377, 0.974846362098674, 0.9881255550951987, 0.9347915592965327, 0.846992521452588, 0.986124923610425, 0.5, 0.5, 0.9839475275396181, 0.5, 0.5, 0.986254714042037, 0.9812666587073723, 0.9749246174466236, 0.9875280268355644, 0.9435764459100782, 0.8469132192907945, 0.9859391890771846, 0.5, 0.5, 0.9838777537458983, 0.5, 0.5, 0.9907465808449725, 0.9842098712862292, 0.9799245636286591, 0.9925598542614464, 0.9367113620396077, 0.8480220593402071, 0.9928913434374778, 0.5, 0.5, 0.9919898989932652, 0.5, 0.5, 0.9891676424638248, 0.9842240917755323, 0.980111543939256, 0.9912701832283887, 0.9421866899176214, 0.8521307887833119, 0.9920226011282474, 0.5, 0.5, 0.9915162563827339, 0.5, 0.5, 0.9907579900157673, 0.9800806571645444, 0.9759456158547957, 0.9921991434201001, 0.9403864464468331, 0.8513028643973142, 0.9930182472465658, 0.5, 0.5, 0.9928357652151357, 0.5, 0.5, 0.9890666799192832, 0.9814207163558871, 0.9757377935282024, 0.9908248014997479, 0.943105168509246, 0.8517775603615891, 0.9923153045501832, 0.5, 0.5, 0.9925198226083459, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# Train and test model on multiple folds of the training data\n",
    "cv = cv.fit(sms_train)\n",
    "\n",
    "# NOTE: Since cross-validation builds multiple models, the fit() method can take a little while to complete.\n",
    "print(cv.avgMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "15d218af-3c8e-457e-b855-459293c52006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:58.666627Z",
     "iopub.status.busy": "2023-05-02T22:38:58.666525Z",
     "iopub.status.idle": "2023-05-02T22:38:58.689351Z",
     "shell.execute_reply": "2023-05-02T22:38:58.688928Z",
     "shell.execute_reply.started": "2023-05-02T22:38:58.666617Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = cv.transform(sms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a93bcf9-7b56-4422-ad2c-ed1391cc3305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:58.689834Z",
     "iopub.status.busy": "2023-05-02T22:38:58.689729Z",
     "iopub.status.idle": "2023-05-02T22:38:58.821124Z",
     "shell.execute_reply": "2023-05-02T22:38:58.820815Z",
     "shell.execute_reply.started": "2023-05-02T22:38:58.689824Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908651766402312"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(prediction, {evaluator.metricName: 'areaUnderROC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1d14d66-0a90-4ade-89cd-cde08d36778d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:58.821754Z",
     "iopub.status.busy": "2023-05-02T22:38:58.821599Z",
     "iopub.status.idle": "2023-05-02T22:38:58.939658Z",
     "shell.execute_reply": "2023-05-02T22:38:58.939349Z",
     "shell.execute_reply.started": "2023-05-02T22:38:58.821738Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9548905405733183"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(prediction, {evaluator.metricName: 'areaUnderPR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ad693bf8-892c-41c5-97a1-06993d936e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:58.940428Z",
     "iopub.status.busy": "2023-05-02T22:38:58.940154Z",
     "iopub.status.idle": "2023-05-02T22:38:58.944311Z",
     "shell.execute_reply": "2023-05-02T22:38:58.944056Z",
     "shell.execute_reply.started": "2023-05-02T22:38:58.940411Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "multi_evaluator = MulticlassClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6270fd53-385d-49a1-9ceb-960c6754a0a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:58.944854Z",
     "iopub.status.busy": "2023-05-02T22:38:58.944668Z",
     "iopub.status.idle": "2023-05-02T22:38:59.046950Z",
     "shell.execute_reply": "2023-05-02T22:38:59.046543Z",
     "shell.execute_reply.started": "2023-05-02T22:38:58.944844Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961576471412704"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"weightedPrecision\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69b625c2-2c79-4c62-963b-70a0839b8a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:59.047630Z",
     "iopub.status.busy": "2023-05-02T22:38:59.047472Z",
     "iopub.status.idle": "2023-05-02T22:38:59.136062Z",
     "shell.execute_reply": "2023-05-02T22:38:59.135672Z",
     "shell.execute_reply.started": "2023-05-02T22:38:59.047614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9607664233576643"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"weightedRecall\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "034d96e7-2897-4dc4-bc57-35dc0999af6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:59.136517Z",
     "iopub.status.busy": "2023-05-02T22:38:59.136423Z",
     "iopub.status.idle": "2023-05-02T22:38:59.215124Z",
     "shell.execute_reply": "2023-05-02T22:38:59.214849Z",
     "shell.execute_reply.started": "2023-05-02T22:38:59.136507Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581370530590708"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7224432d-dc14-4277-af27-b5de0ccfa0b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:59.215808Z",
     "iopub.status.busy": "2023-05-02T22:38:59.215601Z",
     "iopub.status.idle": "2023-05-02T22:38:59.294909Z",
     "shell.execute_reply": "2023-05-02T22:38:59.294449Z",
     "shell.execute_reply.started": "2023-05-02T22:38:59.215791Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9607664233576643"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91a18c83-d2b8-465d-8040-311f6e1f0c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:59.295608Z",
     "iopub.status.busy": "2023-05-02T22:38:59.295426Z",
     "iopub.status.idle": "2023-05-02T22:38:59.372418Z",
     "shell.execute_reply": "2023-05-02T22:38:59.371991Z",
     "shell.execute_reply.started": "2023-05-02T22:38:59.295593Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581370530590708"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f1e49633-adf7-4abc-b765-1ca250baccf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:59.372974Z",
     "iopub.status.busy": "2023-05-02T22:38:59.372774Z",
     "iopub.status.idle": "2023-05-02T22:38:59.496930Z",
     "shell.execute_reply": "2023-05-02T22:38:59.496606Z",
     "shell.execute_reply.started": "2023-05-02T22:38:59.372963Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|   41|\n",
      "|    0|       0.0|  948|\n",
      "|    1|       1.0|  105|\n",
      "|    0|       1.0|    2|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f4b8b6c-232b-4143-a6e5-07bf1b16b638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:59.497581Z",
     "iopub.status.busy": "2023-05-02T22:38:59.497432Z",
     "iopub.status.idle": "2023-05-02T22:38:59.908096Z",
     "shell.execute_reply": "2023-05-02T22:38:59.907643Z",
     "shell.execute_reply.started": "2023-05-02T22:38:59.497565Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.9813084112149533\n",
      "recall=0.7191780821917808\n",
      "accuracy=0.9607664233576643\n"
     ]
    }
   ],
   "source": [
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "accuracy = (TP+TN) / (TP+FP+TN+FN)\n",
    "print(f'{precision=}\\n{recall=}\\n{accuracy=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2293f01-acc3-406a-bd1c-69c97cd15e0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e4555-e8b6-4ed3-8a80-c388bdb1d444",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Random Forest — an ensemble of Decision Trees  \n",
    "Creating model diversity:\n",
    "* each tree trained on\n",
    "* random subset of data\n",
    "* random subset of features used for splitting at each node\n",
    "\n",
    "No two trees in the forest should be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879c623-fbe5-4439-95f5-e193691ece4d",
   "metadata": {},
   "source": [
    "### Gradient-Boosted Trees\n",
    "Iterative boosting algorithm:\n",
    "1. Build a Decision Tree and add to ensemble.\n",
    "2. Predict label for each training instance using ensemble.\n",
    "3. Compare predictions with known labels.\n",
    "4. Emphasize training instances with incorrect predictions.\n",
    "5. Return to 1.\n",
    "\n",
    "Model improves on each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84193b-6374-447d-849d-ce6a2a2a9a49",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93976db5-7685-4352-8628-6d150f227755",
   "metadata": {},
   "source": [
    "#### Delayed flights with Gradient-Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b5ca5a72-2d90-4a40-826e-f1bc444478a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:59.908591Z",
     "iopub.status.busy": "2023-05-02T22:38:59.908486Z",
     "iopub.status.idle": "2023-05-02T22:38:59.969987Z",
     "shell.execute_reply": "2023-05-02T22:38:59.969547Z",
     "shell.execute_reply.started": "2023-05-02T22:38:59.908580Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+-----------------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|    km|label|         features|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+-----------------+\n",
      "| 10| 10|  1|     OO|  5836|ORD|  8.18|      51|   27| 253.0|    1| [10.0,8.18,51.0]|\n",
      "|  1|  4|  1|     OO|  5866|ORD|  15.5|     102| null| 750.0| null| [1.0,15.5,102.0]|\n",
      "| 11| 22|  1|     OO|  6016|ORD|  7.17|     127|  -19|1188.0|    0|[11.0,7.17,127.0]|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights = flights.withColumn('label', (F.col('delay') >= 15).cast('integer'))\n",
    "flights = VectorAssembler(inputCols=['mon', 'depart', 'duration'], outputCol='features').transform(flights)\n",
    "flights.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2d16a4c-041a-439d-beab-9d52a0aca2ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:59.970540Z",
     "iopub.status.busy": "2023-05-02T22:38:59.970416Z",
     "iopub.status.idle": "2023-05-02T22:38:59.995197Z",
     "shell.execute_reply": "2023-05-02T22:38:59.994804Z",
     "shell.execute_reply.started": "2023-05-02T22:38:59.970527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+-----------------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|km    |label|features         |\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+-----------------+\n",
      "|10 |10 |1  |OO     |5836  |ORD|8.18  |51      |27   |253.0 |1    |[10.0,8.18,51.0] |\n",
      "|1  |4  |1  |OO     |5866  |ORD|15.5  |102     |null |750.0 |null |[1.0,15.5,102.0] |\n",
      "|11 |22 |1  |OO     |6016  |ORD|7.17  |127     |-19  |1188.0|0    |[11.0,7.17,127.0]|\n",
      "+---+---+---+-------+------+---+------+--------+-----+------+-----+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_train, flights_test = flights.randomSplit([.8,.2], seed=43)\n",
    "flights.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e8f7fbcb-62aa-431e-9b12-ee8a24bbfec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:38:59.995849Z",
     "iopub.status.busy": "2023-05-02T22:38:59.995598Z",
     "iopub.status.idle": "2023-05-02T22:39:08.266744Z",
     "shell.execute_reply": "2023-05-02T22:39:08.266415Z",
     "shell.execute_reply.started": "2023-05-02T22:38:59.995838Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6130544933172917\n",
      "0.6801790462031959\n",
      "20\n",
      "(3,[0,1,2],[0.3948239175674082,0.33608675436649965,0.26908932806609215])\n"
     ]
    }
   ],
   "source": [
    "# Import the classes required\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Create model objects and train on training data\n",
    "tree = DecisionTreeClassifier().fit(flights_train.dropna())\n",
    "gbt = GBTClassifier().fit(flights_train.dropna())\n",
    "\n",
    "# Compare AUC on testing data\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(evaluator.evaluate(tree.transform(flights_test.dropna())))\n",
    "print(evaluator.evaluate(gbt.transform(flights_test.dropna())))\n",
    "\n",
    "# Find the number of trees and the relative importance of features\n",
    "print(len(gbt.trees))\n",
    "print(gbt.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf5b2c-c6a6-4f7e-b912-40b50290866c",
   "metadata": {},
   "source": [
    "#### Delayed flights with a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fe109157-b089-43f0-89d0-bde8649d3d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:39:08.267215Z",
     "iopub.status.busy": "2023-05-02T22:39:08.267113Z",
     "iopub.status.idle": "2023-05-02T22:39:08.278152Z",
     "shell.execute_reply": "2023-05-02T22:39:08.277818Z",
     "shell.execute_reply.started": "2023-05-02T22:39:08.267204Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "# Create a parameter grid\n",
    "params = ParamGridBuilder() \\\n",
    "            .addGrid(forest.featureSubsetStrategy, ['all', 'onethird', 'sqrt', 'log2']) \\\n",
    "            .addGrid(forest.maxDepth, [2, 5, 10]) \\\n",
    "            .build()\n",
    "\n",
    "# Create a binary classification evaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# Create a cross-validator\n",
    "cv = CrossValidator(estimator=forest, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f326f101-0b90-4706-8c6e-afd2477e487a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:39:08.278624Z",
     "iopub.status.busy": "2023-05-02T22:39:08.278522Z",
     "iopub.status.idle": "2023-05-02T22:40:54.115035Z",
     "shell.execute_reply": "2023-05-02T22:40:54.114644Z",
     "shell.execute_reply.started": "2023-05-02T22:39:08.278614Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 19:39:12 WARN DAGScheduler: Broadcasting large task binary with size 1371.7 KiB\n",
      "23/05/02 19:39:13 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:39:14 WARN DAGScheduler: Broadcasting large task binary with size 1331.6 KiB\n",
      "23/05/02 19:39:18 WARN DAGScheduler: Broadcasting large task binary with size 1503.6 KiB\n",
      "23/05/02 19:39:22 WARN DAGScheduler: Broadcasting large task binary with size 1400.9 KiB\n",
      "23/05/02 19:39:22 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:39:23 WARN DAGScheduler: Broadcasting large task binary with size 1193.4 KiB\n",
      "23/05/02 19:39:27 WARN DAGScheduler: Broadcasting large task binary with size 1400.9 KiB\n",
      "23/05/02 19:39:27 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:39:28 WARN DAGScheduler: Broadcasting large task binary with size 1193.4 KiB\n",
      "23/05/02 19:39:32 WARN DAGScheduler: Broadcasting large task binary with size 1379.5 KiB\n",
      "23/05/02 19:39:33 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/05/02 19:39:33 WARN DAGScheduler: Broadcasting large task binary with size 1393.4 KiB\n",
      "23/05/02 19:39:37 WARN DAGScheduler: Broadcasting large task binary with size 1516.9 KiB\n",
      "23/05/02 19:39:42 WARN DAGScheduler: Broadcasting large task binary with size 1419.3 KiB\n",
      "23/05/02 19:39:42 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/05/02 19:39:43 WARN DAGScheduler: Broadcasting large task binary with size 1209.9 KiB\n",
      "23/05/02 19:39:46 WARN DAGScheduler: Broadcasting large task binary with size 1419.3 KiB\n",
      "23/05/02 19:39:47 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/05/02 19:39:48 WARN DAGScheduler: Broadcasting large task binary with size 1209.9 KiB\n",
      "23/05/02 19:39:52 WARN DAGScheduler: Broadcasting large task binary with size 1375.4 KiB\n",
      "23/05/02 19:39:53 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:39:54 WARN DAGScheduler: Broadcasting large task binary with size 1353.3 KiB\n",
      "23/05/02 19:39:58 WARN DAGScheduler: Broadcasting large task binary with size 1515.3 KiB\n",
      "23/05/02 19:40:02 WARN DAGScheduler: Broadcasting large task binary with size 1394.6 KiB\n",
      "23/05/02 19:40:02 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:40:03 WARN DAGScheduler: Broadcasting large task binary with size 1182.4 KiB\n",
      "23/05/02 19:40:07 WARN DAGScheduler: Broadcasting large task binary with size 1394.6 KiB\n",
      "23/05/02 19:40:07 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:40:08 WARN DAGScheduler: Broadcasting large task binary with size 1182.4 KiB\n",
      "23/05/02 19:40:13 WARN DAGScheduler: Broadcasting large task binary with size 1374.9 KiB\n",
      "23/05/02 19:40:13 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:40:14 WARN DAGScheduler: Broadcasting large task binary with size 1344.8 KiB\n",
      "23/05/02 19:40:18 WARN DAGScheduler: Broadcasting large task binary with size 1503.1 KiB\n",
      "23/05/02 19:40:22 WARN DAGScheduler: Broadcasting large task binary with size 1397.9 KiB\n",
      "23/05/02 19:40:23 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:40:23 WARN DAGScheduler: Broadcasting large task binary with size 1172.1 KiB\n",
      "23/05/02 19:40:27 WARN DAGScheduler: Broadcasting large task binary with size 1397.9 KiB\n",
      "23/05/02 19:40:27 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:40:28 WARN DAGScheduler: Broadcasting large task binary with size 1172.1 KiB\n",
      "23/05/02 19:40:33 WARN DAGScheduler: Broadcasting large task binary with size 1382.5 KiB\n",
      "23/05/02 19:40:33 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/05/02 19:40:34 WARN DAGScheduler: Broadcasting large task binary with size 1361.9 KiB\n",
      "23/05/02 19:40:38 WARN DAGScheduler: Broadcasting large task binary with size 1489.8 KiB\n",
      "23/05/02 19:40:42 WARN DAGScheduler: Broadcasting large task binary with size 1406.0 KiB\n",
      "23/05/02 19:40:43 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:40:43 WARN DAGScheduler: Broadcasting large task binary with size 1178.6 KiB\n",
      "23/05/02 19:40:47 WARN DAGScheduler: Broadcasting large task binary with size 1406.0 KiB\n",
      "23/05/02 19:40:48 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/05/02 19:40:48 WARN DAGScheduler: Broadcasting large task binary with size 1178.6 KiB\n",
      "23/05/02 19:40:52 WARN DAGScheduler: Broadcasting large task binary with size 1373.6 KiB\n",
      "23/05/02 19:40:53 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cv = cv.fit(flights_train.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d706b-646e-42a5-9f0c-6b2a995d5a62",
   "metadata": {},
   "source": [
    "#### Evaluating Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a54c8e21-723d-4e4e-8b55-87a129b476a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T22:40:54.115789Z",
     "iopub.status.busy": "2023-05-02T22:40:54.115551Z",
     "iopub.status.idle": "2023-05-02T22:40:54.601364Z",
     "shell.execute_reply": "2023-05-02T22:40:54.601086Z",
     "shell.execute_reply.started": "2023-05-02T22:40:54.115775Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6166140495942163, 0.6609892407042208, 0.6829900362212911, 0.6520726854481138, 0.6651830212615231, 0.6801588426954762, 0.6396107709568064, 0.6654136638407119, 0.6830336262810341, 0.6396107709568064, 0.6654136638407119, 0.6830333345648107]\n",
      "0.6830336262810341\n",
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30]. (default: 5, current: 10)\n",
      "featureSubsetStrategy: The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto' (default: auto, current: sqrt)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 19:40:54 WARN DAGScheduler: Broadcasting large task binary with size 1145.0 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6839736660828811\n"
     ]
    }
   ],
   "source": [
    "# Average AUC for each parameter combination in grid\n",
    "print(cv.avgMetrics)\n",
    "\n",
    "# Average AUC for the best model\n",
    "print(max(cv.avgMetrics))\n",
    "\n",
    "# What's the optimal parameter value for maxDepth?\n",
    "print(cv.bestModel.explainParam('maxDepth'))\n",
    "# What's the optimal parameter value for featureSubsetStrategy?\n",
    "print(cv.bestModel.explainParam('featureSubsetStrategy'))\n",
    "\n",
    "# AUC for best model on testing data\n",
    "print(evaluator.evaluate(cv.transform(flights_test.dropna())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
