{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7a6bdd-f325-402b-9109-a9d0eac4e8fb",
   "metadata": {},
   "source": [
    "# Generalization Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da7d1a-0937-4716-ad4e-8d4ebe5717d2",
   "metadata": {},
   "source": [
    "## Supervised Learning - Under the Hood\n",
    "Supervised Learning: $y = f(x), f$ is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab21d4-fb4c-4892-bc03-20babaf278fa",
   "metadata": {},
   "source": [
    "## Goals of Supervised Learning\n",
    "* Find a model $\\hat{f}$ that best approximates $f :\\hat{f} \\approx f$\n",
    "* $\\hat{f}$ can be Logistic Regression, Decision Tree, Neural Network ...\n",
    "* Discard noise as much as possible.\n",
    "* **End goal:** $\\hat{f}$ should achieve a low predictive error on unseen datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac709cd5-b4cc-43cf-94df-cbb30939ed2d",
   "metadata": {},
   "source": [
    "## Difficulties in Approximating f\n",
    "* Overfitting: $\\hat{f}$ fits the training set noise.\n",
    "* Underfitting: $\\hat{f}$ is not flexible enough to approximate $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8928ff3d-26dd-4443-b818-a9812c9577b9",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "When a model overfits the training set, its predictive power on unseen datasets is pretty low. The model memorizes the noise present in the training set. Such model achieves a low training set error and a high test set error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d4cfa8-a6c7-4113-82a8-b5bdf6f3a360",
   "metadata": {},
   "source": [
    "## Underfitting\n",
    "When a model underfits the data, the training set error is roughly equal to the test set error. However, both errors are relatively high. The trained model isn't flexible enough to capture the complex dependency between features and labels. In analogy, it's like teaching calculus to a 3-year old. The child does not have the required mental abstraction level that enables him to understand calculus. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12385b8a-bcdb-4e5d-95e4-d597e019c72b",
   "metadata": {},
   "source": [
    "## Generalization Error\n",
    "\n",
    "The generalization error of a model tells you how much it generalizes on unseen data. It can be decomposed into 3 terms: bias, variance and irreducible error where the irreducible error is the error contribution of noise. \n",
    "\n",
    "* **Generalization Error of $\\hat{f}$:** Does $\\hat{f}$ generalize well on unseen data?\n",
    "* it can be decomposed as follows  \n",
    "Generalization error of $$\\hat{f} = bias^2 + variance + irreducible\\ error$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6234322-c2f6-4591-8783-3ca9163ad76f",
   "metadata": {},
   "source": [
    "## Bias\n",
    "\n",
    "The bias term tells you, on average, how much $\\hat{f}$ and f are different. Considering a model with high bias, it is not flexible enough to approximate the true function $f$. High bias models lead to underfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ce605-ef7b-4e5c-8a62-2ca98bc7abcb",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "The variance term tells you how much $\\hat{f}$ is inconsistent over different training sets. Considering a model with high variance, $\\hat{f}$ follows the training data points so closely that it misses the true function $f$. High variance models lead to overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110deaa-caa4-4147-816d-f6f98d6be805",
   "metadata": {},
   "source": [
    "## Model Complexity\n",
    "* Model Complexity: sets the flexibility of $\\hat{f}$.\n",
    "* Example: Maximum tree depth, Minimum samples per leaf, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5c5ca-2cd4-4fd9-82ae-8f25d4ef114d",
   "metadata": {},
   "source": [
    "## Complexity, bias and variance\n",
    "\n",
    "As the complexity of $\\hat{f}$ increases, the bias term decreases while the variance term increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a002e9e-ead6-4ae4-ad4b-1eaad88b632f",
   "metadata": {},
   "source": [
    "# Diagnosing Bias and Variance Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d236549-cba4-4d67-96bf-561d3e9a1d9c",
   "metadata": {},
   "source": [
    "## Estimating the Generalization Error\n",
    "* How do we estimate the generalization error of a model?\n",
    "* Cannot be done directly because:\n",
    "    * $f$ is unknown,\n",
    "    * usually you only have one dataset,\n",
    "    * noise is unpredictable.\n",
    "\n",
    "**Solution:**\n",
    "* split the data to training and test sets\n",
    "* fit $\\hat{f}$ to the training set\n",
    "* evaluate the error of $\\hat{f}$ on the **unseen** test set\n",
    "* generalization error of $\\hat{f} \\approx$ test set error of $\\hat{f}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d85b41-d16e-4bca-b9d1-75095e5cccef",
   "metadata": {},
   "source": [
    "## Better Model Evaluation with Cross-Validation\n",
    "* Test set should not be touched until we are confident about $\\hat{f}$'s performance\n",
    "* Evaluating $\\hat{f}$ on training set: biased estimate, $\\hat{f}$ has already seen all training points\n",
    "* Solution -> Cross-Validation (CV):\n",
    "    * K-Fold CV\n",
    "    * Hold-Out CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc36af-f34c-477b-9f0f-1ad506232cfb",
   "metadata": {},
   "source": [
    "## Diagnose Variance Problems\n",
    "\n",
    "* If $\\hat{f}$ suffers from **high variance**: CV Error of $\\hat{f}$ > training set error of $\\hat{f}$\n",
    "* $\\hat{f}$ is said to overfit the training set. To remedy overfitting:\n",
    "    * decrease model complexity\n",
    "        * ex. decrase max depth, increase min sample per leaf, ...\n",
    "    * gather more data, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82cd4a-4e7f-40c4-abf9-58f2c80ad532",
   "metadata": {},
   "source": [
    "## Diagnose Bias Problemas\n",
    "* if $\\hat{f}$ suffers from high bias: CV error of $\\hat{f} \\approx$ training set error of $\\hat{f}$ >> desired error\n",
    "* $\\hat{f}$ is said to underfit the training set. To remedy underfitting:\n",
    "    * increase model complexity\n",
    "        ex. increase max depth, decrease min sample per leaf, ...\n",
    "    * gather more relevant features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e39c1-385e-4d16-b793-ddef76b1a97a",
   "metadata": {},
   "source": [
    "## K-Fold CV in sklearn on the Auto Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c45d74d-7ef9-4f8f-b3d9-e640f82bc35b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:49.051581Z",
     "iopub.status.busy": "2023-09-02T17:24:49.050933Z",
     "iopub.status.idle": "2023-09-02T17:24:49.403543Z",
     "shell.execute_reply": "2023-09-02T17:24:49.403273Z",
     "shell.execute_reply.started": "2023-09-02T17:24:49.051484Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>origin</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>US</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Asia</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>Europe</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3021</td>\n",
       "      <td>16.5</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>27.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90</td>\n",
       "      <td>2950</td>\n",
       "      <td>17.3</td>\n",
       "      <td>US</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>29.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>68</td>\n",
       "      <td>2135</td>\n",
       "      <td>16.6</td>\n",
       "      <td>Asia</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>17.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3520</td>\n",
       "      <td>16.4</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>25.1</td>\n",
       "      <td>140.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2720</td>\n",
       "      <td>15.4</td>\n",
       "      <td>US</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  displ   hp  weight  accel  origin  size\n",
       "0    18.0  250.0   88    3139   14.5      US  15.0\n",
       "1     9.0  304.0  193    4732   18.5      US  20.0\n",
       "2    36.1   91.0   60    1800   16.4    Asia  10.0\n",
       "3    18.5  250.0   98    3525   19.0      US  15.0\n",
       "4    34.3   97.0   78    2188   15.8  Europe  10.0\n",
       "..    ...    ...  ...     ...    ...     ...   ...\n",
       "387  18.0  250.0   88    3021   16.5      US  15.0\n",
       "388  27.0  151.0   90    2950   17.3      US  10.0\n",
       "389  29.5   98.0   68    2135   16.6    Asia  10.0\n",
       "390  17.5  250.0  110    3520   16.4      US  15.0\n",
       "391  25.1  140.0   88    2720   15.4      US  10.0\n",
       "\n",
       "[392 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "auto = pd.read_csv('auto.zip')\n",
    "auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e86586de-e088-43ef-8bea-99d37b78e590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:49.404041Z",
     "iopub.status.busy": "2023-09-02T17:24:49.403930Z",
     "iopub.status.idle": "2023-09-02T17:24:49.407086Z",
     "shell.execute_reply": "2023-09-02T17:24:49.406801Z",
     "shell.execute_reply.started": "2023-09-02T17:24:49.404030Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = auto.iloc[:, 1:]\n",
    "X['origin'] = pd.Categorical(X['origin']).codes\n",
    "y = auto['mpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce733ca-430c-4d52-84ec-1bea6e4b6754",
   "metadata": {},
   "source": [
    "### First attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8554e11-de07-404b-a55a-9006c80dc6a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:49.407726Z",
     "iopub.status.busy": "2023-09-02T17:24:49.407509Z",
     "iopub.status.idle": "2023-09-02T17:24:49.613866Z",
     "shell.execute_reply": "2023-09-02T17:24:49.613530Z",
     "shell.execute_reply.started": "2023-09-02T17:24:49.407714Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.14, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.14, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.14, random_state=123)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "# Instantiate decision tree regressor and assign it to 'dt'\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.14, random_state=123)\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b539c-1183-4da3-b87d-4037ca48faad",
   "metadata": {},
   "source": [
    "All scorer objects follow the convention that higher return values are better than lower return values. Thus metrics which measure the distance between the model and the data, like metrics.mean_squared_error, are available as neg_mean_squared_error which return the negated value of the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814b49e5-9ab0-41c4-aff7-c65d7b058861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:49.614960Z",
     "iopub.status.busy": "2023-09-02T17:24:49.614769Z",
     "iopub.status.idle": "2023-09-02T17:24:50.409031Z",
     "shell.execute_reply": "2023-09-02T17:24:50.408619Z",
     "shell.execute_reply.started": "2023-09-02T17:24:49.614948Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the list of MSE ontained by 10-fold CV\n",
    "# Set n_jobs to -1 in order to exploit all CPU cores in computation\n",
    "MSE_CV = - cross_val_score(dt, X_train, y_train, cv= 10,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           n_jobs = -1)\n",
    "# Fit 'dt' to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "# Predict the labels of training set\n",
    "y_predict_train = dt.predict(X_train)\n",
    "# Predict the labels of test set\n",
    "y_predict_test = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7907380-5d35-42f8-b7b1-f64e38711e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:50.409862Z",
     "iopub.status.busy": "2023-09-02T17:24:50.409698Z",
     "iopub.status.idle": "2023-09-02T17:24:50.413875Z",
     "shell.execute_reply": "2023-09-02T17:24:50.413335Z",
     "shell.execute_reply.started": "2023-09-02T17:24:50.409846Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MSE: 20.51\n",
      "Train MSE: 15.30\n",
      "Test MSE: 20.92\n"
     ]
    }
   ],
   "source": [
    "# CV MSE\n",
    "print('CV MSE: {:.2f}'.format(MSE_CV.mean()))\n",
    "# Training set MSE\n",
    "print('Train MSE: {:.2f}'.format(MSE(y_train, y_predict_train)))\n",
    "# Test set MSE\n",
    "print('Test MSE: {:.2f}'.format(MSE(y_test, y_predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd9b3c6-951a-48a8-ab01-62cf388c700f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reducing variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22bc2c73-5747-4cb2-bca7-826098af7221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:50.414902Z",
     "iopub.status.busy": "2023-09-02T17:24:50.414697Z",
     "iopub.status.idle": "2023-09-02T17:24:50.418567Z",
     "shell.execute_reply": "2023-09-02T17:24:50.418073Z",
     "shell.execute_reply.started": "2023-09-02T17:24:50.414880Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=123)\n",
    "# Instantiate a DecisionTreeRegressor dt\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0999b54c-6e9c-4ad8-8ca5-0e92ad6c82d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:50.419376Z",
     "iopub.status.busy": "2023-09-02T17:24:50.419192Z",
     "iopub.status.idle": "2023-09-02T17:24:50.829751Z",
     "shell.execute_reply": "2023-09-02T17:24:50.829278Z",
     "shell.execute_reply.started": "2023-09-02T17:24:50.419357Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MSE: 27.41\n"
     ]
    }
   ],
   "source": [
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv=10, \n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       n_jobs=-1)\n",
    "# Compute the 10-folds CV MSE\n",
    "MSE_CV = (MSE_CV_scores.mean())\n",
    "# Print MSE_CV\n",
    "print('CV MSE: {:.2f}'.format(MSE_CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e8bbe-4933-40c4-8fd3-6140f5525a71",
   "metadata": {},
   "source": [
    "### Evaluating training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18702958-288e-4fe7-a6e7-ab5352bdc2cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:50.830858Z",
     "iopub.status.busy": "2023-09-02T17:24:50.830504Z",
     "iopub.status.idle": "2023-09-02T17:24:50.838225Z",
     "shell.execute_reply": "2023-09-02T17:24:50.837641Z",
     "shell.execute_reply.started": "2023-09-02T17:24:50.830836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 25.32\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = dt.predict(X_train)\n",
    "# Evaluate the training set MSE of dt\n",
    "MSE_train = (mean_squared_error(y_train, y_pred_train))\n",
    "# Print MSE_train\n",
    "print('Train MSE: {:.2f}'.format(MSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47464dee-ad60-40a2-9f6b-561a2155d0ab",
   "metadata": {},
   "source": [
    "# Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7e72f-e3fc-4c69-b7c7-c998e5ebac4b",
   "metadata": {},
   "source": [
    "## Advantages of CARTs\n",
    "* Simple to understand.\n",
    "* Simple to interpret.\n",
    "* Easy to use.\n",
    "* Flexibility: ability to describe non-linear dependencies.\n",
    "* Preprocessing: no need to standardize or normalize features, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0cfd31-7339-4c4e-b4af-65b38a840bd3",
   "metadata": {},
   "source": [
    "## Limitations of CARTs\n",
    "* Classification: can only produce orthogonal decision boundaries.\n",
    "* Sensitive to small variations in the training set. Sometimes, when a single point is removed from the training set, a CART's learned parameters may changed drastically.\n",
    "* High variance: unconstrained CARTs may overfit the training set\n",
    "* A solution that takes advantage of the flexibility of CARTs while reducing their tendency to memorize noise (overfitting) is **ensemble learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac851de9-1c54-479d-a00b-40ffd94efc47",
   "metadata": {},
   "source": [
    "## Ensemble Learning\n",
    "* Train different models on the same dataset\n",
    "* Let each model make its predictions.\n",
    "* Meta-model: aggregates predictions of individual models.\n",
    "* Final prediction: more robust and less prone to errors.\n",
    "* Best results: models are skillful in different ways, meaning that if some models make predictions that are way off, the other models should compensate these errors. In such case, the meta-model's predictions are more robust. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6cef5-8b67-4d8e-a88f-f7ee9d5ef221",
   "metadata": {},
   "source": [
    "## Ensemble Learning in Practice: Voting Classifier\n",
    "* Binary classification task\n",
    "* $N$ classifiers make predictions: $P_{1}, P_{2},\\ ...,\\ P_{N}$ with $P_{i}=0$ or 1\n",
    "* Meta-model prediction: **hard voting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244ed3b-736e-4171-826e-37086d8cbd77",
   "metadata": {},
   "source": [
    "## Voting Classifier in sklearn (Breast-Cancer dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6adf9e-592f-4503-82a8-b67957a3bebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:50.839026Z",
     "iopub.status.busy": "2023-09-02T17:24:50.838877Z",
     "iopub.status.idle": "2023-09-02T17:24:50.849515Z",
     "shell.execute_reply": "2023-09-02T17:24:50.848932Z",
     "shell.execute_reply.started": "2023-09-02T17:24:50.839013Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wbc = pd.read_csv('wbc.zip')\n",
    "X = wbc.iloc[:, 2:-1]\n",
    "y = pd.Categorical(wbc['diagnosis']).codes\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1042855-aa85-4e3e-b6d1-951ef1f31fb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:50.850479Z",
     "iopub.status.busy": "2023-09-02T17:24:50.850259Z",
     "iopub.status.idle": "2023-09-02T17:24:50.862681Z",
     "shell.execute_reply": "2023-09-02T17:24:50.862393Z",
     "shell.execute_reply.started": "2023-09-02T17:24:50.850467Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import functions to compute accuracy and split data\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import models, including VotingClassifier meta-model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Set seed for reproducibility\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f241d211-97bb-4640-946a-d75eeb82f0b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:50.863294Z",
     "iopub.status.busy": "2023-09-02T17:24:50.863106Z",
     "iopub.status.idle": "2023-09-02T17:24:50.867139Z",
     "shell.execute_reply": "2023-09-02T17:24:50.866843Z",
     "shell.execute_reply.started": "2023-09-02T17:24:50.863252Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1589da13-33c3-4436-a276-1d3462440f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:50.867725Z",
     "iopub.status.busy": "2023-09-02T17:24:50.867600Z",
     "iopub.status.idle": "2023-09-02T17:24:50.871051Z",
     "shell.execute_reply": "2023-09-02T17:24:50.870713Z",
     "shell.execute_reply.started": "2023-09-02T17:24:50.867715Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state= SEED)\n",
    "# Instantiate individual classifiers\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "knn = KNN()\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "# Define a list called classifier that contains the tuples (classifier_name, classifier)\n",
    "classifiers = [('Logistic Regression', lr),\n",
    "               ('K Nearest Neighbours', knn),\n",
    "               ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "302d66b9-7601-4fc1-a868-466fc9c2ddd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:50.872534Z",
     "iopub.status.busy": "2023-09-02T17:24:50.872306Z",
     "iopub.status.idle": "2023-09-02T17:24:50.979792Z",
     "shell.execute_reply": "2023-09-02T17:24:50.979462Z",
     "shell.execute_reply.started": "2023-09-02T17:24:50.872522Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.971\n",
      "K Nearest Neighbours : 0.953\n",
      "Classification Tree : 0.930\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the defined list of tuples containing the classifiers\n",
    "for clf_name, clf in classifiers:\n",
    "    #fit clf to the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict the labels of the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Evaluate the accuracy of clf on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34220201-d791-41cb-9a49-5d4bc59ee29f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:50.980738Z",
     "iopub.status.busy": "2023-09-02T17:24:50.980380Z",
     "iopub.status.idle": "2023-09-02T17:24:51.067715Z",
     "shell.execute_reply": "2023-09-02T17:24:51.067392Z",
     "shell.execute_reply.started": "2023-09-02T17:24:50.980720Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.971\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a VotingClassifier 'vc'\n",
    "vc = VotingClassifier(estimators=classifiers)\n",
    "# Fit 'vc' to the traing set and predict test set labels\n",
    "vc.fit(X_train, y_train)\n",
    "y_pred = vc.predict(X_test)\n",
    "# Evaluate the test-set accuracy of 'vc'\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd48823-af7f-4c12-ac11-976ae5140e84",
   "metadata": {},
   "source": [
    "## Voting Classifier in sklearn (Indian Liver Patient Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80369860-09ad-4200-8995-f6bf785fcce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:51.068241Z",
     "iopub.status.busy": "2023-09-02T17:24:51.068132Z",
     "iopub.status.idle": "2023-09-02T17:24:51.072734Z",
     "shell.execute_reply": "2023-09-02T17:24:51.072437Z",
     "shell.execute_reply.started": "2023-09-02T17:24:51.068230Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indian = pd.read_csv('indian_liver_patient_preprocessed.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b788d6a-a57a-4dfe-b0a4-0185977887af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:51.073282Z",
     "iopub.status.busy": "2023-09-02T17:24:51.073171Z",
     "iopub.status.idle": "2023-09-02T17:24:51.075455Z",
     "shell.execute_reply": "2023-09-02T17:24:51.075141Z",
     "shell.execute_reply.started": "2023-09-02T17:24:51.073271Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = indian.iloc[:, 1:-1]\n",
    "y = indian['Liver_disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "382c7433-1fd4-4462-875e-340af8e82e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:51.076080Z",
     "iopub.status.busy": "2023-09-02T17:24:51.075907Z",
     "iopub.status.idle": "2023-09-02T17:24:51.078218Z",
     "shell.execute_reply": "2023-09-02T17:24:51.077947Z",
     "shell.execute_reply.started": "2023-09-02T17:24:51.076068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "# Instantiate knn\n",
    "knn = KNN(n_neighbors=27)\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b92d8ec1-d658-4d3e-be86-1903818109f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:51.078739Z",
     "iopub.status.busy": "2023-09-02T17:24:51.078635Z",
     "iopub.status.idle": "2023-09-02T17:24:51.081863Z",
     "shell.execute_reply": "2023-09-02T17:24:51.081459Z",
     "shell.execute_reply.started": "2023-09-02T17:24:51.078729Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state= SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60f7a494-25e5-4731-a8e2-b6b63c4db50c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:51.082406Z",
     "iopub.status.busy": "2023-09-02T17:24:51.082291Z",
     "iopub.status.idle": "2023-09-02T17:24:51.099045Z",
     "shell.execute_reply": "2023-09-02T17:24:51.098686Z",
     "shell.execute_reply.started": "2023-09-02T17:24:51.082394Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.759\n",
      "K Nearest Neighbours : 0.701\n",
      "Classification Tree : 0.730\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)    \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred) \n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e95cecbd-ddca-4394-9fd0-ed9264e2852f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T17:24:51.099679Z",
     "iopub.status.busy": "2023-09-02T17:24:51.099540Z",
     "iopub.status.idle": "2023-09-02T17:24:51.116916Z",
     "shell.execute_reply": "2023-09-02T17:24:51.116555Z",
     "shell.execute_reply.started": "2023-09-02T17:24:51.099667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.770\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
