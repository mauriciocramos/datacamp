{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d8f44c-069d-4224-b9ea-8c94b617c7bb",
   "metadata": {},
   "source": [
    "# Creating a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ae3ddf-b7c7-4549-b9d8-3e01f53adbec",
   "metadata": {},
   "source": [
    "## Keras model building steps\n",
    "* Specify Architecture\n",
    "    * How many layers?\n",
    "    * How many nodes in each layer?\n",
    "    * What activation function to use in each layer?\n",
    "        * ReLU - Rectified Linear Unit\n",
    "        * Identity function\n",
    "        * Hyperbolic Tangent\n",
    "* Compile\n",
    "    * Specify loss function\n",
    "    * Optimization parameters\n",
    "* Fit\n",
    "    \n",
    "* Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d2322-c37d-4192-88b3-3b7130d44f42",
   "metadata": {},
   "source": [
    "## Model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00ba3e1-385d-464b-9205-055ee1732ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T19:14:02.033999Z",
     "iopub.status.busy": "2023-09-02T19:14:02.033862Z",
     "iopub.status.idle": "2023-09-02T19:14:05.672208Z",
     "shell.execute_reply": "2023-09-02T19:14:05.670291Z",
     "shell.execute_reply.started": "2023-09-02T19:14:02.033972Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.config.list_physical_devices('GPU') = [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "print(f\"{tf.config.list_physical_devices('GPU') = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d313ef-29c4-42e7-b9d6-bd3644008721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T19:14:05.675796Z",
     "iopub.status.busy": "2023-09-02T19:14:05.674464Z",
     "iopub.status.idle": "2023-09-02T19:14:05.698830Z",
     "shell.execute_reply": "2023-09-02T19:14:05.698026Z",
     "shell.execute_reply.started": "2023-09-02T19:14:05.675725Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((534, 9), (534,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#read data\n",
    "predictors = np.loadtxt('hourly_wages.csv', delimiter=',', skiprows=1, usecols=range(1,10))\n",
    "target = np.loadtxt('hourly_wages.csv', delimiter=',', skiprows=1, usecols=0)\n",
    "n_cols = predictors.shape[1]\n",
    "predictors.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57092418-9f5f-4024-8c01-fdee911aa6d0",
   "metadata": {},
   "source": [
    "* There are two ways to build up a model, and we will focus on sequential, which is the easier way to build a model.\n",
    "* Sequential models require that each layer has weights or connections only to the one layer coming directly after it in the network diagram.\n",
    "* There are more exotic models out there with complex patterns of connections, but Sequential will do the trick for everything we need here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23374b5b-100b-47eb-b005-01f63d3c4846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T19:14:05.699359Z",
     "iopub.status.busy": "2023-09-02T19:14:05.699240Z",
     "iopub.status.idle": "2023-09-02T19:14:06.003196Z",
     "shell.execute_reply": "2023-09-02T19:14:06.002436Z",
     "shell.execute_reply.started": "2023-09-02T19:14:05.699349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# easier way to crate a model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e5293-53ad-4e92-a849-ffd884a64a1e",
   "metadata": {},
   "source": [
    "* We start adding layers using the add method of the model.\n",
    "* The type of layer you have seen, that standard layer type, is called a Dense layer. It is called Dense because all of the nodes in the previous layer connect to all of the nodes in the current layer.\n",
    "* As you advance in deep learning, you may start using layers that aren't Dense.\n",
    "* In each layer, we specify the number of nodes as the first positional argument, and the activation function we want to use in that layer using the keyword argument activation.\n",
    "* Keras supports every activation function you will want in practice.\n",
    "* In the first layer, we need to specify input shapes as shown here. That says the input will have n_cols columns, and there is nothing after the comma, meaning it can have any number of rows, that is, any number of data points.\n",
    "* You'll notice the last layer has 1 node. That is the output layer, and it matches those diagrams where we ended with only a single node as the output or prediction of the model.\n",
    "* This model has 2 hidden layers, and an output layer.\n",
    "* You may be struck that each hidden layers has 100 nodes. Keras and TensorFlow do the math for us, so don't feel afraid to use much bigger networks than we've seen before. It's quite common to use 100 or 1000s nodes in a layer.\n",
    "* You'll learn more about choosing an appropriate number of nodes later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fc09f6-82d5-4b9c-a91b-72738f2f5a05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T19:14:06.005268Z",
     "iopub.status.busy": "2023-09-02T19:14:06.004885Z",
     "iopub.status.idle": "2023-09-02T19:14:06.011383Z",
     "shell.execute_reply": "2023-09-02T19:14:06.011008Z",
     "shell.execute_reply.started": "2023-09-02T19:14:06.005247Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1000      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e0525-eaa3-42e6-a96a-e2b273e08372",
   "metadata": {},
   "source": [
    "# Compiling and fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c49261-a1ed-4b65-a598-f9a25cba73dd",
   "metadata": {},
   "source": [
    "## Why you need to compile your model\n",
    "* Specify the optimizer\n",
    "    * Many options and mathematically complex\n",
    "    * \"Adam\" is usually a good choice: **adjusts learning rate as it does gradient descent**\n",
    "* Loss function\n",
    "    * \"mean_squared_error\" common for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d90f51-3825-4ff7-8a3f-31568edbaae3",
   "metadata": {},
   "source": [
    "## Compiling a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06141352-83a2-4b5b-a336-84f50e2cb0dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T19:14:06.012079Z",
     "iopub.status.busy": "2023-09-02T19:14:06.011807Z",
     "iopub.status.idle": "2023-09-02T19:14:06.019365Z",
     "shell.execute_reply": "2023-09-02T19:14:06.019065Z",
     "shell.execute_reply.started": "2023-09-02T19:14:06.012066Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d75e9b-8e29-4044-bd40-08e38d11b23c",
   "metadata": {},
   "source": [
    "## What is fitting a model\n",
    "* Applying backpropagation and gradient descent with your data to update the weights\n",
    "* Scaling data before fitting can ease optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba5b9c-62fc-4ba4-8e76-890420c97550",
   "metadata": {},
   "source": [
    "## Fitting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7efc0d48-08ff-4102-8d25-313e85b51d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T19:14:06.019922Z",
     "iopub.status.busy": "2023-09-02T19:14:06.019780Z",
     "iopub.status.idle": "2023-09-02T19:14:07.316135Z",
     "shell.execute_reply": "2023-09-02T19:14:07.315427Z",
     "shell.execute_reply.started": "2023-09-02T19:14:06.019910Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 16:14:06.812394: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:530] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.2\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2023-09-02 16:14:06.813956: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.814176: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.834788: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.834954: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.848998: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.849196: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.870491: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.870637: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.882836: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.883004: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.899178: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-02 16:14:06.899455: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_4' defined at (most recent call last):\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_22982/1750234257.py\", line 1, in <module>\n      model.fit(predictors, target)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_4'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_4}}]] [Op:__inference_train_function_880]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_4' defined at (most recent call last):\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_22982/1750234257.py\", line 1, in <module>\n      model.fit(predictors, target)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/mauricio/miniconda3/envs/dev/lib/python3.10/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_4'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_4}}]] [Op:__inference_train_function_880]"
     ]
    }
   ],
   "source": [
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23291e-7141-4a95-bf07-8e38f1d73e47",
   "metadata": {},
   "source": [
    "# Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c84bf9-3231-4981-9602-3f5575337181",
   "metadata": {},
   "source": [
    "## Classification\n",
    "* 'categorical_crossentropy' loss function: it≈õ by far the most common\n",
    "    * Similar to log loss: Lower is better\n",
    "* Add `metrics = ['accuracy']` to compile step for easy-to-understand diagnostics\n",
    "* Output layer has separate node for each possible outcome, and uses 'softmax' activation\n",
    "    * The softmax activation function ensures the predictions sum to 1, so they can be intepreted as probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a01d2-d2e9-4807-b048-ebbd99336569",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-02T19:14:07.316467Z",
     "iopub.status.idle": "2023-09-02T19:14:07.316598Z",
     "shell.execute_reply": "2023-09-02T19:14:07.316538Z",
     "shell.execute_reply.started": "2023-09-02T19:14:07.316531Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570f593-f76f-43e6-aecf-a8d2a0f75bff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-02T19:14:07.317013Z",
     "iopub.status.idle": "2023-09-02T19:14:07.317242Z",
     "shell.execute_reply": "2023-09-02T19:14:07.317164Z",
     "shell.execute_reply.started": "2023-09-02T19:14:07.317157Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_all_numeric.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5f75b-910a-470a-855a-b083a01c5d4d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-02T19:14:07.317587Z",
     "iopub.status.idle": "2023-09-02T19:14:07.317771Z",
     "shell.execute_reply": "2023-09-02T19:14:07.317700Z",
     "shell.execute_reply.started": "2023-09-02T19:14:07.317694Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(['survived'], axis=1).values.astype('float64')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571fa0f-e472-46c7-b01c-4d30479c3ddc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-02T19:14:07.318289Z",
     "iopub.status.idle": "2023-09-02T19:14:07.318433Z",
     "shell.execute_reply": "2023-09-02T19:14:07.318366Z",
     "shell.execute_reply.started": "2023-09-02T19:14:07.318360Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = to_categorical(df.survived)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38912a-1017-4ec8-b805-921cbb029106",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-02T19:14:07.318915Z",
     "iopub.status.idle": "2023-09-02T19:14:07.319035Z",
     "shell.execute_reply": "2023-09-02T19:14:07.318979Z",
     "shell.execute_reply.started": "2023-09-02T19:14:07.318973Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=91, random_state=1)\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2af93d-4df9-4c46-9885-a145394f41fc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-02T19:14:07.319771Z",
     "iopub.status.idle": "2023-09-02T19:14:07.319891Z",
     "shell.execute_reply": "2023-09-02T19:14:07.319834Z",
     "shell.execute_reply.started": "2023-09-02T19:14:07.319829Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4529c1e-ce81-4b5a-88d9-29c5f4389d9b",
   "metadata": {},
   "source": [
    "## Using models\n",
    "* Save\n",
    "* Reload\n",
    "* Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e671c-5f3f-4d4a-8cd3-f92cceb62b34",
   "metadata": {},
   "source": [
    "## Saving, reloading, and using your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b630864-425e-4214-a762-f0fe839d39ee",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-02T19:14:07.320345Z",
     "iopub.status.idle": "2023-09-02T19:14:07.320465Z",
     "shell.execute_reply": "2023-09-02T19:14:07.320408Z",
     "shell.execute_reply.started": "2023-09-02T19:14:07.320402Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_file.h5')\n",
    "! ls -lh model_file.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0655d2-0581-4c32-b342-c4773501783f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-02T19:14:07.320849Z",
     "iopub.status.idle": "2023-09-02T19:14:07.320976Z",
     "shell.execute_reply": "2023-09-02T19:14:07.320917Z",
     "shell.execute_reply.started": "2023-09-02T19:14:07.320910Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = load_model('model_file.h5')\n",
    "yhat = model.predict(X_test)\n",
    "yhat[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25681b46-9566-4a07-980a-2fe5fb43d24e",
   "metadata": {},
   "source": [
    "## Verifying model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e009b-5d00-450c-8145-5d8d8b91ec50",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-02T19:14:07.321263Z",
     "iopub.status.idle": "2023-09-02T19:14:07.321383Z",
     "shell.execute_reply": "2023-09-02T19:14:07.321327Z",
     "shell.execute_reply.started": "2023-09-02T19:14:07.321321Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
