{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0a4f77-cc7e-4a52-a933-0d0ca1a62810",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "* Some words occur very commonly across all documents\n",
    "* Corpus of documents on the universe\n",
    "    * One document has jupiter and universe occurring 20 times each.\n",
    "    * jupiter rarely occurs in the other documents. universe is common.\n",
    "    * Give more weight to jupiter on account of exclusivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3956aa19-9e03-4658-affb-4000c07e59f4",
   "metadata": {},
   "source": [
    "# Applications\n",
    "* Automatically detect stopwords\n",
    "* Search algorithms to determine the ranking of pages\n",
    "* Recommender systems\n",
    "* Better performance in predicted modeling for some cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9de90d-5ded-4e85-b93d-ff4607ece53c",
   "metadata": {},
   "source": [
    "# Term frequency-inverse document frequency\n",
    "> The weight of a term in a document is proportional to term frequency and an inverse function of the number of documents in which it occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993cc225-bb39-4c7f-af95-79c722674409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T20:40:40.066961Z",
     "iopub.status.busy": "2023-01-05T20:40:40.066825Z",
     "iopub.status.idle": "2023-01-05T20:40:40.069750Z",
     "shell.execute_reply": "2023-01-05T20:40:40.069284Z",
     "shell.execute_reply.started": "2023-01-05T20:40:40.066950Z"
    }
   },
   "source": [
    "## Mathematical formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c5f1b-9689-4f37-b26d-47ac71f340b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T20:40:40.066961Z",
     "iopub.status.busy": "2023-01-05T20:40:40.066825Z",
     "iopub.status.idle": "2023-01-05T20:40:40.069750Z",
     "shell.execute_reply": "2023-01-05T20:40:40.069284Z",
     "shell.execute_reply.started": "2023-01-05T20:40:40.066950Z"
    }
   },
   "source": [
    "$$w_{i,j} = tf_{i,j} \\times \\log{\\left(\\frac{N}{df_i}\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f7c056-fd63-4488-ac2d-f01d528a5c89",
   "metadata": {},
   "source": [
    "## tf-idf using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f66027-4073-44ab-a009-5003efb57b57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:07.394716Z",
     "iopub.status.busy": "2023-01-06T01:52:07.394633Z",
     "iopub.status.idle": "2023-01-06T01:52:07.610901Z",
     "shell.execute_reply": "2023-01-06T01:52:07.610495Z",
     "shell.execute_reply.started": "2023-01-06T01:52:07.394706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corpus = pd.Series(\n",
    "    [\n",
    "        \"The lion is the king of the jungle\",\n",
    "        \"Lions have lifespans of a decade\",\n",
    "        \"The lion is an endangered species\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78686d11-332d-418e-b1cf-e7fd2e329755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:07.611771Z",
     "iopub.status.busy": "2023-01-06T01:52:07.611606Z",
     "iopub.status.idle": "2023-01-06T01:52:07.903161Z",
     "shell.execute_reply": "2023-01-06T01:52:07.902748Z",
     "shell.execute_reply.started": "2023-01-06T01:52:07.611760Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3c2b68-3145-47e6-9df4-e035f7ece61c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:07.903771Z",
     "iopub.status.busy": "2023-01-06T01:52:07.903560Z",
     "iopub.status.idle": "2023-01-06T01:52:07.914089Z",
     "shell.execute_reply": "2023-01-06T01:52:07.913823Z",
     "shell.execute_reply.started": "2023-01-06T01:52:07.903759Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>decade</th>\n",
       "      <th>endangered</th>\n",
       "      <th>have</th>\n",
       "      <th>is</th>\n",
       "      <th>jungle</th>\n",
       "      <th>king</th>\n",
       "      <th>lifespans</th>\n",
       "      <th>lion</th>\n",
       "      <th>lions</th>\n",
       "      <th>of</th>\n",
       "      <th>species</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   an  decade  endangered  have  is  jungle  king  lifespans  lion  lions  of  \\\n",
       "0   0       0           0     0   1       1     1          0     1      0   1   \n",
       "1   0       1           0     1   0       0     0          1     0      1   1   \n",
       "2   1       0           1     0   1       0     0          0     1      0   0   \n",
       "\n",
       "   species  the  \n",
       "0        0    3  \n",
       "1        0    0  \n",
       "2        1    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(corpus)\n",
    "pd.DataFrame(count_matrix.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84dbfca-c943-43da-b6c1-ff703f0bd09b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:07.914562Z",
     "iopub.status.busy": "2023-01-06T01:52:07.914457Z",
     "iopub.status.idle": "2023-01-06T01:52:07.923506Z",
     "shell.execute_reply": "2023-01-06T01:52:07.923061Z",
     "shell.execute_reply.started": "2023-01-06T01:52:07.914551Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>decade</th>\n",
       "      <th>endangered</th>\n",
       "      <th>have</th>\n",
       "      <th>is</th>\n",
       "      <th>jungle</th>\n",
       "      <th>king</th>\n",
       "      <th>lifespans</th>\n",
       "      <th>lion</th>\n",
       "      <th>lions</th>\n",
       "      <th>of</th>\n",
       "      <th>species</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254347</td>\n",
       "      <td>0.334435</td>\n",
       "      <td>0.334435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.763040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.355432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.459548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459548</td>\n",
       "      <td>0.349498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         an    decade  endangered      have        is    jungle      king  \\\n",
       "0  0.000000  0.000000    0.000000  0.000000  0.254347  0.334435  0.334435   \n",
       "1  0.000000  0.467351    0.000000  0.467351  0.000000  0.000000  0.000000   \n",
       "2  0.459548  0.000000    0.459548  0.000000  0.349498  0.000000  0.000000   \n",
       "\n",
       "   lifespans      lion     lions        of   species       the  \n",
       "0   0.000000  0.254347  0.000000  0.254347  0.000000  0.763040  \n",
       "1   0.467351  0.000000  0.467351  0.355432  0.000000  0.000000  \n",
       "2   0.000000  0.349498  0.000000  0.000000  0.459548  0.349498  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Generate matrix of word vectors\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fbe1ab-f9cf-4899-80b7-6e0462c4cf48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## tf-idf weight of a word ocurring in all documents\n",
    "\n",
    "The word bottle occurs 5 times in a particular document D and also occurs in every document of the corpus. What is the tf-idf weight of bottle in D?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a7c7b-f84b-450f-a1f8-5aacfd457354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T20:40:40.066961Z",
     "iopub.status.busy": "2023-01-05T20:40:40.066825Z",
     "iopub.status.idle": "2023-01-05T20:40:40.069750Z",
     "shell.execute_reply": "2023-01-05T20:40:40.069284Z",
     "shell.execute_reply.started": "2023-01-05T20:40:40.066950Z"
    }
   },
   "source": [
    "$$w_{i,j} = tf_{i,j} \\times \\log{\\left(\\frac{N}{df_i}\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "881cf5c2-832c-4b81-95b1-7f99b3468d3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:07.923923Z",
     "iopub.status.busy": "2023-01-06T01:52:07.923816Z",
     "iopub.status.idle": "2023-01-06T01:52:07.926278Z",
     "shell.execute_reply": "2023-01-06T01:52:07.925989Z",
     "shell.execute_reply.started": "2023-01-06T01:52:07.923912Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "5 * np.log(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63c764-4e7e-4f0a-ab10-8f3b0576f60a",
   "metadata": {},
   "source": [
    "> This is because the inverse document frequency is constant across documents in a corpus and since bottle occurs in every document, its value is log(1), which is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd50aba-98c1-44cd-a50a-d62ddaac3c56",
   "metadata": {
    "tags": []
   },
   "source": [
    "## tf-idf vectors for TED talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab9ef184-b07d-4c34-ae56-ee2df4752653",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:07.926806Z",
     "iopub.status.busy": "2023-01-06T01:52:07.926638Z",
     "iopub.status.idle": "2023-01-06T01:52:07.965646Z",
     "shell.execute_reply": "2023-01-06T01:52:07.965236Z",
     "shell.execute_reply.started": "2023-01-06T01:52:07.926796Z"
    }
   },
   "outputs": [],
   "source": [
    "ted = pd.read_csv('ted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d3b547-dd8c-4d2a-92a0-17ab4fc5aafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:07.966736Z",
     "iopub.status.busy": "2023-01-06T01:52:07.966629Z",
     "iopub.status.idle": "2023-01-06T01:52:07.971515Z",
     "shell.execute_reply": "2023-01-06T01:52:07.971140Z",
     "shell.execute_reply.started": "2023-01-06T01:52:07.966725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We're going to talk — my — a new lecture, just...</td>\n",
       "      <td>https://www.ted.com/talks/al_seckel_says_our_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a representation of your brain, and yo...</td>\n",
       "      <td>https://www.ted.com/talks/aaron_o_connell_maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's a great honor today to share with you The...</td>\n",
       "      <td>https://www.ted.com/talks/carter_emmart_demos_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My passions are music, technology and making t...</td>\n",
       "      <td>https://www.ted.com/talks/jared_ficklin_new_wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It used to be that if you wanted to get a comp...</td>\n",
       "      <td>https://www.ted.com/talks/jeremy_howard_the_wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Today I'm going to unpack for you three exampl...</td>\n",
       "      <td>https://www.ted.com/talks/john_hodgman_design_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Both myself and my brother belong to the under...</td>\n",
       "      <td>https://www.ted.com/talks/sheikha_al_mayassa_g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>John Hockenberry: It's great to be here with y...</td>\n",
       "      <td>https://www.ted.com/talks/tom_shannon_the_pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>What you're doing, right now, at this very mom...</td>\n",
       "      <td>https://www.ted.com/talks/nilofer_merchant_got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>We've got a real problem with math education r...</td>\n",
       "      <td>https://www.ted.com/talks/conrad_wolfram_teach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transcript  \\\n",
       "0    We're going to talk — my — a new lecture, just...   \n",
       "1    This is a representation of your brain, and yo...   \n",
       "2    It's a great honor today to share with you The...   \n",
       "3    My passions are music, technology and making t...   \n",
       "4    It used to be that if you wanted to get a comp...   \n",
       "..                                                 ...   \n",
       "495  Today I'm going to unpack for you three exampl...   \n",
       "496  Both myself and my brother belong to the under...   \n",
       "497  John Hockenberry: It's great to be here with y...   \n",
       "498  What you're doing, right now, at this very mom...   \n",
       "499  We've got a real problem with math education r...   \n",
       "\n",
       "                                                   url  \n",
       "0    https://www.ted.com/talks/al_seckel_says_our_b...  \n",
       "1    https://www.ted.com/talks/aaron_o_connell_maki...  \n",
       "2    https://www.ted.com/talks/carter_emmart_demos_...  \n",
       "3    https://www.ted.com/talks/jared_ficklin_new_wa...  \n",
       "4    https://www.ted.com/talks/jeremy_howard_the_wo...  \n",
       "..                                                 ...  \n",
       "495  https://www.ted.com/talks/john_hodgman_design_...  \n",
       "496  https://www.ted.com/talks/sheikha_al_mayassa_g...  \n",
       "497  https://www.ted.com/talks/tom_shannon_the_pain...  \n",
       "498  https://www.ted.com/talks/nilofer_merchant_got...  \n",
       "499  https://www.ted.com/talks/conrad_wolfram_teach...  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a6cca1-c5e8-4d82-acba-9d47605945a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:07.972229Z",
     "iopub.status.busy": "2023-01-06T01:52:07.972009Z",
     "iopub.status.idle": "2023-01-06T01:52:08.384096Z",
     "shell.execute_reply": "2023-01-06T01:52:08.383779Z",
     "shell.execute_reply.started": "2023-01-06T01:52:07.972214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000001</th>\n",
       "      <th>00001</th>\n",
       "      <th>000042</th>\n",
       "      <th>0001</th>\n",
       "      <th>000th</th>\n",
       "      <th>001</th>\n",
       "      <th>01</th>\n",
       "      <th>024</th>\n",
       "      <th>...</th>\n",
       "      <th>zywiec</th>\n",
       "      <th>ºf</th>\n",
       "      <th>čapek</th>\n",
       "      <th>ʾan</th>\n",
       "      <th>ʾilla</th>\n",
       "      <th>ʾilāha</th>\n",
       "      <th>อย</th>\n",
       "      <th>อยman</th>\n",
       "      <th>อร</th>\n",
       "      <th>送你葱</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 29158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00       000  000001  00001  000042  0001  000th  001   01  024  ...  \\\n",
       "0    0.0  0.000000     0.0    0.0     0.0   0.0    0.0  0.0  0.0  0.0  ...   \n",
       "1    0.0  0.000000     0.0    0.0     0.0   0.0    0.0  0.0  0.0  0.0  ...   \n",
       "2    0.0  0.000000     0.0    0.0     0.0   0.0    0.0  0.0  0.0  0.0  ...   \n",
       "3    0.0  0.000000     0.0    0.0     0.0   0.0    0.0  0.0  0.0  0.0  ...   \n",
       "4    0.0  0.012900     0.0    0.0     0.0   0.0    0.0  0.0  0.0  0.0  ...   \n",
       "..   ...       ...     ...    ...     ...   ...    ...  ...  ...  ...  ...   \n",
       "495  0.0  0.000000     0.0    0.0     0.0   0.0    0.0  0.0  0.0  0.0  ...   \n",
       "496  0.0  0.008076     0.0    0.0     0.0   0.0    0.0  0.0  0.0  0.0  ...   \n",
       "497  0.0  0.000000     0.0    0.0     0.0   0.0    0.0  0.0  0.0  0.0  ...   \n",
       "498  0.0  0.000000     0.0    0.0     0.0   0.0    0.0  0.0  0.0  0.0  ...   \n",
       "499  0.0  0.000000     0.0    0.0     0.0   0.0    0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "     zywiec   ºf  čapek  ʾan  ʾilla  ʾilāha   อย  อยman   อร  送你葱  \n",
       "0       0.0  0.0    0.0  0.0    0.0     0.0  0.0    0.0  0.0  0.0  \n",
       "1       0.0  0.0    0.0  0.0    0.0     0.0  0.0    0.0  0.0  0.0  \n",
       "2       0.0  0.0    0.0  0.0    0.0     0.0  0.0    0.0  0.0  0.0  \n",
       "3       0.0  0.0    0.0  0.0    0.0     0.0  0.0    0.0  0.0  0.0  \n",
       "4       0.0  0.0    0.0  0.0    0.0     0.0  0.0    0.0  0.0  0.0  \n",
       "..      ...  ...    ...  ...    ...     ...  ...    ...  ...  ...  \n",
       "495     0.0  0.0    0.0  0.0    0.0     0.0  0.0    0.0  0.0  0.0  \n",
       "496     0.0  0.0    0.0  0.0    0.0     0.0  0.0    0.0  0.0  0.0  \n",
       "497     0.0  0.0    0.0  0.0    0.0     0.0  0.0    0.0  0.0  0.0  \n",
       "498     0.0  0.0    0.0  0.0    0.0     0.0  0.0    0.0  0.0  0.0  \n",
       "499     0.0  0.0    0.0  0.0    0.0     0.0  0.0    0.0  0.0  0.0  \n",
       "\n",
       "[500 rows x 29158 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(ted['transcript'])\n",
    "pd.DataFrame(tfidf_matrix.A, columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a380d41c-e468-4074-86a9-26a5b1b148a7",
   "metadata": {},
   "source": [
    "# Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d83841-b269-42cb-9c9a-694e5c00a334",
   "metadata": {},
   "source": [
    "We now know how to compute vectors out of text documents. With this representation in mind, let us now explore techniques that will allow us to determine how similar two vectors and consequentially two documents, are to each other. More specifically, we will learn about the cosine similarity score which is one of the most popularly used similarity metrics in NLP. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147a841-cae2-434b-a4aa-834ab1f671f8",
   "metadata": {},
   "source": [
    "## Mathematical formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4687b524-d1af-4e3d-bc15-78785bc20d99",
   "metadata": {},
   "source": [
    "Very simply put, the cosine similarity score of two vectors is the cosine of the angle between the vectors. Mathematically, it is the ratio of the dot product of the vectors and the product of the magnitude of the two vectors. Let's walk through what this formula really means. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8663b5a-69ad-4f89-b13e-d662d728a174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T21:01:39.996258Z",
     "iopub.status.busy": "2023-01-05T21:01:39.996123Z",
     "iopub.status.idle": "2023-01-05T21:01:39.998827Z",
     "shell.execute_reply": "2023-01-05T21:01:39.998391Z",
     "shell.execute_reply.started": "2023-01-05T21:01:39.996248Z"
    }
   },
   "source": [
    "$$ similarity(\\vec{A},\\vec{B}) = \\cos{(\\theta)} = \\frac{\\vec{A} \\cdot \\vec{B}}{||\\vec{A}|| \\times ||\\vec{B}||}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6f6e1-01a4-4494-a272-e54d417ac202",
   "metadata": {},
   "source": [
    "## The dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1de218d-bea7-418f-9f22-2613d672df50",
   "metadata": {},
   "source": [
    "Consider two vectors,\n",
    "$$\\vec{V} = (v_1 , v_2 , ⋯ , v_n ), \\vec{W} = (w_1 , w_2 , ⋯ , w_n)$$\n",
    "\n",
    "Then the dot product of V and W is,\n",
    "$$\\vec{V} \\cdot \\vec{W} = (v_1 \\times w_1 ) + (v_2 \\times w_2 ) + ⋯ + (v \\times w )$$\n",
    "\n",
    "Example:\n",
    "\n",
    "$$\\vec{A} = (4, 7, 1), \\vec{B} = (5, 2, 3)$$\n",
    "$$\\vec{A} \\cdot \\vec{B} = (4 \\times 5) + (7 \\times 2) + ⋯ (1 \\times 3)$$\n",
    "$$ = 20 + 14 + 3 = 37$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07a5d89c-f42a-4719-9718-b1368821185a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.384579Z",
     "iopub.status.busy": "2023-01-06T01:52:08.384476Z",
     "iopub.status.idle": "2023-01-06T01:52:08.387416Z",
     "shell.execute_reply": "2023-01-06T01:52:08.387169Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.384569Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A:=np.array([4,7,1]), B:=np.array([5,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e49c8b-b2e4-495f-85cb-3e98564cf1bc",
   "metadata": {},
   "source": [
    "## Magnitude of a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f228fb-be23-477c-8e90-0b0f395886d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T21:29:43.962551Z",
     "iopub.status.busy": "2023-01-05T21:29:43.962416Z",
     "iopub.status.idle": "2023-01-05T21:29:43.965115Z",
     "shell.execute_reply": "2023-01-05T21:29:43.964665Z",
     "shell.execute_reply.started": "2023-01-05T21:29:43.962541Z"
    }
   },
   "source": [
    "For any vector,\n",
    "$$\\vec{V} = (v_1 , v_2 , ⋯ , v_n)$$\n",
    "The magnitude is defined as,\n",
    "$$||\\vec{V}|| = \\sqrt{(v_1^2 , v_2^2 , ⋯ , v_n^2)}$$\n",
    "Example:\n",
    "$$\\vec{A} = (4,7,1), \\vec{B} = (5,2,3)$$\n",
    "$$||\\vec{A}|| = \\sqrt{(4)^2 + (7)^2 + (1)^2} = \\sqrt{16+49+1} = \\sqrt{66}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47761b6c-6bf9-482f-bfc2-f657e6286888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.387921Z",
     "iopub.status.busy": "2023-01-06T01:52:08.387774Z",
     "iopub.status.idle": "2023-01-06T01:52:08.391559Z",
     "shell.execute_reply": "2023-01-06T01:52:08.391233Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.387905Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.12403840463596"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06bf5a3-1cdd-40a5-aa6b-eff69bd3ba01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T21:29:43.962551Z",
     "iopub.status.busy": "2023-01-05T21:29:43.962416Z",
     "iopub.status.idle": "2023-01-05T21:29:43.965115Z",
     "shell.execute_reply": "2023-01-05T21:29:43.964665Z",
     "shell.execute_reply.started": "2023-01-05T21:29:43.962541Z"
    }
   },
   "source": [
    "$$||\\vec{B}|| = \\sqrt{(5)^2 + (2)^2 + (3)^2} = \\sqrt{25+4+9} = \\sqrt{38}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e88cb05a-0cb7-4297-a7ca-a6821f8d9a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.392323Z",
     "iopub.status.busy": "2023-01-06T01:52:08.392055Z",
     "iopub.status.idle": "2023-01-06T01:52:08.394993Z",
     "shell.execute_reply": "2023-01-06T01:52:08.394631Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.392306Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.164414002968976"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e105b-df4f-4ca3-a56a-492fd2b4b99b",
   "metadata": {},
   "source": [
    "## The cosine score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baacc56-8fed-430c-b71c-7b7732cfc742",
   "metadata": {},
   "source": [
    "$$\\cos{(\\theta)} = cos(\\vec{A},\\vec{B}) = \\frac{\\vec{A} \\cdot \\vec{B}}{||\\vec{A}|| \\times ||\\vec{B}||} = \\frac{37}{\\sqrt{66}\\times\\sqrt{38}} \\sim 0.7388$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4beb114f-b72d-4ba4-9539-552a733baaba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.395645Z",
     "iopub.status.busy": "2023-01-06T01:52:08.395491Z",
     "iopub.status.idle": "2023-01-06T01:52:08.398894Z",
     "shell.execute_reply": "2023-01-06T01:52:08.398572Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.395629Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7388188340435563"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cda671-5800-44df-a1a2-714ef95064be",
   "metadata": {},
   "source": [
    "## Cosine Score: points to remember\n",
    "* Value between -1 and 1.\n",
    "* In NLP, value between 0 and 1 because term frequencies are positive.\n",
    "* Robust to document length: since the cosine score ignores the magnitude of the vectors, it is fairly robust to document length. This may be an advantage or a disadvantage depending on the use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7135519-0ec5-41bd-b444-bc4baa73fde2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.399661Z",
     "iopub.status.busy": "2023-01-06T01:52:08.399410Z",
     "iopub.status.idle": "2023-01-06T01:52:08.418279Z",
     "shell.execute_reply": "2023-01-06T01:52:08.418032Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.399643Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73881883])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity([A],[B])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba48591-574c-46dd-9100-f5e2b870da5c",
   "metadata": {},
   "source": [
    "## Cosine similarity matrix of a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5514e35-2fb9-4e06-880b-6ed4343e3e60",
   "metadata": {},
   "source": [
    "Compute the cosine similarity matrix which contains the pairwise cosine similarity score for every pair of sentences (vectorized using tf-idf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33bd86fd-b6c5-4210-99b0-65e9f21690b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.418827Z",
     "iopub.status.busy": "2023-01-06T01:52:08.418630Z",
     "iopub.status.idle": "2023-01-06T01:52:08.421664Z",
     "shell.execute_reply": "2023-01-06T01:52:08.421253Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.418817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The sun is the largest celestial body in the solar system',\n",
       " 'The solar system consists of the sun and eight revolving planets',\n",
       " 'Ra was the Egyptian Sun God',\n",
       " 'The Pyramids were the pinnacle of Egyptian architecture',\n",
       " 'The quick brown fox jumps over the lazy dog']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = ['The sun is the largest celestial body in the solar system', 'The solar system consists of the sun and eight revolving planets', 'Ra was the Egyptian Sun God', 'The Pyramids were the pinnacle of Egyptian architecture', 'The quick brown fox jumps over the lazy dog']\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73ad8eec-ad12-4724-974f-79dac7c7885d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.422437Z",
     "iopub.status.busy": "2023-01-06T01:52:08.422178Z",
     "iopub.status.idle": "2023-01-06T01:52:08.438844Z",
     "shell.execute_reply": "2023-01-06T01:52:08.438473Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.422420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>architecture</th>\n",
       "      <th>body</th>\n",
       "      <th>brown</th>\n",
       "      <th>celestial</th>\n",
       "      <th>consists</th>\n",
       "      <th>dog</th>\n",
       "      <th>egyptian</th>\n",
       "      <th>eight</th>\n",
       "      <th>fox</th>\n",
       "      <th>...</th>\n",
       "      <th>pyramids</th>\n",
       "      <th>quick</th>\n",
       "      <th>ra</th>\n",
       "      <th>revolving</th>\n",
       "      <th>solar</th>\n",
       "      <th>sun</th>\n",
       "      <th>system</th>\n",
       "      <th>the</th>\n",
       "      <th>was</th>\n",
       "      <th>were</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272065</td>\n",
       "      <td>0.225839</td>\n",
       "      <td>0.272065</td>\n",
       "      <td>0.482058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.346907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346907</td>\n",
       "      <td>0.279882</td>\n",
       "      <td>0.232328</td>\n",
       "      <td>0.279882</td>\n",
       "      <td>0.330606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229087</td>\n",
       "      <td>0.480764</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  architecture      body     brown  celestial  consists       dog  \\\n",
       "0  0.000000      0.000000  0.337218  0.000000   0.337218  0.000000  0.000000   \n",
       "1  0.346907      0.000000  0.000000  0.000000   0.000000  0.346907  0.000000   \n",
       "2  0.000000      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "3  0.000000      0.401284  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "4  0.000000      0.000000  0.000000  0.355599   0.000000  0.000000  0.355599   \n",
       "\n",
       "   egyptian     eight       fox  ...  pyramids     quick        ra  revolving  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   0.000000   \n",
       "1  0.000000  0.346907  0.000000  ...  0.000000  0.000000  0.000000   0.346907   \n",
       "2  0.387878  0.000000  0.000000  ...  0.000000  0.000000  0.480764   0.000000   \n",
       "3  0.323754  0.000000  0.000000  ...  0.401284  0.000000  0.000000   0.000000   \n",
       "4  0.000000  0.000000  0.355599  ...  0.000000  0.355599  0.000000   0.000000   \n",
       "\n",
       "      solar       sun    system       the       was      were  \n",
       "0  0.272065  0.225839  0.272065  0.482058  0.000000  0.000000  \n",
       "1  0.279882  0.232328  0.279882  0.330606  0.000000  0.000000  \n",
       "2  0.000000  0.321974  0.000000  0.229087  0.480764  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.382428  0.000000  0.401284  \n",
       "4  0.000000  0.000000  0.000000  0.338890  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an instance of tf-idf Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Generate the tf-idf vectors for the corpus\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "pd.DataFrame(tfidf_matrix.A, columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd3c32e1-5cf0-4af8-bad6-3ccccaabc55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.439621Z",
     "iopub.status.busy": "2023-01-06T01:52:08.439378Z",
     "iopub.status.idle": "2023-01-06T01:52:08.443107Z",
     "shell.execute_reply": "2023-01-06T01:52:08.442735Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.439605Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.36413198, 0.18314713, 0.18435251, 0.16336438],\n",
       "       [0.36413198, 1.        , 0.15054075, 0.21704584, 0.11203887],\n",
       "       [0.18314713, 0.15054075, 1.        , 0.21318602, 0.07763512],\n",
       "       [0.18435251, 0.21704584, 0.21318602, 1.        , 0.12960089],\n",
       "       [0.16336438, 0.11203887, 0.07763512, 0.12960089, 1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475c2d1-ff74-4944-9da2-0a2b884c6b8a",
   "metadata": {},
   "source": [
    "> The cosine similarity matrix lies at the heart of many practical systems such as recommenders. From our similarity matrix, we see that the first and the second sentence are the most similar. Also the fifth sentence has, on average, the lowest pairwise cosine scores. This is intuitive as it contains entities that are not present in the other sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd2ac2-de45-422b-8396-5b1daa298c29",
   "metadata": {},
   "source": [
    "# Building a plot line based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38ae2c44-e054-46e0-a69d-2549defb5d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.443882Z",
     "iopub.status.busy": "2023-01-06T01:52:08.443648Z",
     "iopub.status.idle": "2023-01-06T01:52:08.480246Z",
     "shell.execute_reply": "2023-01-06T01:52:08.479974Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.443867Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>tagline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9094</th>\n",
       "      <td>159550</td>\n",
       "      <td>The Last Brickmaker in America</td>\n",
       "      <td>A man must cope with the loss of his wife and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9095</th>\n",
       "      <td>392572</td>\n",
       "      <td>Rustom</td>\n",
       "      <td>Rustom Pavri, an honourable officer of the Ind...</td>\n",
       "      <td>Decorated Officer. Devoted Family Man. Defendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096</th>\n",
       "      <td>402672</td>\n",
       "      <td>Mohenjo Daro</td>\n",
       "      <td>Village lad Sarman is drawn to big, bad Mohenj...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9097</th>\n",
       "      <td>315011</td>\n",
       "      <td>Shin Godzilla</td>\n",
       "      <td>From the mind behind Evangelion comes a hit la...</td>\n",
       "      <td>A god incarnate. A city doomed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9098</th>\n",
       "      <td>391698</td>\n",
       "      <td>The Beatles: Eight Days a Week - The Touring Y...</td>\n",
       "      <td>The band stormed Europe in 1963, and, in 1964,...</td>\n",
       "      <td>The band you know. The story you don't.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9099 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0        862                                          Toy Story   \n",
       "1       8844                                            Jumanji   \n",
       "2      15602                                   Grumpier Old Men   \n",
       "3      31357                                  Waiting to Exhale   \n",
       "4      11862                        Father of the Bride Part II   \n",
       "...      ...                                                ...   \n",
       "9094  159550                     The Last Brickmaker in America   \n",
       "9095  392572                                             Rustom   \n",
       "9096  402672                                       Mohenjo Daro   \n",
       "9097  315011                                      Shin Godzilla   \n",
       "9098  391698  The Beatles: Eight Days a Week - The Touring Y...   \n",
       "\n",
       "                                               overview  \\\n",
       "0     Led by Woody, Andy's toys live happily in his ...   \n",
       "1     When siblings Judy and Peter discover an encha...   \n",
       "2     A family wedding reignites the ancient feud be...   \n",
       "3     Cheated on, mistreated and stepped on, the wom...   \n",
       "4     Just when George Banks has recovered from his ...   \n",
       "...                                                 ...   \n",
       "9094  A man must cope with the loss of his wife and ...   \n",
       "9095  Rustom Pavri, an honourable officer of the Ind...   \n",
       "9096  Village lad Sarman is drawn to big, bad Mohenj...   \n",
       "9097  From the mind behind Evangelion comes a hit la...   \n",
       "9098  The band stormed Europe in 1963, and, in 1964,...   \n",
       "\n",
       "                                                tagline  \n",
       "0                                                   NaN  \n",
       "1             Roll the dice and unleash the excitement!  \n",
       "2     Still Yelling. Still Fighting. Still Ready for...  \n",
       "3     Friends are the people who let you be yourself...  \n",
       "4     Just When His World Is Back To Normal... He's ...  \n",
       "...                                                 ...  \n",
       "9094                                                NaN  \n",
       "9095  Decorated Officer. Devoted Family Man. Defendi...  \n",
       "9096                                                NaN  \n",
       "9097                    A god incarnate. A city doomed.  \n",
       "9098            The band you know. The story you don't.  \n",
       "\n",
       "[9099 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "movies = pd.read_csv('movie_overviews.csv')\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c5402-db87-413f-9323-37a826b58164",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Text preprocessing\n",
    "2. Generate tf-idf vectors\n",
    "3. Generate cosine similarity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878be6c4-4892-4913-8591-e6083c63e14b",
   "metadata": {},
   "source": [
    "## The recommender function\n",
    "1. Take a movie title, cosine similarity matrix and indices series as arguments.\n",
    "2. Extract pairwise cosine similarity scores for the movie.\n",
    "3. Sort the scores in descending order.\n",
    "4. Output titles corresponding to the highest scores.\n",
    "5. Ignore the highest similarity score (of 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9237a-df5e-4f02-976e-68b22647ec85",
   "metadata": {},
   "source": [
    "## Generating tf-idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "493d1a9d-7607-4bdd-96ba-8c366a251687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.481035Z",
     "iopub.status.busy": "2023-01-06T01:52:08.480740Z",
     "iopub.status.idle": "2023-01-06T01:52:08.679608Z",
     "shell.execute_reply": "2023-01-06T01:52:08.679225Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.481020Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9099, 30020)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Generate matrix of tf-idf vectors\n",
    "tfidf_matrix = vectorizer.fit_transform(movies['overview'].fillna(''))\n",
    "# pd.DataFrame(tfidf_matrix.A, columns=vectorizer.get_feature_names_out())\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b521150-c653-4c59-8984-4543eef7d7c2",
   "metadata": {},
   "source": [
    "## Generating cosine similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605510a7-8cfa-49d0-ad2a-a1db4003b45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.680118Z",
     "iopub.status.busy": "2023-01-06T01:52:08.680012Z",
     "iopub.status.idle": "2023-01-06T01:52:08.681810Z",
     "shell.execute_reply": "2023-01-06T01:52:08.681520Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.680107Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Generate cosine similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fffb769-6f55-40b4-b7a6-6907fe31ff77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:08.682314Z",
     "iopub.status.busy": "2023-01-06T01:52:08.682155Z",
     "iopub.status.idle": "2023-01-06T01:52:10.200776Z",
     "shell.execute_reply": "2023-01-06T01:52:10.200444Z",
     "shell.execute_reply.started": "2023-01-06T01:52:08.682304Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cosine_sim1 = cosine_similarity(tfidf_matrix, tfidf_matrix, dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fa9d38c-a70a-44c8-93dc-4d9190f86345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:10.201254Z",
     "iopub.status.busy": "2023-01-06T01:52:10.201151Z",
     "iopub.status.idle": "2023-01-06T01:52:10.649646Z",
     "shell.execute_reply": "2023-01-06T01:52:10.649305Z",
     "shell.execute_reply.started": "2023-01-06T01:52:10.201243Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity: 0.031205929594335755\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean similarity: {cosine_sim1.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4de62-0650-4d6b-91c5-c9d1679df42d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The `linear_kernel` function\n",
    "\n",
    "* Magnitude of a tf-idf vector is always 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c55ceff7-268f-4dbf-804b-9c796b962858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:10.651153Z",
     "iopub.status.busy": "2023-01-06T01:52:10.651044Z",
     "iopub.status.idle": "2023-01-06T01:52:11.049848Z",
     "shell.execute_reply": "2023-01-06T01:52:11.049555Z",
     "shell.execute_reply.started": "2023-01-06T01:52:10.651143Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985712715683042"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking whether the magnitude of a tf-idf vector is 1\n",
    "magnitude = np.apply_along_axis(func1d=np.linalg.norm, axis=1, arr=tfidf_matrix.A).mean()\n",
    "magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb93b0e-569d-4066-b98d-a721b48aa810",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Since the magnitude is 1, the cosine score of two tf-idf vectors is equal to their dot product!\n",
    "$$ \\cos{(\\theta)} = \\frac{\\vec{A} \\cdot \\vec{B}}{||\\vec{A}|| \\times ||\\vec{B}||} = \\frac{\\vec{A} \\cdot \\vec{B}}{1 \\times 1} = \\vec{A} \\cdot \\vec{B}$$\n",
    "* Cosine similarity, or the cosine kernel, computes similarity as the normalized dot product of X and Y\n",
    "    * On L2-normalized data, this function is equivalent to `linear_kernel`.\n",
    "* Can significantly improve computation time.\n",
    "* Use `linear_kernel` instead of `cosine_similarity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "feb4c1f6-e082-4a15-ad9c-d93d201a57a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:11.050335Z",
     "iopub.status.busy": "2023-01-06T01:52:11.050229Z",
     "iopub.status.idle": "2023-01-06T01:52:12.573486Z",
     "shell.execute_reply": "2023-01-06T01:52:12.573043Z",
     "shell.execute_reply.started": "2023-01-06T01:52:11.050325Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking whether cosine_similarity() is like matmul (@)\n",
    "cosine_sim2 = tfidf_matrix @ tfidf_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31c94155-a5aa-40e3-9f74-084558cee882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:12.573993Z",
     "iopub.status.busy": "2023-01-06T01:52:12.573885Z",
     "iopub.status.idle": "2023-01-06T01:52:13.491391Z",
     "shell.execute_reply": "2023-01-06T01:52:13.490974Z",
     "shell.execute_reply.started": "2023-01-06T01:52:12.573981Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim1.mean() == cosine_sim2.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f143eafe-99d8-44b6-981d-4810b81c943a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:13.491860Z",
     "iopub.status.busy": "2023-01-06T01:52:13.491756Z",
     "iopub.status.idle": "2023-01-06T01:52:13.493652Z",
     "shell.execute_reply": "2023-01-06T01:52:13.493345Z",
     "shell.execute_reply.started": "2023-01-06T01:52:13.491849Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "# Generate cosine similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08f5e124-b118-4a35-bd03-ffc25ffea4ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:13.494027Z",
     "iopub.status.busy": "2023-01-06T01:52:13.493932Z",
     "iopub.status.idle": "2023-01-06T01:52:15.012603Z",
     "shell.execute_reply": "2023-01-06T01:52:15.012184Z",
     "shell.execute_reply.started": "2023-01-06T01:52:13.494017Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cosine_sim3 = linear_kernel(tfidf_matrix, tfidf_matrix, dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df55c32a-33e2-4f50-ba9c-12621f3efa0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:15.013087Z",
     "iopub.status.busy": "2023-01-06T01:52:15.012986Z",
     "iopub.status.idle": "2023-01-06T01:52:15.925666Z",
     "shell.execute_reply": "2023-01-06T01:52:15.925400Z",
     "shell.execute_reply.started": "2023-01-06T01:52:15.013077Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim2.mean() == cosine_sim3.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8a704-2b98-42ad-842c-f5243bfbf4b1",
   "metadata": {},
   "source": [
    "## Plot recommendation engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f4a0ffe-a5ad-4c8e-9424-8868cf55f3e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:15.926131Z",
     "iopub.status.busy": "2023-01-06T01:52:15.926028Z",
     "iopub.status.idle": "2023-01-06T01:52:15.948711Z",
     "shell.execute_reply": "2023-01-06T01:52:15.948300Z",
     "shell.execute_reply.started": "2023-01-06T01:52:15.926121Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies = pd.read_csv('movie_overviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44ce0b02-6803-472b-ab28-950bb07015c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:15.949190Z",
     "iopub.status.busy": "2023-01-06T01:52:15.949089Z",
     "iopub.status.idle": "2023-01-06T01:52:15.953173Z",
     "shell.execute_reply": "2023-01-06T01:52:15.952754Z",
     "shell.execute_reply.started": "2023-01-06T01:52:15.949180Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# indices\n",
    "indices = movies.reset_index(drop=False).set_index('title')['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de58b181-0b41-4a11-829d-e3eb9ccaf2e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:15.953629Z",
     "iopub.status.busy": "2023-01-06T01:52:15.953528Z",
     "iopub.status.idle": "2023-01-06T01:52:16.126701Z",
     "shell.execute_reply": "2023-01-06T01:52:16.126364Z",
     "shell.execute_reply.started": "2023-01-06T01:52:15.953619Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer \n",
    "tfidf_matrix = TfidfVectorizer(stop_words='english').fit_transform(movies['overview'].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a078df28-971c-4917-b3f3-3e225d483bf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:16.127154Z",
     "iopub.status.busy": "2023-01-06T01:52:16.127053Z",
     "iopub.status.idle": "2023-01-06T01:52:16.535956Z",
     "shell.execute_reply": "2023-01-06T01:52:16.535537Z",
     "shell.execute_reply.started": "2023-01-06T01:52:16.127144Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cosine simililarity\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0f06fe2-9272-46a8-8161-2dc13a7dad16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:16.536426Z",
     "iopub.status.busy": "2023-01-06T01:52:16.536326Z",
     "iopub.status.idle": "2023-01-06T01:52:16.539246Z",
     "shell.execute_reply": "2023-01-06T01:52:16.538954Z",
     "shell.execute_reply.started": "2023-01-06T01:52:16.536416Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim, indices):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "    # Get the pairwsie similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Get the scores for 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    # Return the top 10 most similar movies\n",
    "    return movies['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fb62f2a-9eef-441e-b00b-eaccf32a50f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:52:16.539751Z",
     "iopub.status.busy": "2023-01-06T01:52:16.539589Z",
     "iopub.status.idle": "2023-01-06T01:52:16.546204Z",
     "shell.execute_reply": "2023-01-06T01:52:16.545955Z",
     "shell.execute_reply.started": "2023-01-06T01:52:16.539740Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132                              Batman Forever\n",
       "6907                            The Dark Knight\n",
       "1116                             Batman Returns\n",
       "7573                 Batman: Under the Red Hood\n",
       "524                                      Batman\n",
       "7907                           Batman: Year One\n",
       "8171    Batman: The Dark Knight Returns, Part 1\n",
       "2581               Batman: Mask of the Phantasm\n",
       "8232    Batman: The Dark Knight Returns, Part 2\n",
       "6150                              Batman Begins\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(title='The Dark Knight Rises',\n",
    "                    cosine_sim=cosine_sim,\n",
    "                    indices=indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f1790-046b-42fa-a976-805844c77c28",
   "metadata": {},
   "source": [
    "# Beyond n-grams: word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a2f57-2458-434e-87da-c4ba895f86dd",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "* Mapping words into an n-dimensional vector space\n",
    "* Produced using deep learning and huge amounts of data\n",
    "* Discern how similar two words are to each other\n",
    "* Used to detect synonyms and antonyms\n",
    "* Captures complex relationships\n",
    "    * King - Queen → Man - Woman\n",
    "    * France - Paris → Russia - Moscow\n",
    "* Dependent on pre-trained spacy model; independent of dataset you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a89af2d-87ff-436f-8935-cb52eb0517c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:56:49.417782Z",
     "iopub.status.busy": "2023-01-06T01:56:49.417645Z",
     "iopub.status.idle": "2023-01-06T01:56:49.420635Z",
     "shell.execute_reply": "2023-01-06T01:56:49.420396Z",
     "shell.execute_reply.started": "2023-01-06T01:56:49.417772Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# Load model and create Doc object\n",
    "spacy.require_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91740fd2-18b7-43e6-a8ed-a0a1f8a2a252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:56:50.908691Z",
     "iopub.status.busy": "2023-01-06T01:56:50.908482Z",
     "iopub.status.idle": "2023-01-06T01:56:51.663703Z",
     "shell.execute_reply": "2023-01-06T01:56:51.663277Z",
     "shell.execute_reply.started": "2023-01-06T01:56:50.908679Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.8607     0.15804   -4.1425    -8.6359   -16.955      1.157\n",
      "  -1.588      5.6609   -12.03      16.417      4.1907     5.5122\n",
      "  -0.11932   -6.06       3.8957    -7.8212     3.6736   -14.824\n",
      "  -7.6638     2.5344     7.9893     3.6785     4.3296   -11.338\n",
      "  -3.5506    -5.899      1.0998     3.4515    -5.4191     1.8356\n",
      "  -2.902     -7.9294    -1.1269     8.4124     5.1416    -3.1489\n",
      "  -4.2061    -1.459      7.8313     0.27859   -4.3832     8.0756\n",
      "  -0.94784   -6.1214     8.2792     5.0529    -8.3611    -6.0743\n",
      "  -0.53773    2.7538     3.8162    -4.1612     0.7591    -2.8374\n",
      "  -6.4851    -3.3435     3.2703     2.759      2.6645     4.0013\n",
      "  13.381     -5.2907    -3.133      4.5374   -11.899     -6.716\n",
      "  -0.041939  -2.0879     3.0101    10.3        2.6835     2.7265\n",
      "   8.3018    -4.4563    14.43       3.9642    -4.8287    -5.648\n",
      "  -7.2597   -11.475     -2.6171     0.3325    14.454     -5.155\n",
      "   0.93722   -2.6187    -1.783      3.8711     1.4681    -6.705\n",
      "  -4.0953    -0.22536    9.444    -10.305     -0.13202   -2.5534\n",
      "   0.36113   -8.539      2.6755    -2.5872     2.8679     9.7515\n",
      "  -2.1221     0.82061  -10.319      1.1547    -6.5808     4.9236\n",
      "  -5.0744    -1.4781    -4.9195    -8.3767     9.5575    -3.685\n",
      "   2.1198    -0.17453    2.0831    -3.9546     1.0606     2.7273\n",
      "  -3.8842    -1.3651    -9.3881     8.7217     0.36486    6.9968\n",
      "   5.9808    -1.9575    -4.9097     0.17648    0.82424    3.5459\n",
      "   0.63201   -5.3636     0.18387    5.3658    -7.0217    -6.1577\n",
      "  12.318     -9.2032    -3.8502    -2.3115     3.8475     1.1169\n",
      " -19.406      1.3987     4.8752    -1.3337   -10.459    -10.679\n",
      "  -8.125      1.8708    -8.5214    -5.3364    -1.5602     1.5305\n",
      "   7.3319     1.4623    -4.2276     3.925     -3.6453    -8.9947\n",
      "  -9.9602     4.5267    -2.8874     3.9509     0.33015   -0.69045\n",
      "  -8.5682     5.6035     4.4303    -0.12195   -9.1766     7.1214\n",
      "  11.119    -13.376    -11.446     -4.6233     2.5693     1.0571\n",
      "  -3.7533     2.1846    11.634     -0.71756   -3.1931     9.6407\n",
      "  -0.97389   -9.5713     7.6816     6.216     -3.557      8.6693\n",
      "  -9.1699     6.9589    -3.7244    -1.4941   -11.266      3.6515\n",
      "  -6.93      13.741     -5.546      1.3314    -3.5116     4.2548\n",
      "  -4.1717     0.6486    13.1       -5.2464    -2.2528    -4.0023\n",
      "   0.80613    0.41242    5.1636     6.016    -11.018      2.5725\n",
      "  -5.4786     3.9834     1.7688     1.0016    -6.0102     0.75538\n",
      "  -3.0043     5.4985     5.7801    -7.1877    -0.80729    3.1282\n",
      "   0.39466    2.0783   -17.384     -7.25       3.3675    -2.8671\n",
      "  -4.7587     2.5144    -8.2825    13.736     -0.033851  -6.3096\n",
      " -17.447     -2.4643     5.0504     0.05487    8.3954    -7.3362\n",
      "   6.2495    -0.50043   13.246      4.4032    -5.1087     8.4952\n",
      " -11.692      1.8684    -4.0402    -7.5522    -3.1862     1.7126\n",
      "  -8.6044     7.4476     9.7846     4.0875     6.8338     7.4497\n",
      "   6.187     -5.592      4.6493     0.78633  -10.055      5.5839\n",
      "  -5.2267    -3.3644   -14.551      2.5234    -4.6496    -5.5413\n",
      "  -0.79268   -9.7865     2.4501    -0.26537  -15.947    -10.645\n",
      "   3.9164     1.9886     9.6709    -1.5746     1.333      1.628\n",
      "  -3.5716     2.7336     9.7687     1.9344     4.3976    -2.1922\n",
      "  -4.7053     0.61891    8.0963     7.9379   -11.57       4.3334  ]\n",
      "[ 8.3869e+00 -7.2075e+00  2.3706e+00 -1.1738e+01 -1.1974e+01  5.3761e+00\n",
      " -9.9660e+00  1.1431e+01 -7.5086e+00  8.4296e+00  3.4408e+00 -2.6037e-01\n",
      "  5.6193e+00 -2.2490e+00  6.6699e+00  6.7404e+00  5.9742e-01 -9.2806e+00\n",
      "  2.3533e+00  5.2523e+00  6.0303e+00  1.0061e+01 -1.4558e+01 -2.4992e+00\n",
      " -2.2138e+00  1.3396e+00 -5.9991e-01  8.9889e-01  1.6407e+00 -1.2971e+01\n",
      " -6.4929e+00  7.1568e+00 -1.2418e+01 -3.1108e+00 -7.1099e+00  1.5284e+01\n",
      "  5.5889e+00 -1.7614e+00  1.7298e+01  1.1384e+01 -4.3353e+00  1.0056e+01\n",
      "  1.9498e-01 -9.9001e+00 -3.9718e+00 -4.4642e-01  9.8552e+00 -9.5914e-01\n",
      " -3.8020e+00 -5.0123e+00  1.2988e+01  2.6711e+00  7.9438e+00 -6.2004e+00\n",
      " -1.8386e+00  1.5090e+00  8.7065e+00 -2.7585e+00 -1.3565e+00  7.5341e+00\n",
      "  1.3944e+01  2.4971e+00 -2.6668e+00  2.3929e+00 -1.4486e+01  2.4427e+00\n",
      "  2.8312e+00  4.4812e+00  1.3152e+01  2.7047e+00 -2.0325e+00  1.1106e+00\n",
      "  1.1329e+01 -8.3772e+00  4.3435e+00 -1.0533e+01  2.4561e+00  1.8225e+00\n",
      " -4.8650e-01 -4.9198e+00  2.0593e+00 -1.0526e+01  3.6286e+00 -7.8267e+00\n",
      " -4.7401e+00 -3.3364e+00  7.6566e-01 -1.6490e+00  1.9645e+00 -1.0348e+01\n",
      "  4.0577e+00 -9.5178e+00  1.8217e+00 -8.6321e+00 -2.2617e+00  8.2407e+00\n",
      " -4.2805e+00 -1.2635e+01  1.5002e+00 -1.5028e+01 -1.2967e+00  8.8444e-01\n",
      " -1.0508e+01 -1.1794e+01 -5.9872e+00 -2.0147e+00 -4.5813e+00  3.1173e+00\n",
      " -4.9756e+00  8.7460e+00 -7.2064e+00 -2.1144e+01 -1.3713e+00 -6.6397e+00\n",
      " -1.3918e+00  5.3078e-02 -1.0120e+01 -3.5015e+00 -2.7846e-01  1.4919e+00\n",
      " -6.5164e+00  2.8868e+00 -3.9307e+00  1.4120e+01 -6.2467e-01 -3.1941e+00\n",
      "  4.0083e+00 -9.5383e-01 -1.0618e+01  4.2574e+00  1.0457e+00  4.0531e+00\n",
      " -1.2411e+01 -7.6482e+00 -1.2130e+01  5.5020e+00 -5.5855e+00  8.9720e+00\n",
      "  9.3427e+00  1.0879e+01  4.1582e+00 -2.5860e+00  1.9443e+00 -8.7265e+00\n",
      " -2.7634e+00  1.8921e+00 -3.7815e+00 -9.2013e+00 -1.4649e+01  7.6314e+00\n",
      "  7.4582e-01 -8.8893e+00  1.5500e+00 -2.6028e+00  1.1060e+01  3.0140e+00\n",
      " -3.4123e+00 -1.8096e+00  5.6680e+00 -7.2724e+00 -6.3229e+00 -1.1769e+01\n",
      " -3.9264e+00 -8.9803e+00  6.3989e+00 -1.2253e+00  2.4864e+00  6.8135e+00\n",
      " -7.0184e+00 -1.3726e+01  9.7312e+00 -7.3405e+00 -9.2453e+00  5.7757e+00\n",
      "  4.3007e+00 -8.0123e+00  3.0860e+00  8.0444e+00  1.4223e-01  6.2707e+00\n",
      "  6.8613e+00 -8.8526e+00  1.1775e+01  1.0861e+00  6.3906e+00  1.1675e+01\n",
      " -1.3301e+00 -6.7024e+00  5.3385e+00  1.4182e+01 -1.2517e+01 -1.8817e+00\n",
      " -1.8420e+00  3.0100e+00  6.0498e+00  1.9003e+00 -3.2307e+00  1.8404e+01\n",
      "  2.0600e+00  9.1670e+00 -1.1971e+00 -9.3937e-01 -1.0348e+01 -9.1562e-01\n",
      " -1.1602e+01 -1.6915e+00  8.5983e+00 -2.1288e+00 -6.2938e+00  3.7402e+00\n",
      "  7.5835e+00  3.1627e+00  1.1238e-01  3.6468e+00 -1.0811e+01 -1.2922e+01\n",
      "  7.6225e-02  5.5020e+00  7.4424e+00  4.9263e+00 -3.8132e+00 -3.0775e+00\n",
      "  8.9782e+00 -1.2392e+00  1.8193e+01  7.8366e+00 -3.9842e+00 -1.0240e+01\n",
      " -5.4788e+00  7.5782e-01 -3.6894e+00 -1.4040e+00  7.6965e+00 -4.9921e+00\n",
      " -1.0762e+01  3.4511e+00  8.3834e+00 -1.4089e+01  5.9996e+00 -5.4175e+00\n",
      "  3.2911e+00  4.1133e-01 -3.1855e-01 -1.0471e+01 -7.4132e+00 -1.2667e+01\n",
      " -3.9429e+00  6.4862e-01  1.6643e+01  5.2537e+00 -1.5739e+00  1.2384e+01\n",
      " -3.2884e+00  6.6548e+00 -1.5164e+00  7.2858e+00 -7.1104e+00  1.9264e+01\n",
      " -4.0647e+00  1.4088e+01  1.5324e+00  8.0043e+00 -8.2516e-02  1.2144e+01\n",
      "  4.7768e+00 -2.3385e-03  6.2556e+00  5.3055e+00 -8.4901e+00  1.2877e+01\n",
      "  2.4654e-01 -7.6876e+00 -3.0579e-01 -7.9235e+00 -1.0720e+00  8.6324e+00\n",
      " -2.9564e+00 -9.3927e+00  5.2550e+00 -8.9600e-01 -1.1907e+00  6.1608e+00\n",
      " -9.1574e+00 -1.9537e+00  3.9863e+00 -2.0028e+00  1.3954e+01  5.8352e+00\n",
      " -6.9264e+00  5.7303e+00  9.9175e+00 -4.5458e+00 -1.4370e+00 -1.5490e+01\n",
      " -1.2893e+00 -9.9277e+00  4.2732e+00  6.3726e+00 -1.0262e+01  1.3245e+01]\n",
      "[ 1.0727    0.91195  -4.1039   -5.9668    1.1263   -0.83625   6.5321\n",
      "  2.9779   -1.4953    1.6501    4.1008   -0.4266   -4.7607    0.36301\n",
      "  4.2993   -3.6101   -1.889    -4.1127   -1.3471   -0.89894   0.097736\n",
      "  0.15628   1.4744   -1.5274    2.5652    0.087846 -4.1222    5.9653\n",
      "  2.4877    3.5936    1.601    -4.1639   -3.1682   -2.8031    5.6053\n",
      "  0.14115  -0.25719  -3.6074    4.2861    1.382    -0.94911   5.7315\n",
      "  2.5586   -3.0848   -1.4495    3.7087   -0.53288  -2.3908    1.2943\n",
      "  2.3577    3.9595   -3.0808    1.5959   -2.2442   -0.62637  -2.9861\n",
      " -2.2205   -1.1305    1.3804    2.5867    2.763     0.50591   3.0677\n",
      " -0.61219   0.64739  -2.359    -2.011    -2.8984    1.6451   -2.4643\n",
      "  1.6514    0.20814  -2.4877   -2.2363    0.96361  -0.96412  -1.3239\n",
      "  1.0742   -0.27852  -2.4566    1.7298   -3.3927    2.1089    0.90448\n",
      " -1.5328    0.86462   3.5339    1.1258   -3.2568   -1.3779   -0.68623\n",
      "  3.9564   -3.4808   -5.2019    1.4987   -1.0585    2.728    -6.1352\n",
      "  0.8505   -0.91237   1.8974    2.5978    0.39621   3.1309   -3.6546\n",
      "  1.3873   -4.0891   -0.54836  -1.9152   -0.37005   0.2584   -3.3973\n",
      "  1.5201   -6.2553   -1.0796    2.8594   -4.876    -8.2331    2.7122\n",
      "  1.8854   -2.4079   -0.47123  -1.5291    3.0175    2.7858    2.3865\n",
      "  1.8145   -2.0765    1.7502   -3.0525   -4.3591   -0.53213  -2.1454\n",
      " -2.5447   -0.438    -1.4258   -1.9157   -1.6171    5.8285    1.1991\n",
      " -2.8218    0.043204  3.5379    3.5541   -7.2266   -0.72617   0.56633\n",
      " -2.4348    0.39325   0.69029  -3.0725    1.5416    1.7953   -2.2407\n",
      "  0.698     1.7164    7.15     -1.4165   -0.42141  -3.2721    1.4328\n",
      " -3.6265   -6.3823   -0.46848  -1.0379    1.0466    0.87008  -2.357\n",
      " -1.4904   -0.54497   3.3646    3.1787   -0.51058  -2.8319    2.9578\n",
      " -0.93904  -0.9987    3.5361    0.94907  -1.29      2.9977    3.2273\n",
      "  4.1075   -1.5983    0.29348   2.4246    2.2037   -6.4413   -0.055544\n",
      "  3.4999   -1.4565    6.8339   -3.3839   -1.9973   -0.93155  -2.3863\n",
      " -3.6192    1.5612   -2.911     1.8757   -1.0683   -0.40643  -4.1491\n",
      " -0.16276  -2.5662    3.2755    3.3367    2.7256    0.79124   1.0789\n",
      "  3.8892    0.66009   1.1769    0.92851  -1.7587    3.8739   -0.074525\n",
      "  2.6581   -1.9163    2.3657   -1.2286    0.87889  -3.2244    3.2322\n",
      "  0.95236  -0.31974  -2.4018   -0.027426  3.7302    2.131    -5.8045\n",
      " -1.0454   -0.66586   0.29267  -1.5386    2.4998   -0.79626   5.2818\n",
      " -1.048     1.4811   -0.9604   -2.7624    0.57054  -3.2426    1.9664\n",
      " -1.1249   -0.73802  -1.5845    4.7569    2.9549    2.4597    2.3944\n",
      " -3.3849    2.4664    2.7727   -6.4496   -1.7051    0.095561 -1.6132\n",
      "  1.5263    1.5727   -0.22175  -0.3177    0.37162   0.83749   0.078783\n",
      "  0.026365  1.5217   -3.5558   -2.1386    0.43453  -1.5964   -1.0109\n",
      " -1.6598   -1.3195   -1.1033    3.2393   -2.1572    0.055977  0.89149\n",
      "  0.60515  -4.3048   -4.0544   -0.75188   4.1462   -0.92559   3.5261\n",
      "  2.5949   -3.5926   -1.9169    3.328    -2.2059   -0.78317  -4.6701\n",
      "  0.19135  -1.6233   -1.7663    1.3902   -6.9965    1.204   ]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp('I am happy')\n",
    "# Generate word vectors for each token\n",
    "for token in doc:\n",
    "    print(token.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750f841-e461-42e5-919e-6e682dd73347",
   "metadata": {},
   "source": [
    "## Word similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76540bc3-d30a-4fc9-b238-8a8f4a82abc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T01:59:47.456503Z",
     "iopub.status.busy": "2023-01-06T01:59:47.456300Z",
     "iopub.status.idle": "2023-01-06T01:59:47.470669Z",
     "shell.execute_reply": "2023-01-06T01:59:47.470282Z",
     "shell.execute_reply.started": "2023-01-06T01:59:47.456491Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy happy 1.0\n",
      "happy joyous 0.38305556774139404\n",
      "happy sad 0.5034751296043396\n",
      "joyous happy 0.38305556774139404\n",
      "joyous joyous 1.0\n",
      "joyous sad 0.5143248438835144\n",
      "sad happy 0.5034751296043396\n",
      "sad joyous 0.5143248438835144\n",
      "sad sad 1.0\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"happy joyous sad\")\n",
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc21bc-122d-45cf-978f-5dad88bae5ec",
   "metadata": {},
   "source": [
    "## Document similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d15d9a9-2587-4033-9d4a-180a9d2bf0ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T02:00:03.698165Z",
     "iopub.status.busy": "2023-01-06T02:00:03.698030Z",
     "iopub.status.idle": "2023-01-06T02:00:03.724173Z",
     "shell.execute_reply": "2023-01-06T02:00:03.723687Z",
     "shell.execute_reply.started": "2023-01-06T02:00:03.698154Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate doc objects\n",
    "sent1 = nlp(\"I am happy\")\n",
    "sent2 = nlp(\"I am sad\")\n",
    "sent3 = nlp(\"I am joyous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e71c55d-3782-46b4-9a50-122c745c089e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T02:00:04.578787Z",
     "iopub.status.busy": "2023-01-06T02:00:04.578652Z",
     "iopub.status.idle": "2023-01-06T02:00:04.588150Z",
     "shell.execute_reply": "2023-01-06T02:00:04.587796Z",
     "shell.execute_reply.started": "2023-01-06T02:00:04.578776Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740256667137146"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute similarity between sent1 and sent2\n",
    "sent1.similarity(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "becc36a4-6d92-44dd-93b1-0aafc8972653",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T02:00:05.506839Z",
     "iopub.status.busy": "2023-01-06T02:00:05.506700Z",
     "iopub.status.idle": "2023-01-06T02:00:05.513171Z",
     "shell.execute_reply": "2023-01-06T02:00:05.512783Z",
     "shell.execute_reply.started": "2023-01-06T02:00:05.506827Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.981972336769104"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute similarity between sent1 and sent3\n",
    "sent1.similarity(sent3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000d97a-478d-4bcf-a08a-be855772a6cf",
   "metadata": {},
   "source": [
    "## Generating word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2e72afb-ad25-4af2-895a-df665e77e703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T02:01:35.466530Z",
     "iopub.status.busy": "2023-01-06T02:01:35.466391Z",
     "iopub.status.idle": "2023-01-06T02:01:35.499513Z",
     "shell.execute_reply": "2023-01-06T02:01:35.499081Z",
     "shell.execute_reply.started": "2023-01-06T02:01:35.466518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I 1.0\n",
      "I like 0.3184410333633423\n",
      "I apples 0.1975560337305069\n",
      "I and -0.0979199931025505\n",
      "I oranges 0.05048731341958046\n",
      "like I 0.3184410333633423\n",
      "like like 1.0\n",
      "like apples 0.29574334621429443\n",
      "like and 0.2435961216688156\n",
      "like oranges 0.2706858813762665\n",
      "apples I 0.1975560337305069\n",
      "apples like 0.29574334621429443\n",
      "apples apples 1.0\n",
      "apples and 0.24472729861736298\n",
      "apples oranges 0.7808240652084351\n",
      "and I -0.0979199931025505\n",
      "and like 0.2435961216688156\n",
      "and apples 0.24472729861736298\n",
      "and and 1.0\n",
      "and oranges 0.3738572895526886\n",
      "oranges I 0.05048731341958046\n",
      "oranges like 0.2706858813762665\n",
      "oranges apples 0.7808240652084351\n",
      "oranges and 0.3738572895526886\n",
      "oranges oranges 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create the doc object\n",
    "sent = 'I like apples and oranges'\n",
    "doc = nlp(sent)\n",
    "\n",
    "# Compute pairwise similarity scores\n",
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace71cae-8d29-45d6-99d5-66963f6bf1d5",
   "metadata": {},
   "source": [
    "> Notice how the words 'apples' and 'oranges' have the highest pairwaise similarity score. This is expected as they are both fruits and are more related to each other than any other pair of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04809b0a-55c5-4f1c-a4aa-a52159e116c9",
   "metadata": {},
   "source": [
    "## Computing similarity of Pink Floyd songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8bc0e81-1556-42ca-b963-be9ca37e0fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T02:04:23.767147Z",
     "iopub.status.busy": "2023-01-06T02:04:23.767009Z",
     "iopub.status.idle": "2023-01-06T02:04:23.769718Z",
     "shell.execute_reply": "2023-01-06T02:04:23.769369Z",
     "shell.execute_reply.started": "2023-01-06T02:04:23.767135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hopes = \"\\nBeyond the horizon of the place we lived when we were young\\nIn a world of magnets and miracles\\nOur thoughts strayed constantly and without boundary\\nThe ringing of the division bell had begun\\nAlong the Long Road and on down the Causeway\\nDo they still meet there by the Cut\\nThere was a ragged band that followed in our footsteps\\nRunning before times took our dreams away\\nLeaving the myriad small creatures trying to tie us to the ground\\nTo a life consumed by slow decay\\nThe grass was greener\\nThe light was brighter\\nWhen friends surrounded\\nThe nights of wonder\\nLooking beyond the embers of bridges glowing behind us\\nTo a glimpse of how green it was on the other side\\nSteps taken forwards but sleepwalking back again\\nDragged by the force of some in a tide\\nAt a higher altitude with flag unfurled\\nWe reached the dizzy heights of that dreamed of world\\nEncumbered forever by desire and ambition\\nThere's a hunger still unsatisfied\\nOur weary eyes still stray to the horizon\\nThough down this road we've been so many times\\nThe grass was greener\\nThe light was brighter\\nThe taste was sweeter\\nThe nights of wonder\\nWith friends surrounded\\nThe dawn mist glowing\\nThe water flowing\\nThe endless river\\nForever and ever\\n\"\n",
    "mother = \"\\nMother do you think they'll drop the bomb?\\nMother do you think they'll like this song?\\nMother do you think they'll try to break my balls?\\nOoh, ah\\nMother should I build the wall?\\nMother should I run for President?\\nMother should I trust the government?\\nMother will they put me in the firing mine?\\nOoh ah,\\nIs it just a waste of time?\\nHush now baby, baby, don't you cry.\\nMama's gonna make all your nightmares come true.\\nMama's gonna put all her fears into you.\\nMama's gonna keep you right here under her wing.\\nShe won't let you fly, but she might let you sing.\\nMama's gonna keep baby cozy and warm.\\nOoh baby, ooh baby, ooh baby,\\nOf course mama's gonna help build the wall.\\nMother do you think she's good enough, for me?\\nMother do you think she's dangerous, to me?\\nMother will she tear your little boy apart?\\nOoh ah,\\nMother will she break my heart?\\nHush now baby, baby don't you cry.\\nMama's gonna check out all your girlfriends for you.\\nMama won't let anyone dirty get through.\\nMama's gonna wait up until you get in.\\nMama will always find out where you've been.\\nMama's gonna keep baby healthy and clean.\\nOoh baby, ooh baby, ooh baby,\\nYou'll always be baby to me.\\nMother, did it need to be so high?\\n\"\n",
    "hey = \"\\nHey you, out there in the cold\\nGetting lonely, getting old\\nCan you feel me?\\nHey you, standing in the aisles\\nWith itchy feet and fading smiles\\nCan you feel me?\\nHey you, don't help them to bury the light\\nDon't give in without a fight\\nHey you out there on your own\\nSitting naked by the phone\\nWould you touch me?\\nHey you with you ear against the wall\\nWaiting for someone to call out\\nWould you touch me?\\nHey you, would you help me to carry the stone?\\nOpen your heart, I'm coming home\\nBut it was only fantasy\\nThe wall was too high\\nAs you can see\\nNo matter how he tried\\nHe could not break free\\nAnd the worms ate into his brain\\nHey you, out there on the road\\nAlways doing what you're told\\nCan you help me?\\nHey you, out there beyond the wall\\nBreaking bottles in the hall\\nCan you help me?\\nHey you, don't tell me there's no hope at all\\nTogether we stand, divided we fall\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6a1a46a-7b82-469d-8bfc-6abc7b3890a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T02:05:06.324520Z",
     "iopub.status.busy": "2023-01-06T02:05:06.324319Z",
     "iopub.status.idle": "2023-01-06T02:05:06.428991Z",
     "shell.execute_reply": "2023-01-06T02:05:06.428627Z",
     "shell.execute_reply.started": "2023-01-06T02:05:06.324508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5779930353164673\n",
      "0.9465446472167969\n"
     ]
    }
   ],
   "source": [
    "# Create Doc objects\n",
    "mother_doc = nlp(mother)\n",
    "hopes_doc = nlp(hopes)\n",
    "hey_doc = nlp(hey)\n",
    "\n",
    "# Print similarity between mother and hopes\n",
    "print(mother_doc.similarity(hopes_doc))\n",
    "\n",
    "# Print similarity between mother and hey\n",
    "print(mother_doc.similarity(hey_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1561b1-1dc5-4315-81ae-280a68cc3ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T02:06:00.795759Z",
     "iopub.status.busy": "2023-01-06T02:06:00.795622Z",
     "iopub.status.idle": "2023-01-06T02:06:00.798663Z",
     "shell.execute_reply": "2023-01-06T02:06:00.798190Z",
     "shell.execute_reply.started": "2023-01-06T02:06:00.795747Z"
    }
   },
   "source": [
    "> Notice that 'Mother' and 'Hey You' have a similarity score of 0.9 whereas 'Mother' and 'High Hopes' has a score of only 0.6. This is probably because 'Mother' and 'Hey You' were both songs from the same album 'The Wall' and were penned by Roger Waters. On the other hand, 'High Hopes' was a part of the album 'Division Bell' with lyrics by David Gilmour and his wife, Penny Samson. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
